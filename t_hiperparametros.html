<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pt-br" xml:lang="pt-br"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Evitando mínimos locais e overfitting – PSI5892</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e0b2e4e5c4db31b3b64fdef51415d7d2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nenhum resultado",
    "search-matching-documents-text": "documentos correspondentes",
    "search-copy-link-title": "Copiar link para a busca",
    "search-hide-matches-text": "Esconder correspondências adicionais",
    "search-more-match-text": "mais correspondência neste documento",
    "search-more-matches-text": "mais correspondências neste documento",
    "search-clear-button-title": "Limpar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Procurar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">PSI5892</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Procurar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Alternar de navegação" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teoria" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Teoria</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-teoria">    
        <li>
    <a class="dropdown-item" href="./t_introducao.html">
 <span class="dropdown-text">Introdução</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_regressao_linear.html">
 <span class="dropdown-text">Regressão linear</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_lms.html">
 <span class="dropdown-text">O algoritmo LMS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_neuronio.html">
 <span class="dropdown-text">O modelo do neurônio</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_mlp.html">
 <span class="dropdown-text">A rede perceptron multicamada</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_hiperparametros.html">
 <span class="dropdown-text">Evitando mínimos locais e <em>overfitting</em></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_autodiff.html">
 <span class="dropdown-text">Introdução à diferenciação automática</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_pytorch_topicos.html">
 <span class="dropdown-text">Tópicos sobre o <em>framework</em> PyTorch</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_pytorch_exemplo_mlp.html">
 <span class="dropdown-text">Implementação da rede MLP com PyTorch</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_medidas.html">
 <span class="dropdown-text">Medidas de desempenho</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_pca.html">
 <span class="dropdown-text">Análise de Componentes Principais</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_lda.html">
 <span class="dropdown-text">Análise de Discriminantes Lineares</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-material-de-apoio" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Material de apoio</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-material-de-apoio">    
        <li>
    <a class="dropdown-item" href="./ap_python_topicos.html">
 <span class="dropdown-text">Tópicos de programação com Python</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Evitando mínimos locais e <em>overfitting</em></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="justify">
<p>Há diferentes maneiras de evitar que o algoritmo <em>backpropagation</em> fique parado em um mínimo local da função custo, evitando assim que a rede atinja soluções subótimas no treinamento. Outro problema que pode acontecer no treinamento das redes neurais é o chamado <em>overfitting</em>, em que a solução da rede fica especializada nos dados de treinamento e tem um desempenho ruim com os dados de teste. Vimos um exemplo de <em>overfitting</em> com a regressão linear. A seguir, vamos abordar as técnicas mais usadas para evitar esses problemas. Boa parte delas envolve o ajuste de hiperparâmetros, que por sua vez, são todos os parâmetros da rede que não são “aprendidos” durante o treinamento. Por exemplo, o passo de adaptação <span class="math inline">\(\eta\)</span> é um hiperparâmetro enquanto os pesos não o são.</p>
<section id="função-de-ativação" class="level2">
<h2 class="anchored" data-anchor-id="função-de-ativação">Função de ativação</h2>
<p>O cálculo do gradiente para atualização do vetor de pesos de um determinado neurônio requer o conhecimento da derivada da função de ativação <span class="math inline">\(\varphi(\cdot)\)</span> associada a ele. Para atualização do gradiente, é importante que essa derivada exista e seja não nula. Por isso, as funções sinal e degrau, usadas no neurônio de Rosenblatt, não são adequadas. A seguir vamos descrever as funções de wativação mais usadas na MLP.</p>
<section id="sigmoidal" class="level3">
<h3 class="anchored" data-anchor-id="sigmoidal">Sigmoidal</h3>
<p>A função sigmoidal, também conhecida como função logística, é definida como<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \varphi_j(v_k^{(j)})={\rm sgm}(a\,v_k^{(j)})=\displaystyle\frac{1}{1+e^{-a\, v_k^{(j)}}},\;\;\;\; a&gt;0,
$}
\end{equation*}\]</span></p>
<p>em que <span class="math inline">\(v_k^{(j)}\)</span> é o resultado da soma do <em>bias</em> com a combinação linear entre as entradas e os pesos do neurônio <span class="math inline">\(k\)</span> da camada <span class="math inline">\(j\)</span> e <span class="math inline">\(a\)</span> é um parâmetro positivo ajustável. A derivada dessa função é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \varphi'_j(v_k^{(j)})=\frac{\rm d}{{\rm d}v_k^{(j)}}{\rm sgm}(a\,v_k^{(j)})=\displaystyle \frac{a\,e^{-a\, v_k^{(j)}}}{\left[1+e^{-a\, v_k^{(j)}}\right]^2}= a \varphi_j(v_k^{(j)})[1-\varphi_j(v_k^{(j)})].
$}
\end{equation*}\]</span></p>
<p>Como <span class="math inline">\(\varphi_j(v_k^{(j)})=y_k^{(j)}\)</span> é a saída do neurônio <span class="math inline">\(k\)</span> da camada <span class="math inline">\(j\)</span>, ainda podemos escrever</p>
<p><span class="math display">\[
\varphi'_j(v_k^{(j)})= a\, y_k^{(j)}(1-y_k^{(j)}).
\]</span></p>
<p>Na <a href="#fig-sigmoide" class="quarto-xref">Figura&nbsp;1</a> são mostrados gráficos da função sigmoidal e de sua derivada para dois valores de <span class="math inline">\(a\)</span>. Pode-se observar que a saída do neurônio com função sigmoidal fica no intervalo <span class="math inline">\([0,\; 1]\)</span>. Quanto maior o valor do parâmetro <span class="math inline">\(a\)</span> mais abrupta é a mudança do patamar <span class="math inline">\(0\)</span> para o patamar <span class="math inline">\(1\)</span> e consequentemente maior a derivada em <span class="math inline">\(v_k^{(j)}=0\)</span>.</p>
<div id="fig-sigmoide" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sigmoide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/sgmoide.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sigmoide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1: Função sigmoidal e sua derivada para dois valores do parâmetro <span class="math inline">\(a\)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="tangente-hiperbólica" class="level3">
<h3 class="anchored" data-anchor-id="tangente-hiperbólica">Tangente hiperbólica</h3>
<p>Outra função de ativação muito utilizada na MLP é a tangente hiperbólica. Essa é a função de ativação que utilizamos nos experimentos com a rede MLP até agora (com <span class="math inline">\(a=1\)</span>). A tangente hiperbólica é definida como</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \varphi_j(v_k^{(j)})={\rm tanh}(a\,v_k^{(j)})=\frac{e^{a\,v_k^{(j)}}-e^{-a\,v_k^{(j)}}}{e^{a\,v_k^{(j)}}+e^{-a\,v_k^{(j)}}},\;\;\;a&gt;0,
  $}
\end{equation*}\]</span> sendo <span class="math inline">\(a\)</span> uma constante positiva. Sua derivada é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\varphi_j'(v_k^{(j)})=\frac{\rm d}{{\rm d}v_k^{(j)}}{\rm tanh}(a\,v_k^{(j)})=a\,\left[1-{\rm tanh}^2(v_k^{(j)})\right].
$}
\end{equation*}\]</span></p>
<p>Lembrando que a saída do neurônio <span class="math inline">\(k\)</span> com função de ativação tangente hiperbólica é dada por <span class="math inline">\(y_k^{(j)}={\rm tanh}(v_k^{(j)})\)</span>, também podemos escrever</p>
<p><span class="math display">\[
\varphi'_j(v_k^{(j)})=\frac{1}{a}(a-y_k^{(j)})(a+y_k^{(j)}).
\]</span></p>
<p>Na <a href="#fig-tanh" class="quarto-xref">Figura&nbsp;2</a> são mostrados gráficos da função tangente hiperbólica e de sua derivada para dois valores de <span class="math inline">\(a\)</span>. Pode-se observar que a saída do neurônio com essa função fica no intervalo <span class="math inline">\([-1,\; 1]\)</span>. Quanto maior o valor do parâmetro <span class="math inline">\(a\)</span> mais abrupta é a mudança do patamar <span class="math inline">\(-1\)</span> para o patamar <span class="math inline">\(1\)</span> e consequentemente maior a derivada em <span class="math inline">\(v_k^{(j)}=0\)</span>.</p>
<div id="fig-tanh" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tanh-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/tanh.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tanh-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2: Função tangente hiperbólica e sua derivada para dois valores do parâmetro <span class="math inline">\(a\)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="relu" class="level3">
<h3 class="anchored" data-anchor-id="relu">ReLU</h3>
<p>A unidade linear retificada (<em>Rectified Linear Unit</em> - ReLU) é uma função de ativação dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \varphi_j(v_k^{(j)})={\rm ReLU}(v_k^{(j)})=\max(0, v_k^{(j)})=\left\{\begin{array}{cc}
                                     0, &amp; v_k^{(j)}\leq 0 \\
                                     v_k^{(j)}, &amp; v_k^{(j)}&gt;0
                                   \end{array}
                                 \right.

$}
\end{equation*}\]</span></p>
<p>Essa função também é conhecida como função rampa e é análoga ao retificador de meia-onda, o que justifica seu nome. Sua derivada é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \varphi_j'(v_k^{(j)})={\rm ReLU}'(v_k^{(j)})=\left\{\begin{array}{cc}
                                     0, &amp; v_k^{(j)}&lt; 0 \\
                                     1, &amp; v_k^{(j)}&gt;0\\
                                     \nexists, &amp; v_k^{(j)}=0.
                                   \end{array}
                                 \right.

$}
\end{equation*}\]</span></p>
<p>Na <a href="#fig-relu" class="quarto-xref">Figura&nbsp;3</a> são mostradas a função ReLU e a sua derivada. Observe que a função ReLU não é diferenciável em <span class="math inline">\(v_k^{(j)}=0\)</span>. Como ela é diferenciável em todos os outros valores de <span class="math inline">\(v_k^{(j)}\)</span>, o valor de sua derivada em zero pode ser arbitrariamente escolhido como 0 ou 1. Em geral, o treinamento de redes MLP profundas que usam essa função é mais rápido quando comparado ao treinamento das redes MLP que usam a tangente hiperbólica. Essa função foi baseada no princípio de que os modelos são mais facilmente otimizados quando o seu comportamento é próximo do linear.</p>
<div id="fig-relu" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-relu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/ReLU.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-relu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3: Função ReLU e sua derivada (a derivada em <span class="math inline">\(v_k^{(j)}=0\)</span> foi arbitrariamente escolhida como 0)
</figcaption>
</figure>
</div>
<p>Na literatura, há diferentes variantes da ReLU, como:</p>
<ul>
<li><em>Softplus</em>;</li>
<li><em>Gaussian Error Linear Unit</em> (GELU);</li>
<li><em>Leaky rectified linear unit</em> (<em>Leaky</em> ReLU);</li>
<li><em>Parametric rectified linear unit</em> (PReLU);</li>
<li><em>Exponential linear unit</em> (ELU);</li>
<li><em>Sigmoid linear unit</em> (SiLU).</li>
</ul>
<p>Algumas dessas funções são diferenciáveis em todos os pontos, o que evita ter que escolher arbitrariamente o valor da derivada em <span class="math inline">\(v_k^{(j)}=0\)</span>. Apesar da existência dessas variantes, a ReLU ainda é a mais utilizada em redes profundas. Ela apresenta algumas vantagens como:</p>
<ol type="1">
<li>ativação esparsa: em uma rede inicializada aleatoriamente, apenas 50% dos neurônios ocultos são ativados (saída não nula);</li>
<li>melhor propagação do gradiente: consegue escapar de mínimos locais em comparação com as funções sigmoidal ou tangente hiperbólica;</li>
<li>computação eficiente;</li>
<li>invariante à escala: <span class="math inline">\(\max(0,\,ax)= a\,\max(0,\,x),\;\;a&gt;0\)</span>.</li>
</ol>
<p>Apesar dessas vantagens, a ReLU é ilimitada, o que pode levar o algoritmo de treinamento à divergência. Além disso, neurônios com ReLU podem se tornar inativos para essencialmente todas as entradas. Nesse estado, nenhum gradiente é retropropagado e o neurônio “morre”. Em alguns casos, muitos neurônios podem ficar inativos, diminuindo efetivamente a capacidade do modelo. Esse problema geralmente surge quando a taxa de aprendizado (passo de adaptação) é muito alta e pode ser evitado usando a função <em>leaky</em> ReLU, que atribui uma pequena inclinação positiva para entradas negativas.</p>
</section>
<section id="softmax" class="level3">
<h3 class="anchored" data-anchor-id="softmax"><em>Softmax</em></h3>
<p>Em problemas de classificação multiclasse, é comum considerar uma rede com <span class="math inline">\(N_L\)</span> neurônios de saída, sendo <span class="math inline">\(N_L\)</span> o número de classes. Nesse caso, a saída esperada da rede é a ativação de apenas um dos <span class="math inline">\(N_L\)</span> neurônios e a inativação dos <span class="math inline">\(N_L-1\)</span> restantes. Para isso, costuma-se usar a função de ativação <em>softmax</em> nos neurônios de saída. Como a função sigmoidal, a função <em>softmax</em> limita a saída do neurônio entre 0 e 1. Porém, ela também leva em conta as saídas dos demais neurônios da camada. Dessa forma, considera-se uma normalização fazendo com que a soma de todas as saídas dos neurônios seja unitária, o que faz com que o vetor saída da rede seja um vetor de probabilidades. A função <em>softmax</em> para o <span class="math inline">\(k\)</span>-ésimo neurônio da camada de saída é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\varphi_L(v_k^{(L)})={\rm Softmax}(v_k^{(L)})=\frac{e^{v_k^{(L)}}}{\displaystyle \sum_{\ell=1}^{N_L}e^{v_\ell^{(L)}}},
$}
\end{equation*}\]</span></p>
<p>em que <span class="math inline">\(0\leq\varphi_L(v_k^{(L)})\leq 1\)</span> e <span class="math inline">\(\sum_{\ell=1}^{N_L}\varphi_L(v_\ell^{(L)})=1\)</span>. A derivada dessa função é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\varphi'_L(v_k^{(L)})={\rm Softmax}'(v_k^{(L)})=\frac{e^{v_k^{(L)}}\left[\displaystyle \sum_{\ell=1}^{N_L}e^{v_\ell^{(L)}}-e^{v_k^{(L)}}\right]}{\displaystyle \left[\sum_{\ell=1}^{N_L}e^{v_\ell^{(L)}}\right]^2}.
$}
\end{equation*}\]</span></p>
</section>
</section>
<section id="função-custo" class="level2">
<h2 class="anchored" data-anchor-id="função-custo">Função custo</h2>
<p>A escolha da função custo depende da finalidade da rede neural. Quando empregada em problemas de regressão, é comum usar o erro quadrático médio (<em>Mean Squared Error</em> - MSE) definido por</p>
<p><span class="math display">\[\begin{equation}\label{mse}
J_{\rm MSE} = \frac{1}{N_L} \sum_{\ell=1}^{N_L} e_{\ell}^2(n),
\end{equation}\]</span> em que <span class="math display">\[\begin{equation}\label{e_n}
e_{\ell}(n) = d_{\ell}(n) - y_{\ell}^{(L)}(n)
\end{equation}\]</span></p>
<p>são os erros dos neurônios da camada de saída da rede. Apesar de não ser a função custo mais adequada para problemas de classificação, o MSE foi utilizado nos problemas das meias-luas apresentados até o momento.</p>
<p>Quando a rede é empregada em problemas de classificação, é comum usar a entropia cruzada, uma vez que ela é mais adequada para erros de categorização. No caso de classificação binária em que as categorias são <span class="math inline">\(d = 0\)</span> ou <span class="math inline">\(d=1\)</span> e existe apenas um neurônio de saída, a entropia cruzada é dada por</p>
<p><span class="math display">\[
J_{\rm EC} = -  \left[ d_1(n) \ln\left({y_{1}^{(L)}(n)}\right) + [1 - d_1(n)] \ln{\left(1 -y_{1}^{(L)}(n)\right)}\right].
\]</span></p>
<p>Para entender essa função, considere novamente o problema das meias-luas, mantendo <span class="math inline">\(d=1\)</span> para a Região A, mas considerando que <span class="math inline">\(d=0\)</span> para a Região B. Quando <span class="math inline">\(y_1^{(L)}(n)\geq 0,5\)</span> a rede classifica o dado como pertencente à Região A e para <span class="math inline">\(y_1^{(L)}(n)&lt;0,5\)</span> o dado é classificado como pertencente à Região B. Dessa forma, a saída da rede pode ser interpretada como a probabilidade do dado de entrada pertencer à Região A. Quando <span class="math inline">\(d_1(n)=y_1^{(L)}(n) \in \{0, 1\}\)</span>, <span class="math inline">\(J_{\rm EC}=0\)</span>, que é o valor mínimo que essa função custo pode assumir. Para <span class="math inline">\(d_1(n)=1\)</span> e <span class="math inline">\(y_1^{(L)}(n)=0,\!1\)</span>, a rede erra, pois classifica o dado como pertencente à Região B enquanto ele de fato pertence à Região A e <span class="math inline">\(J_{\rm EC}=-1\times \ln(0,1)=2,\!3026.\)</span> A função custo tem o mesmo valor para <span class="math inline">\(d_1(n)=0\)</span> e <span class="math inline">\(y_1^{(L)}(n)=0,\!9\)</span>, caso em que também há erro de classificação. No caso de classificação entre <span class="math inline">\(N_L\)</span> classes, essa função é chamada de entropia cruzada categórica e é dada por</p>
<p><span class="math display">\[
J_{\rm ECC} = -  \frac{1}{N_L}\sum_{\ell=1}^{N_L} d_\ell(n)  \ln\left(y_{\ell}^{(L)}(n)\right).
\]</span></p>
<p>Uma das maneiras de se reduzir <em>overfitting</em> é usar regularização na função custo. Isso controla o ajuste dos pesos, possibilitando que a rede tenha uma boa capacidade de generalização. A regularização <span class="math inline">\(\ell_2\)</span> é a mais comum e consiste em somar à função custo o termo <span class="math display">\[\frac{\lambda}{2N_L}\sum_{\ell=1}^{N_L}\|\mathbf{w}_\ell^{(L)}(n-1)\|^2,\]</span> em que <span class="math inline">\(\lambda\)</span> é um hiperparâmetro. Assim, ao minimizar a função custo somada a esse termo, o algoritmo também procura minimizar a norma dos vetores de peso da camada de saída, evitando dessa forma que ocorra divergência <span class="citation" data-cites="Bishop_book2006">(<a href="#ref-Bishop_book2006" role="doc-biblioref">Bishop 2006</a>)</span>.</p>
<p>Existem também outras funções custo cujas derivadas não são determinadas analiticamente, mas podem ser obtidas por diferenciação automática (<em>autodiff</em>), que é um conjunto de técnicas usadas para avaliar derivadas de funções numéricas expressas como programas de computador. Mais detalhes sobre <em>autodiff</em> podem ser obtidos em <span class="citation" data-cites="BaydinJMLR2018">(<a href="#ref-BaydinJMLR2018" role="doc-biblioref">Baydin et al. 2018</a>)</span>.</p>
</section>
<section id="inicialização" class="level2">
<h2 class="anchored" data-anchor-id="inicialização">Inicialização</h2>
<p>Sabemos que a inicialização é fundamental para que a rede MLP evite mínimos locais. Nos experimentos com as meias-luas que apresentamos até agora, os pesos e <em>biases</em> foram inicializados com números aleatórios gerados a partir de uma distribuição uniforme no intervalo <span class="math inline">\([-10^{-2},\;10^{-2}]\)</span>. Como não se tem ideia dos valores dos parâmetros ótimos, de fato os pesos precisam ser inicializados de forma aleatória. O problema da forma que inicializamos é definir o intervalo da distribuição uniforme. O intervalo “ideal” depende do conjunto de dados, da arquitetura da rede etc. e sua escolha se torna mais difícil ainda em redes profundas. Além disso, uma pergunta que poderíamos fazer é: a inicialização dos parâmetros da rede considerando uma distribuição uniforme é a mais adequada?</p>
<p>No algoritmo <em>backpropagation</em>, o cálculo do gradiente local de uma determinada camada <span class="math inline">\(j\)</span> da rede depende dos gradientes locais das camadas posteriores, ou seja, o gradiente local <span class="math inline">\(\delta^{(j)}_k\)</span> carrega consigo a multiplicação de todos os gradientes locais das camadas mais profundas da rede. Para redes neurais profundas, se os gradientes locais forem menores do que um, as atualizações dos pesos e <em>biases</em> das camadas mais rasas acabam assumindo valores muito pequenos, tornando o processo de aprendizado lento e ineficiente. Analogamente, para gradientes locais sempre maiores que um, as atualizações dos pesos das camadas menos profundas acabam assumindo valores muito elevados, levando o algoritmo de treinamento à divergência. Esse problema é conhecido como desvanecimento ou explosão dos gradientes. O objetivo das técnicas de inicialização de parâmetros é evitar esse problema. Dessa forma, os pesos e <em>biases</em> precisam ser inicializados dentro de um intervalo específico.</p>
<p>A seguir, vamos abordar duas técnicas de inicialização frequentemente usadas na literatura <span class="citation" data-cites="JasonInit2021">(<a href="#ref-JasonInit2021" role="doc-biblioref">Brownlee 2021</a>)</span>.</p>
<section id="inicialização-de-xavier" class="level3">
<h3 class="anchored" data-anchor-id="inicialização-de-xavier">Inicialização de Xavier</h3>
<p>A inicialização de Xavier foi proposta originalmente no artigo <span class="citation" data-cites="Xavier2010">(<a href="#ref-Xavier2010" role="doc-biblioref">Glorot e Bengio 2010</a>)</span>. Para entender a ideia dessa inicialização, vamos primeiramente considerar que os neurônios da rede MLP têm função de ativação do tipo sigmoidal e pesos grandes. Como a função do tipo sigmoidal é plana para valores grandes da entrada, as ativações ficarão saturadas e os gradientes começarão a se aproximar de zero.</p>
<p>Para evitar esse problema, a inicialização de Xavier busca garantir que a variância de <span class="math inline">\(y^{(j)}_k\)</span> seja mantida igual ao longo das camadas, o que pode evitar o problema de desvanecimento ou explosão dos gradientes. Considerando função de ativação linear, temos</p>
<p><span class="math display">\[
y_k^{(j)}=b_k^{(j)}+w_{k1}^{(j)}y_1^{(j-1)}+w_{k2}^{(j)}y_2^{(j-1)}+\cdots+w_{kN_{j-1}}^{(j)}y_{N_{j-1}}^{(j-1)}.
\]</span></p>
<p>Calculando a variância de <span class="math inline">\(y_k^{(j)}\)</span>, obtém-se</p>
<p><span class="math display">\[
{\rm var}(y_k^{(j)})={\rm var}\left(b_k^{(j)}+w_{k1}^{(j)}y_1^{(j-1)}+w_{k2}^{(j)}y_2^{(j-1)}+\cdots+w_{kN_{j-1}}^{(j)}y_{N_{j-1}}^{(j-1)}\right).
\]</span></p>
<p>Assumindo que os <em>biases</em> foram inicializados com zero, sua variância também é nula. Portanto, precisamos calcular apenas a variância dos termos do lado direito da equação que contém os pesos. Assumindo independência entre os pesos e as entradas da camada <span class="math inline">\(j\)</span>, temos</p>
<p><span class="math display">\[
{\rm var}(w_{k\ell}^{(j)}y_\ell^{(j-1)})=[{\rm E}\{y_\ell^{(j-1)}\}]^2{\rm var}(w_{k\ell}^{(j)})+[{\rm E}\{w_{k\ell}^{(j)}\}]^2{\rm var}(y_\ell^{(j-1)})+{\rm var}(w_{k\ell}^{(j)}){\rm var}(y_\ell^{(j-1)}),
\]</span></p>
<p><span class="math inline">\(\ell=1,2,\cdots,N_{j-1}.\)</span> Considerando ainda que as entradas e os pesos têm médias nulas, a expressão anterior se reduz a</p>
<p><span class="math display">\[
{\rm var}(w_{k\ell}^{(j)}y_\ell^{(j-1)})={\rm var}(w_{k\ell}^{(j)}){\rm var}(y_\ell^{(j-1)}).
\]</span></p>
<p>Usando esse resultado no cálculo da variância de <span class="math inline">\(y_k^{(j)}\)</span>, chega-se a</p>
<p><span class="math display">\[
{\rm var}(y_k^{(j)})=N_{j-1}{\rm var}(w_{k\ell}^{(j)}){\rm var}(y_\ell^{(j-1)}).
\]</span></p>
<p>Como se deseja que <span class="math inline">\({\rm var}(y_k^{(j)})={\rm var}(y_\ell^{(j-1)})\)</span>, obtemos</p>
<p><span class="math display">\[
{\rm var}(w_{k\ell}^{(j)})=\frac{1}{N_{j-1}}.
\]</span></p>
<p>Diante desse resultado, a inicialização de Xavier propõe inicializar os pesos utilizando uma distribuição normal com média nula e desvio padrão <span class="math inline">\(1/\sqrt{N_{j-1}}\)</span>, ou seja</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm N}\left(0,\,\frac{1}{N_{j-1}}\right).
$}
\end{equation*}\]</span></p>
<p>Uma variante dessa inicialização, conhecida na literatura como inicialização de Glorot, leva em conta também o número de número de neurônios da camada <span class="math inline">\(j\)</span>, ou seja</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm N}\left(0,\,\frac{2}{N_{j-1}+N_j}\right).
$}
\end{equation*}\]</span></p>
<p>A ideia dessa inicialização é preservar também a variância do sinal retropropagado e para isso, considera que a variância do peso é aproximada por</p>
<p><span class="math display">\[
{\rm var}(w_{k\ell}^{(j)})\approx\frac{1}{(N_{j-1}+N_j)/2}.
\]</span></p>
<p>Há ainda variantes dessas inicializações que utilizam a distribuição uniforme. Assim, a inicialização de Xavier com distribuição uniforme é</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm U}\left[-\sqrt{\frac{3}{N_{j-1}}},\;+\sqrt{\frac{3}{N_{j-1}}}\,\right]

$}
\end{equation*}\]</span></p>
<p>e a inicialização de Glorot com distribuição uniforme é</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm U}\left[-\sqrt{\frac{6}{N_{j-1}+N_j}},\;+\sqrt{\frac{6}{N_{j-1}+N_j}}\,\right].
$}
\end{equation*}\]</span></p>
</section>
<section id="inicialização-de-he" class="level3">
<h3 class="anchored" data-anchor-id="inicialização-de-he">Inicialização de He</h3>
<p>O problema de desvanecimento ou explosão dos gradientes visto com funções de ativação do tipo sigmoidal geralmente não ocorre quando se usa ReLU. Diante disso, foi proposta uma inicialização alternativa à de Xavier para neurônios que consideram ReLU, conhecida como inicialização de He, no artigo <span class="citation" data-cites="He2015">(<a href="#ref-He2015" role="doc-biblioref">He et al. 2015</a>)</span>. Basicamente, a inicialização de He propõe que os pesos tenham o dobro da variância calculada anteriormente, ou seja,</p>
<p><span class="math display">\[
{\rm var}(w_{k\ell}^{(j)})=\frac{2}{N_{j-1}},
\]</span></p>
<p>o que leva à seguinte inicialização considerando a distribuição normal</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm N}\left(0,\,\frac{2}{N_{j-1}}\right)
$}
\end{equation*}\]</span></p>
<p>e à seguinte variante para distribuição uniforme</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm U}\left[-\sqrt{\frac{6}{N_{j-1}}},\;+\sqrt{\frac{6}{N_{j-1}}}\,\right].
$}
\end{equation*}\]</span></p>
</section>
</section>
<section id="passo-de-adaptação" class="level2">
<h2 class="anchored" data-anchor-id="passo-de-adaptação">Passo de Adaptação</h2>
<p>Um dos principais hiperparâmetros que precisam ser ajustados no treinamento de uma rede neural é o passo de adaptação ou taxa de aprendizagem. Se o passo for muito baixo, a convergência do algoritmo de treinamento será muito lenta como mostrado na <a href="#fig-passos" class="quarto-xref">Figura&nbsp;4</a> (a). Em contrapartida, um passo muito elevado pode levar o algoritmo à divergência, caso ilustrado na <a href="#fig-passos" class="quarto-xref">Figura&nbsp;4</a> (c). Na <a href="#fig-passos" class="quarto-xref">Figura&nbsp;4</a> (b), considera-se um passo ideal que proporciona uma rápida convergência. O passo de adaptação ideal depende da superfície de desempenho, que, por sua vez, depende da arquitetura da rede e do conjunto de dados. O treinamento da rede pode ser acelerado quando se utiliza uma taxa de aprendizagem ideal <span class="citation" data-cites="Jordan2018learning">(<a href="#ref-Jordan2018learning" role="doc-biblioref">Jordan 2018</a>)</span>.</p>
<div id="fig-passos" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-passos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/passos.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-passos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;4: Três passos de adaptação diferentes: (a) passo muito baixo que requer muitas iterações até que o algoritmo atinja o mínimo da função custo; (b) passo ótimo que faz com que o algoritmo atinja o mínimo rapidamente e (c) passo muito elevado que pode levar o algoritmo à divergência. <a href="https://www.jeremyjordan.me/nn-learning-rate">[Fonte]</a>.
</figcaption>
</figure>
</div>
<p>Uma das técnicas mais utilizadas para ajustar o passo de adaptação é a <em>learning rate annealing</em>. Nessa técnica, o valor do passo deve ser relativamente alto no início e diminuir gradualmente ao longo do treinamento. Com um passo elevado no início do treinamento, os pesos e <em>biases</em> são ajustados rapidamente para valores “bons”, ou seja, uma taxa alta pode fazer com que o algoritmo “pule” mínimos locais. Em seguida, uma taxa de aprendizagem pequena faz um ajuste fino, possibilitando o algoritmo explorar as partes “mais profundas” da função custo. A forma mais comum de fazer isso é considerar o decaimento do passo em escada ou exponencial, como ilustrado na <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a>.</p>
<p>No decaimento em escada com degraus uniformes da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (a), o passo da <span class="math inline">\(k\)</span>-ésima época é calculado como</p>
<p><span class="math display">\[
\eta(k)=\eta_0-\Delta \eta \lfloor k/\Delta k\rfloor,
\]</span></p>
<p>em que <span class="math inline">\(\eta_0\)</span> é o valor inicial do passo, <span class="math inline">\(\Delta \eta\)</span> o valor do decaimento e <span class="math inline">\(\Delta k\)</span> o número de épocas em que o passo é mantido fixo. No caso da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (a), foram usados <span class="math inline">\(\eta_0=0,\!1\)</span>, <span class="math inline">\(\Delta \eta=0,\!0101\)</span> e <span class="math inline">\(\Delta k=20\)</span>.</p>
<p>No decaimento em escada com degraus não uniformes da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (b), o passo da <span class="math inline">\(k\)</span>-ésima época é calculado como</p>
<p><span class="math display">\[
\eta(k)=\eta_0\Delta \eta^{\lfloor k/\Delta k\rfloor}.
\]</span></p>
<p>No caso da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (b), foram usados <span class="math inline">\(\eta_0=0,\!1\)</span>, <span class="math inline">\(\Delta \eta=0,\!5\)</span> e <span class="math inline">\(\Delta k=20\)</span>.</p>
<p>Por fim, no decaimento exponencial da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (c), o passo da <span class="math inline">\(k\)</span>-ésima época é calculado como</p>
<p><span class="math display">\[
\eta(k)=\eta_0 e^{-a k},\;\;a&gt;0.
\]</span></p>
<p>No caso da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (c), foram usados <span class="math inline">\(\eta_0=0,\!1\)</span> e <span class="math inline">\(a=0,\!01\)</span>.</p>
<div id="fig-decaimento" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-decaimento-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/decaimento.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-decaimento-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5: <em>Learning rate annealing</em>: (a) decaimento em escada uniforme, (b) decaimento em escada não uniforme e (c) decaimento exponencial.
</figcaption>
</figure>
</div>
<p>O desafio de usar esquemas de ajuste dos passos de adaptação é que seus hiperparâmetros precisam ser definidos com antecedência e dependem da arquitetura da rede e do problema. Além disso, pode ser conveniente adaptar pesos de neurônios de camadas diferentes com passos distintos. Algoritmos de otimização como Adam e RMSprop resolvem esses problemas, pois ajustam os passos de adaptação de forma automática com o uso de regularização, como veremos posteriormente.</p>
</section>
<section id="mini-batch" class="level2">
<h2 class="anchored" data-anchor-id="mini-batch"><em>Mini-batch</em></h2>
<p>Abordamos anteriormente o treinamento do algoritmo LMS nos modos <em>batch</em>, <em>mini-batch</em> e estocástico<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Como o algoritmo LMS foi proposto para aplicações de tempo real, o modo estocástico é o mais utilizado. A cada dado de entrada se deseja ter o dado de saída correspondente com o menor atraso possível, ou seja, o treinamento ocorre junto com a inferência. A saída e o erro calculados no treinamento são utilizados para atualizar os pesos e ao mesmo tempo para se obter a estimativa ou classificação desejada.</p>
<p>No caso das redes neurais, o modo <em>mini-batch</em> é o mais utilizado. Geralmente, a inferência não é realizada durante o treinamento. A saída e o erro são utilizados no treinamento apenas para atualizar os pesos do algoritmo. Depois do treinamento, fixam-se os pesos para então se fazer a inferência e testar o classificador ou regressor. Apesar de termos abordado os três modos de treinamento apenas no algoritmo LMS, a extensão para redes neurais é direta.</p>
<p>O uso de <em>mini-batch</em> no processo de aprendizado consiste em dividir aleatoriamente o conjunto de treinamento da rede em blocos de tamanho previamente definido, embaralhando-se as amostras do conjunto. A atualização dos pesos e <em>biases</em> ocorre apenas depois que são calculados os gradientes de todos os elementos de um <em>mini-batch</em>. Dessa forma, a atualização dos parâmetros da rede está associada à média dos gradientes de um <em>mini-batch</em>. Considera-se passada uma época quando todos os <em>mini-batches</em> são percorridos. Após cada época do algoritmo de otimização, a divisão do conjunto de treinamento entre <em>mini-batches</em> é refeita de maneira aleatória, embaralhando-se novamente o conjunto de treinamento. <strong>O tamanho de cada <em>mini-batch</em> é um hiperparâmetro e não muda no decorrer das épocas.</strong></p>
<p>Quando se considera que cada <em>mini-batch</em> é formado apenas por uma amostra do conjunto de treinamento, diz-se que o método de atualização de parâmetros é estocástico. O uso do método estocástico para atualização de parâmetros de uma rede neural é pouco eficiente, pois a atualização ocorre em direções distintas do mínimo da função custo, o que faz com que o algoritmo leve mais épocas para convergir. O método estocástico também anula as vantagens computacionais de uma implementação matricial do algoritmo, uma vez que as atualizações são realizadas sobre cada amostra de treinamento.</p>
<p>Quando um <em>mini-batch</em> possui todos os elementos do conjunto de treinamento, nomeia-se o método de atualização de parâmetros apenas como <em>batch</em>. Com o método <em>batch</em>, os parâmetros são sempre atualizados na direção do mínimo da função custo. Diante disso, o <em>batch</em> seria o modo de treinamento ideal se não houvesse limitações computacionais. Como é necessário esperar que todo o conjunto de treinamento seja percorrido para se realizar a atualização dos parâmetros, o modo de treinamento <em>batch</em> é muito demorado e computacionalmente ineficiente quando comparado com o <em>mini-batch</em>.</p>
</section>
<section id="dropout" class="level2">
<h2 class="anchored" data-anchor-id="dropout"><em>Dropout</em></h2>
<p>Outro problema que pode aparecer no treinamento das redes neurais é o <em>overfitting</em>, que ocorre quando há uma diferença significativa entre o desempenho da rede sobre seu conjunto de treinamento e sobre um outro conjunto distinto de dados, o conjunto de teste. Neste caso, a rede se especializa tanto no conjunto de treinamento, que não apresenta capacidade de generalização satisfatória para outros dados. Uma das técnicas mais utilizadas para evitar esse problema é o <em>dropout</em>. Essa técnica basicamente inativa aleatoriamente, em cada iteração do algoritmo <em>backpropagation</em>, diferentes neurônios de cada camada oculta da rede. Cada neurônio é inativado com probabilidade <span class="math inline">\(p\)</span>, sendo <span class="math inline">\(p\)</span> o hiperparâmetro associado a essa esquema. Na <a href="#fig-dropout" class="quarto-xref">Figura&nbsp;6</a>, exemplifica-se a aplicação do <em>dropout</em> com <span class="math inline">\(p = 0,\!5\)</span>. Observe que metade dos neurônios de cada camada oculta (neurônios destacadas em vermelho) foram inativados em uma determinada iteração. Quando um neurônio é inativado, seu gradiente é nulo de modo que seus pesos não são atualizados. Heuristicamente, a eliminação temporária de diferentes conjuntos de neurônios leva ao treinamento de redes neurais distintas. Dessa forma, o procedimento de eliminação é equivalente ao cálculo da média dos efeitos de um grande número de redes distintas. Como elas vão se adaptar de diferentes maneiras, isso possibilita a redução do <em>overfitting</em>, pois será mais difícil para a rede se especializar nos dados de treinamento <span class="citation" data-cites="Goodfellow2016">(<a href="#ref-Goodfellow2016" role="doc-biblioref">Goodfellow, Bengio, e Courville 2016</a>)</span>.</p>
<div id="fig-dropout" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dropout-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/dropout.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dropout-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6: Exemplo de aplicação do <em>dropout</em> em uma rede MLP com <span class="math inline">\(p = 0,5\)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="momentum" class="level2">
<h2 class="anchored" data-anchor-id="momentum"><em>Momentum</em></h2>
<p>Como vimos anteriormente, o algoritmo LMS é uma aproximação estocástica do algoritmo do gradiente exato (<em>steepest descent</em>). Vimos também que existe um compromisso entre a velocidade de convergência e a precisão da solução. Quanto menor o passo de adaptação, mais lento é o algoritmo e os pesos variam menos em torno da solução de Wiener. Quanto maior o passo, maior a sua velocidade de convergência e maior também a variação dos pesos torno da solução ótima. O algoritmo também pode divergir dependendo do valor do passo e neste caso, os pesos vão para infinito. O mesmo acontece com o algoritmo <em>backpropagation</em>: quanto menor for o passo de adaptação, menores serão as mudanças nos pesos da rede de uma iteração para outra, mais suave será a trajetória no espaço dos pesos e mais lenta a taxa de aprendizagem. Se aumentarmos muito o passo de adaptação para acelerar a taxa de aprendizagem, as mudanças dos pesos de uma iteração para outra também aumentam e o algoritmo pode divergir.</p>
<p>Um método simples de aumentar a taxa de aprendizagem sem causar divergência é modificar a adaptação do <em>backpropagation</em> incluindo um termo chamado <em>momentum</em>. Antes de introduzir esse termo, vamos lembrar da atualização da matriz de pesos da Camada <span class="math inline">\(j\)</span> da MLP com o algoritmo <em>backpropagation</em>:</p>
<p><span class="math display">\[
\mathbf{W}^{(j)}(n)=\mathbf{W}^{(j)}(n-1)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(n),
\]</span></p>
<p>em que</p>
<p><span class="math display">\[
\boldsymbol{\Delta}_{\delta}^{(j)}(n)=\boldsymbol{\delta}^{(j)}(n)[\mathbf{x}^{(j)}(n)]^{\rm T}.
\]</span></p>
<p>Definindo agora a matriz <span class="math display">\[
\boldsymbol{\Delta}\mathbf{W}^{(j)}(n-1)\triangleq\mathbf{W}^{(j)}(n-1)-\mathbf{W}^{(j)}(n-2),
\]</span></p>
<p>que representa a diferença entre a matriz de pesos da iteração <span class="math inline">\(n-1\)</span> e da iteração <span class="math inline">\(n-2\)</span>, a atualização do <em>backpropagation</em> com <em>momentum</em> fica</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \mathbf{W}^{(j)}(n)=\mathbf{W}^{(j)}(n-1)+\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(n-1)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(n),
$}
\end{equation*}\]</span></p>
<p>em que <span class="math inline">\(0\leq \alpha&lt;1\)</span> é a constante de <em>momentum</em>. Observe que <span class="math inline">\(\alpha=0\)</span> leva essa atualização à forma padrão do <em>backpropagation</em> sem <em>momentum</em>. Usando a definição <span class="math inline">\(\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)\)</span>, podemos reescrever essa equação de atualização como</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \boldsymbol{\Delta}\mathbf{W}^{(j)}(n)=\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(n-1)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(n).
$}
\end{equation*}\]</span></p>
<p>Para entender o efeito do termo de <em>momentum</em>, note que</p>
<p><span class="math display">\[\begin{align*}
\boldsymbol{\Delta}\mathbf{W}^{(j)}(1)&amp;=\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(1)\nonumber\\
\boldsymbol{\Delta}\mathbf{W}^{(j)}(2)&amp;=\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(1)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(2)\nonumber\\
&amp;=\alpha\left[\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(1)\right]+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(2)\nonumber\\
&amp;=\alpha^2\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)+\eta\left[\alpha\boldsymbol{\Delta}_{\delta}^{(j)}(1)+\boldsymbol{\Delta}_{\delta}^{(j)}(2)\right]\nonumber\\
\boldsymbol{\Delta}\mathbf{W}^{(j)}(3)&amp;=\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(2)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(3)\nonumber\\
&amp;=\alpha^3\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)+\eta\left[\alpha^2\boldsymbol{\Delta}_{\delta}^{(j)}(1)+\alpha\boldsymbol{\Delta}_{\delta}^{(j)}(2)+\boldsymbol{\Delta}_{\delta}^{(j)}(3)\right]\nonumber\\
&amp;\vdots\nonumber\\
\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)&amp;=\alpha^n\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)+\eta\sum_{k=1}^n \alpha^{n-k}\boldsymbol{\Delta}_{\delta}^{(j)}(k).\nonumber
\end{align*}\]</span></p>
<p>O termo <span class="math inline">\(\alpha^n\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)\)</span> tende a zero a medida que o número de iterações aumenta, uma vez que <span class="math inline">\(0\leq\alpha&lt;1\)</span> e os pesos são inicializados com valores finitos. Assim, podemos escrever</p>
<p><span class="math display">\[
\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)=\eta\sum_{k=1}^n \alpha^{n-k}\boldsymbol{\Delta}_{\delta}^{(j)}(k).
\]</span></p>
<p>Essa equação nos possibilita entender os efeitos benéficos do <em>momentum</em>, enumerados a seguir <span class="citation" data-cites="Haykin2009">(<a href="#ref-Haykin2009" role="doc-biblioref">Haykin 2009</a>)</span>:</p>
<ul>
<li>o ajuste <span class="math inline">\(\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)\)</span> representa a soma de uma série temporal ponderada exponencialmente. Como <span class="math inline">\(0\leq \alpha&lt;1\)</span>, consideram-se pesos maiores para ajustes recentes e pesos menores para os mais antigos. Dessa forma, <span class="math inline">\(\alpha\)</span> também é chamado na literatura de fator de esquecimento;</li>
<li>quando o termo <span class="math inline">\(\boldsymbol{\Delta}_{\delta}^{(j)}(n)\)</span> tem o mesmo sinal algébrico em sucessivas iterações, a matriz <span class="math inline">\(\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)\)</span> cresce em magnitude e a matriz de pesos <span class="math inline">\(\mathbf{W}^{(j)}(n)\)</span> é ajustada com uma grande quantidade. Diante disso, o <em>momentum</em> tende a acelerar a convergência do <em>backpropagation</em> em direções de descida mais íngreme;</li>
<li>quando o sinal algébrico do termo <span class="math inline">\(\boldsymbol{\Delta}_{\delta}^{(j)}(n)\)</span> muda em sucessivas iterações, a matriz <span class="math inline">\(\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)\)</span> diminui em magnitude e a matriz de pesos <span class="math inline">\(\mathbf{W}^{(j)}(n)\)</span> é ajustada com uma pequena quantidade. Diante disso, o <em>momentum</em> tem o efeito de estabilizador em direções que oscilam em sinal.</li>
</ul>
<p>Em suma, a incorporação do <em>momentum</em> no algoritmo <em>backpropagation</em> pode trazer alguns efeitos benéficos no aprendizado, incluindo a possibilidade de evitar que o algoritmo fique estagnado em um mínimo local.</p>
<p>A seguir vamos comparar o <em>backpropagation</em> com e sem <em>momentum</em>.</p>
<section id="exemplo-das-meias-luas" class="level3">
<h3 class="anchored" data-anchor-id="exemplo-das-meias-luas">Exemplo das meias-luas</h3>
<p>No exemplo das meias-luas com <span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=-4\)</span> e <span class="math inline">\(r_3=6\)</span>, vimos que uma MLP com configuração <span class="math inline">\(2\)</span>-<span class="math inline">\(3(\text{tanh})\)</span>-<span class="math inline">\(2(\text{tanh})\)</span>-<span class="math inline">\(1(\text{tanh})\)</span> treinada com o <em>backpropagation</em> sem <em>momentum</em> é capaz de classificar corretamente os dados dependendo da inicialização. Para verificar o efeito benéfico de se utilizar <em>momentum</em>, vamos considerar uma MLP com configuração <span class="math inline">\(2\)</span>-<span class="math inline">\(3(\text{tanh})\)</span>-<span class="math inline">\(10(\text{tanh})\)</span>-<span class="math inline">\(1(\text{tanh})\)</span>. Essa mudança de configuração se deve ao fato de que o <em>backpropagation</em> com <em>momentum</em> na configuração anterior se comporta de maneira análoga ao caso sem <em>momentum</em>. Considerou-se ainda o modo de treinamento <em>mini-batch</em> (<span class="math inline">\(N_t=1000,\)</span> <span class="math inline">\(N_b=50\)</span> e <span class="math inline">\(N_e=2000\)</span>). Os pesos e <em>biases</em> foram inicializados com números aleatórios gerados a partir de uma distribuição uniforme no intervalo <span class="math inline">\([-10^{-2}, 10^{-2}]\)</span>, o passo de adaptação foi considerado fixo e igual a <span class="math inline">\(\eta=0,\!1\)</span> e a constante de momentum igual a <span class="math inline">\(\alpha=0,\!9\)</span>. Além disso, considerou-se a função custo do erro quadrático médio (MSE).</p>
<p>Na <a href="#fig-momentum" class="quarto-xref">Figura&nbsp;7</a>, são mostradas a função custo ao longo das épocas de treinamento, a classificação dos dados de teste e a separação das regiões para uma determinada inicialização. Verifica-se que o algoritmo <em>backpropagation</em> sem <em>momentum</em> não consegue escapar do mínimo local, obtendo <span class="math inline">\(7,\!9\%\)</span> de taxa de erro de classificação. Ao se utilizar <em>momentum</em>, percebe-se que o algoritmo apresenta um MSE próximo do caso sem <em>momentum</em> durante as <span class="math inline">\(450\)</span> épocas iniciais do treinamento. Depois disso, eles seguem caminhos diferentes: o algoritmo sem <em>momentum</em> fica parado no mínimo local correspondente a um MSE aproximadamente <span class="math inline">\(-7\)</span> dB, enquanto o algoritmo com <em>momentum</em> consegue atingir um MSE de aproximadamente <span class="math inline">\(-43\)</span> dB na época <span class="math inline">\(2000\)</span>. Isso é suficiente para não gerar erros de classificação.</p>
<div id="fig-momentum" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-momentum-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/momentum.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-momentum-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7: O problema de classificação das meias-luas (<span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=-4\)</span> e <span class="math inline">\(r_3=6\)</span>). Função custo ao longo das épocas de treinamento, classificação dos dados de teste (<span class="math inline">\(N_{\text{teste}}=2000\)</span>) e separação das regiões obtidas com uma rede MLP <span class="math inline">\(2\)</span>-<span class="math inline">\(3(\text{tanh})\)</span>-<span class="math inline">\(10(\text{tanh})\)</span>-<span class="math inline">\(1(\text{tanh})\)</span> treinada em <em>mini-batch</em> (<span class="math inline">\(N_t=1000\)</span>, <span class="math inline">\(N_b=50\)</span>) com o algoritmo <em>backpropagation</em> sem <em>momentum</em> (<span class="math inline">\(\eta=0,\!1\)</span>) e com <em>momentum</em> (<span class="math inline">\(\eta=0,1\)</span>, <span class="math inline">\(\alpha=0,\!9\)</span>); pesos e <em>biases</em> inicializados com números aleatórios gerados a partir de uma distribuição uniforme no intervalo <span class="math inline">\([-10^{-2}, 10^{-2}]\)</span>.
</figcaption>
</figure>
</div>
<p>O comportamento observado na <a href="#fig-momentum" class="quarto-xref">Figura&nbsp;7</a> nem sempre se repete, pois depende da inicialização. Em muitos casos, os algoritmos com e sem <em>momentum</em> apresentam comportamentos semelhantes. Ainda podem ocorrer situações em que o algoritmo com <em>momentum</em> não consegue evitar mínimos locais, enquanto o algoritmo sem <em>momentum</em> consegue. Apesar disso, o uso de <em>momentum</em> é considerado benéfico na maior parte das vezes. Isso de deve ao fato de que quando implementado junto com outras técnicas pode fazer com que a rede atinja valores de MSE mais baixos no treinamento, o que é indício de que mínimos locais foram evitados.</p>
</section>
</section>
<section id="otimizador-adam" class="level2">
<h2 class="anchored" data-anchor-id="otimizador-adam">Otimizador Adam</h2>
<p>A escolha do algoritmo de otimização é essencial em Aprendizado de Máquina. O algoritmo de otimização Adam (<em>adaptive moment estimation</em>) <span class="citation" data-cites="Adam2015">(<a href="#ref-Adam2015" role="doc-biblioref">Kingma e Ba 2015</a>)</span> é uma extensão do algoritmo do gradiente estocástico e tem sido muito utilizado recentemente. Ao introduzir o algoritmo, os autores listam os benefícios de se usar Adam em problemas de otimização não convexa:</p>
<ol type="1">
<li>simples de implementar, computacionalmente eficiente e requer poucos requisitos de memória;</li>
<li>adequado quando se usa muitos dados e/ou parâmetros;</li>
<li>apropriado para problemas não estacionários e problemas com gradientes muito ruidosos e/ou esparsos; e</li>
<li>os hiperparâmetros têm interpretação intuitiva e são simples de ajustar.</li>
</ol>
<p>O otimizador Adam atualiza os pesos e <em>biases</em> de uma rede neural a partir dos gradientes calculados na iteração atual e em iterações passadas, de forma a tornar mais estável o processo de aprendizado da rede, evitando-se assim variações excessivas em direções que não são a do mínimo da função custo. Ele combina o gradiente estocástico com <em>momentum</em> com o otimizador RMSprop (<em>root mean squared propagation</em>). Para introduzir esse otimizador, vamos antes introduzir o otimizador RMSprop.</p>
<p>À medida que os dados se propagam na rede, os gradientes calculados para atualização dos parâmetros podem ficar muito pequenos ou muito grandes. Gradientes muito pequenos podem levar à estagnação do <em>backpropagation</em>. Em contrapartida, gradientes muito grandes podem levar à divergência do algoritmo. O otimizador RMSprop foi proposto por G. Hinton, um dos “pais” do <em>backpropagation</em>, para lidar com esse problema usando uma média móvel dos gradientes ao quadrado. Isso gera uma normalização no algoritmo, que passa a ser encarado como um algoritmo de passo variável. Assim, quando os gradientes são grandes, o método diminui o passo para evitar a divergência e quando os gradientes são pequenos, ele aumenta o passo para evitar a estagnação. A título de curiosidade, o algoritmo RMSprop foi proposto por Hinton na sexta aula do curso <em>Neural Networks for Machine Learning</em> e diferente do Adam, não foi publicado.</p>
<p>Quando deduzimos o algoritmo <em>backpropagation</em>, definimos a matriz</p>
<p><span class="math display">\[
\boldsymbol{\Delta}_{\delta}^{(j)}(n)=\boldsymbol{\delta}^{(j)}(n)[\mathbf{x}^{(j)}(n)]^{\rm T},
\]</span></p>
<p>que contém o negativo dos vetores gradiente de todos os neurônios da Camada <span class="math inline">\(j\)</span>. Vamos agora definir a matriz <span class="math inline">\(\mathbf{S}^{(j)}(n)\)</span>, calculada recursivamente como</p>
<p><span class="math display">\[
\mathbf{S}^{(j)}(n) = \beta_2\mathbf{S}^{(j)}(n-1) + (1-\beta_2)\left[\boldsymbol{\Delta}_{\delta}^{(j)}(n)\right]^{\odot 2},
\]</span></p>
<p>em que <span class="math inline">\(\mathbf{S}^{(j)}(0)=\boldsymbol{0}\)</span>, <span class="math inline">\(0\ll \beta_2&lt; 1\)</span> é um hiperparâmetro que faz o papel de um fator de esquecimento e a operação <span class="math inline">\([\boldsymbol{\Delta}_{\delta}^{(j)}(n)]^{\odot 2}\)</span> indica que cada elemento da matriz <span class="math inline">\(\boldsymbol{\Delta}_{\delta}^{(j)}(n)\)</span> é elevado ao quadrado. Levando em conta a inicialização com valores nulos, a equação recursiva para a matriz <span class="math inline">\(\mathbf{S}^{(j)}(n)\)</span> pode ser reescrita como</p>
<p><span class="math display">\[
\mathbf{S}^{(j)}(n)=(1-\beta_2)\displaystyle \sum_{k=1}^{n}\beta_2^{n-k}\left[\boldsymbol{\Delta}_{\delta}^{(j)}(k)\right]^{\odot 2}.
\]</span></p>
<p>A menos da constante <span class="math inline">\((1-\beta_2)\)</span>, observa-se que essa estimativa considera pesos maiores para os gradientes ao quadrado mais recentes e pesos menores para os mais antigos, o que caracteriza uma janela exponencial. Utilizando a matriz <span class="math inline">\(\mathbf{S}^{(j)}(n)\)</span>, a atualização dos pesos e <em>biases</em> da Camada <span class="math inline">\(j\)</span> da rede segundo o otimizador RMSprop é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\mathbf{W}^{(j)}(n) = \mathbf{W}^{(j)}(n-1) + \eta\;{\boldsymbol{\Delta}_{\delta}^{(j)}(n)} \oslash \left[{\left[{\mathbf{S}}^{(j)}(n)\right]^{\odot \frac{1}{2}} + \varepsilon}\mathbf{1}\right],
$}
\end{equation*}\]</span></p>
<p>em que <span class="math inline">\(\oslash\)</span> se refere a divisão de Hadamard, que resulta em uma matriz em que cada elemento é igual à divisão do respectivo elemento da matriz à esquerda pelo respectivo elemento da matriz à direita, <span class="math inline">\(\varepsilon\)</span> é uma constante positiva pequena (e.g., <span class="math inline">\(\varepsilon=10^{-8}\)</span>) usada para evitar divisões por zero e <span class="math inline">\(\mathbf{1}\)</span> é uma matriz com todos os elementos iguais a 1 e dimensões adequadas para que a soma seja possível de ser calculada. Para entender melhor essas operações, suponha que na iteração <span class="math inline">\(n\)</span> dispomos das matrizes</p>
<p><span class="math display">\[
\boldsymbol{\Delta}_{\delta}^{(j)}(n)=\left[\begin{array}{cc}
                a &amp; b \\
                c &amp; d
              \end{array}
\right]\;\;\;\text{e}\;\;\; {\mathbf{S}}^{(j)}(n)=\left[\begin{array}{cc}
                 e &amp; f \\
                 g &amp; h
               \end{array}
\right].
\]</span></p>
<p>Assim,</p>
<p><span class="math display">\[
{\boldsymbol{\Delta}_{\delta}^{(j)}(n)} \oslash \left({\left[{\mathbf{S}}^{(j)}(n)\right]^{\odot \frac{1}{2}} + \varepsilon\mathbf{1}}\right)=\left[\begin{array}{ccc}
                 \displaystyle\frac{a}{\sqrt{e}+\varepsilon} &amp;&amp; \displaystyle\frac{b}{\sqrt{f}+\varepsilon} \\
                 &amp;&amp;\\
                 \displaystyle\frac{c}{\sqrt{g}+\varepsilon} &amp;&amp; \displaystyle\frac{d}{\sqrt{h}+\varepsilon}
               \end{array}
\right].
\]</span></p>
<p>Em vez de usar o negativo dos gradientes de <span class="math inline">\(\boldsymbol{\Delta}_{\delta}^{(j)}(n)\)</span>, o otimizador Adam também considera uma janela exponencial para estimar esses gradientes. Para isso, define-se a matriz</p>
<p><span class="math display">\[
\mathbf{V}^{(j)}(n) = \beta_1\mathbf{V}^{(j)}(n-1) + (1-\beta_1)\boldsymbol{\Delta}_{\delta}^{(j)}(n)
\]</span></p>
<p>em que <span class="math inline">\(\mathbf{V}^{(j)}(0)=\boldsymbol{0}\)</span> e <span class="math inline">\(0\ll \beta_1&lt; 1\)</span> é um hiperparâmetro que também faz o papel de um fator de esquecimento. Novamente, levando em conta a inicialização com valores nulos, a equação recursiva para <span class="math inline">\(\mathbf{V}^{(j)}(n)\)</span> pode ser reescrita como</p>
<p><span class="math display">\[
\mathbf{V}^{(j)}(n)=(1-\beta_1)\displaystyle \sum_{k=1}^{n}\beta_1^{n-k}\boldsymbol{\Delta}_{\delta}^{(j)}(k).
\]</span></p>
<p>As inicializações das matrizes <span class="math inline">\(\mathbf{S}^{(j)}\)</span> e <span class="math inline">\(\mathbf{V}^{(j)}\)</span> com elementos nulos podem gerar distorções no início do treinamento do algoritmo. Observe que na atualização do RMSprop, o valor da matriz <span class="math inline">\(\mathbf{S}^{(j)}(n)\)</span> para <span class="math inline">\(n=1\)</span> é <span class="math inline">\(\mathbf{S}^{(j)}(1)=(1-\beta_2)[\boldsymbol{\Delta}_{\delta}^{(j)}(1)]^{\odot 2}\)</span>, o que tende a ser muito pequeno já que <span class="math inline">\(0\ll \beta_2 &lt;1\)</span>. Para amenizar isso, são definidas as as matrizes de correção</p>
<p><span class="math display">\[\begin{align*}
\overline{\mathbf{V}}^{(j)}(n) &amp;= \frac{1}{1 - \beta_1^n}\,{\mathbf{V}^{(j)}(n)}\;\; \textnormal{e} \nonumber\\
\overline{\mathbf{S}}^{(j)}(n) &amp;= \frac{1}{1 - \beta_2^n}\,{\mathbf{S}^{(j)}(n)}. \nonumber
\end{align*}\]</span></p>
<p>Como <span class="math inline">\(0\ll \beta_1, \beta_2&lt;1\)</span>, as matrizes corrigidas <span class="math inline">\(\overline{\mathbf{V}}^{(j)}(n)\)</span> e <span class="math inline">\(\overline{\mathbf{S}}^{(j)}(n)\)</span> tendem às matrizes <span class="math inline">\({\mathbf{V}}^{(j)}(n)\)</span> e <span class="math inline">\({\mathbf{S}}^{(j)}(n)\)</span>, respectivamente, a medida que <span class="math inline">\(n\)</span> aumenta. Ou seja, o efeito da correção ocorre apenas no início do treinamento, como esperado. Utilizando essas matrizes corrigidas, a atualização dos pesos e <em>bias</em> da Camada <span class="math inline">\(j\)</span> da rede segundo o otimizador Adam é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\mathbf{W}^{(j)}(n) = \mathbf{W}^{(j)}(n-1) + \eta\;{\overline{\mathbf{V}}^{(j)}(n)} \oslash \left[{\left[{\overline{\mathbf{S}}^{(j)}(n)}\right]^{\odot \frac{1}{2}} + \varepsilon\mathbf{1}}\right].
$}
\end{equation*}\]</span></p>
<p>A seguir vamos comparar o <em>backpropagation</em> com o RMSprop e Adam.</p>
<section id="exemplo-das-meias-luas-1" class="level3">
<h3 class="anchored" data-anchor-id="exemplo-das-meias-luas-1">Exemplo das meias-luas</h3>
<p>No exemplo das meias-luas com <span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=-4\)</span> e <span class="math inline">\(r_3=6\)</span>, vimos que uma MLP com configuração <span class="math inline">\(2\)</span>-<span class="math inline">\(3(\text{tanh})\)</span>-<span class="math inline">\(2(\text{tanh})\)</span>-<span class="math inline">\(1(\text{tanh})\)</span> treinada com o <em>backpropagation</em> sem <em>momentum</em> é capaz de classificar corretamente os dados dependendo da inicialização. No entanto, quando consideramos uma rede mais profunda, a probabilidade do <em>backpropagation</em> de ficar parado em mínimos locais é alta. Como exemplo, vamos considerar uma MLP com cinco camadas e configuração <span class="math inline">\(2\)</span>-<span class="math inline">\(3(\text{tanh})\)</span>-<span class="math inline">\(4(\text{tanh})\)</span>-<span class="math inline">\(4(\text{tanh})\)</span>-<span class="math inline">\(2(\text{tanh})\)</span>-<span class="math inline">\(1(\text{tanh})\)</span> no modo de treinamento <em>mini-batch</em> (<span class="math inline">\(N_t=1000\)</span>, <span class="math inline">\(N_b=50\)</span> e <span class="math inline">\(N_e=5000\)</span>). Os pesos e <em>biases</em> foram inicializados com números aleatórios gerados a partir de uma distribuição uniforme no intervalo <span class="math inline">\([-10^{-2}, 10^{-2}]\)</span> e o passo de adaptação foi considerado fixo e igual a <span class="math inline">\(\eta=0,\!5\)</span> para todos os algoritmos. Além disso, considerou-se a função custo do erro quadrático médio (MSE). Por fim, os hiperparâmetros do algoritmo RMSprop foram selecionados como <span class="math inline">\(\beta_2=0,\!99\)</span> e <span class="math inline">\(\varepsilon=10^{-4}\)</span> e do Adam como <span class="math inline">\(\beta_1=\beta_2=0,\!99\)</span> e <span class="math inline">\(\varepsilon=10^{-4}\)</span>.</p>
<p>Na <a href="#fig-adam1" class="quarto-xref">Figura&nbsp;8</a>, na <a href="#fig-adam2" class="quarto-xref">Figura&nbsp;9</a> e na <a href="#fig-adam4" class="quarto-xref">Figura&nbsp;10</a>, são mostradas a função custo ao longo das épocas, a classificação dos dados de teste e a separação das regiões para três inicializações diferentes, respectivamente. Nos três casos, verifica-se que o algoritmo <em>backpropagation</em> sem <em>momentum</em>, denotado como SGD (<em>stochastic gradient</em>), não consegue escapar do mínimo local, obtendo <span class="math inline">\(50\%\)</span> de taxa de erro de classificação. No caso da <a href="#fig-adam1" class="quarto-xref">Figura&nbsp;8</a>, os comportamentos do RMSprop e do Adam são muito parecidos: ambos atingem um MSE de aproximadamente <span class="math inline">\(-100\)</span> dB no treinamento e apresentam taxas de erro de classificação iguais a zero. Mudando a inicialização, observamos na <a href="#fig-adam2" class="quarto-xref">Figura&nbsp;9</a> um comportamento diferente para o Adam, que apesar de escapar de um mínimo local logo depois da época <span class="math inline">\(3700\)</span>, apresenta um MSE que oscila em torno de <span class="math inline">\(-15\)</span> dB, o que levou a um erro de classificação de <span class="math inline">\(1\%\)</span>. Neste caso, o RMSprop atinge novamente um MSE de aproximadamente <span class="math inline">\(-100\)</span> dB no treinamento e mantém a taxa de erro de classificação igual a zero. Mudando novamente a inicialização, observamos na <a href="#fig-adam4" class="quarto-xref">Figura&nbsp;10</a> que o Adam atingiu novamente o patamar de <span class="math inline">\(-100\)</span> dB no treinamento e <span class="math inline">\(0\%\)</span> de taxa de erro de classificação. Já o RMSprop ficou parado em um mínimo local que levou a um MSE de aproximadamente <span class="math inline">\(-7\)</span> dB e a uma taxa de erro de classificação de <span class="math inline">\(5,\!5\%\)</span>.</p>
<p>A partir desse experimento, verifica-se que mudar o algoritmo de otimização é benéfico para evitar mínimos locais, principalmente quando comparamos o RMSprop e o Adam com o SGD em redes profundas. No entanto, a adoção de um desses algoritmos de otimização apenas não é suficiente para evitar mínimos locais, como vimos na <a href="#fig-adam2" class="quarto-xref">Figura&nbsp;9</a> e na <a href="#fig-adam4" class="quarto-xref">Figura&nbsp;10</a>. Considerando o Adam e o RMSprop, observa-se na literatura que o Adam tem sido preferido na maior parte das aplicações. No entanto, o Adam tem algumas desvantagens:</p>
<ol type="1">
<li>não converge adequadamente em alguns exemplos simples, como pudemos comprovar no exemplo da <a href="#fig-adam2" class="quarto-xref">Figura&nbsp;9</a>;</li>
<li>o erro de generalização pode ser grande em muitos problemas de visão computacional;</li>
<li>requer mais memória que o método do gradiente (SGD); e</li>
<li>tem dois hiperparâmetros e portanto, alguns ajustes podem ser necessários.</li>
</ol>
<div id="fig-adam1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-adam1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/adam1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-adam1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8: O problema de classificação das meias-luas (<span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=-4\)</span> e <span class="math inline">\(r_3=6\)</span>). Função custo ao longo das épocas de treinamento, classificação dos dados de teste (<span class="math inline">\(N_{\text{teste}}=2000\)</span>) e separação das regiões obtidas com uma rede MLP <span class="math inline">\(2\)</span>-<span class="math inline">\(3(\text{tanh})\)</span>-<span class="math inline">\(4(\text{tanh})\)</span>-<span class="math inline">\(4(\text{tanh})\)</span>-<span class="math inline">\(2(\text{tanh})\)</span>-<span class="math inline">\(1(\text{tanh})\)</span> treinada em <em>mini-batch</em> (<span class="math inline">\(N_t=1000\)</span>, <span class="math inline">\(N_b=50\)</span>) com o algoritmo SGD (<span class="math inline">\(\eta=0,5\)</span>), RMSprop (<span class="math inline">\(\eta=0,5\)</span>, <span class="math inline">\(\beta_2=0,99\)</span>, <span class="math inline">\(\varepsilon=10^{-4}\)</span>) e Adam (<span class="math inline">\(\eta=0,5\)</span>, <span class="math inline">\(\beta_1=\beta_2=0,99\)</span>, <span class="math inline">\(\varepsilon=10^{-4}\)</span>); pesos e <em>biases</em> inicializados com números aleatórios gerados a partir de uma distribuição uniforme no intervalo <span class="math inline">\([-10^{-2}, 10^{-2}]\)</span>.
</figcaption>
</figure>
</div>
<div id="fig-adam2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-adam2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/adam2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-adam2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;9: Veja legenda da <a href="#fig-adam1" class="quarto-xref">Figura&nbsp;8</a>.
</figcaption>
</figure>
</div>
<div id="fig-adam4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-adam4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/adam4.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-adam4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;10: Veja legenda da <a href="#fig-adam1" class="quarto-xref">Figura&nbsp;8</a>.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="validação-cruzada" class="level2">
<h2 class="anchored" data-anchor-id="validação-cruzada">Validação cruzada</h2>
<p>A essência do aprendizado de uma rede MLP com o algoritmo <em>backpropagation</em> é aproximar um mapeamento entrada-saída por meio dos pesos e <em>biases</em>, utilizado um conjunto de exemplos rotulados. Espera-se que a rede aprenda o suficiente com os dados do passado e que seja capaz de generalizar para dados futuros. No processo de aprendizagem, é importante selecionar a “melhor” rede (número de camadas, número de neurônios, funções de ativação, passo de adaptação, etc.) dentro de um conjunto de redes candidatas, considerando um determinado critério. Além disso, o MSE tende a diminuir monotonicamente ao longo das épocas de treinamento. Em geral, quanto maior o número de épocas, mais baixo é o MSE. No entanto, um MSE baixo no treinamento não corresponde necessariamente a um desempenho satisfatório da rede com o conjunto de teste, ou seja, pode haver <em>overfitting</em>. A pergunta que cabe fazer aqui é: quando devemos parar de treinar já que um treinamento longo pode gerar <em>overfitting</em>?</p>
<p>Para responder essa pergunta e selecionar a melhor rede, é comum utilizar um conjunto de dados de validação. Neste caso, o conjunto de dados disponível deve ser primeiramente particionado de maneira aleatória entre treinamento e teste. O conjunto de treinamento, por sua vez, deve ser particionado em dois subconjuntos disjuntos:</p>
<ol type="1">
<li>subconjunto de estimação, usado para treinar o modelo;</li>
<li>subconjunto de validação, usado para testar o modelo durante o treinamento.</li>
</ol>
<p>A ideia de usar um conjunto de validação distinto do conjunto de treinamento e de teste é validar o modelo durante o treinamento com um conjunto de dados diferente do utilizado para estimar os parâmetros. A avaliação final do modelo para observar sua capacidade de generalização deve ser sempre feita com os dados do conjunto de teste, que não foram usados durante o treinamento, considerando fixos os pesos e <em>biases</em> da rede.</p>
<p>Normalmente, uma rede MLP treinada com o algoritmo <em>backpropagation</em> aprende em etapas, passando da realização de funções de mapeamento simples para funções de mapeamento mais complexas à medida que o treinamento avança. Esse processo pode ser verificado pela diminuição do MSE ao longo das épocas de treinamento: ele começa com um valor alto, diminui rapidamente e depois continua a diminuir lentamente quando a rede atinge um mínimo local da superfície de erro. Como o principal objetivo é obter uma rede com uma boa capacidade de generalização, é muito difícil descobrir quando parar de treinar, baseando-se apenas na curva de aprendizado do treinamento. Em particular, é possível que ocorra <em>overfitting</em> se o treinamento não for interrompido no ponto certo.</p>
<p>Podemos identificar o começo do <em>overfitting</em> por meio da validação cruzada (<em>cross-validation</em>). O subconjunto de exemplos de estimação é usado para treinar a rede da maneira usual, exceto por uma pequena modificação: o treinamento é interrompido periodicamente depois de um determinado número de épocas e e a rede é testada com o subconjunto de validação. Mais especificamente, o “processo de estimação seguido de validação” periódico ocorre da seguinte forma <span class="citation" data-cites="Haykin2009">(<a href="#ref-Haykin2009" role="doc-biblioref">Haykin 2009</a>)</span>:</p>
<ol type="1">
<li>após um intervalo de treinamento - a cada cinco épocas, por exemplo - os pesos e <em>biases</em> da MLP são mantidos fixos e apenas o cálculo progressivo é realizado. O erro de validação é então medido para cada exemplo do subconjunto de validação;</li>
<li>quando a fase de validação é concluída, o treinamento é retomado em um novo intervalo e o processo é repetido.</li>
</ol>
<p>Na <a href="#fig-validacao" class="quarto-xref">Figura&nbsp;11</a> são mostradas duas curvas de aprendizado: uma obtida com o subconjunto de estimação (treinamento) e outra obtida com os dados do subconjunto de validação. Normalmente, o modelo não se sai tão bem no subconjunto de validação quanto no subconjunto de estimação. A curva de aprendizado de estimação diminui monotonicamente ao longo das épocas. Em contrapartida, a curva de validação diminui monotonicamente até um ponto de mínimo e a partir deste ponto começa a aumentar à medida que o o treinamento continua. Observando a curva de aprendizado de estimação, pode parecer que seria melhor continuar o treinamento além do ponto de mínimo da curva de validação. No entanto, o que a rede está aprendendo além desse ponto é essencialmente o ruído contido nos dados de treinamento, o que leva ao <em>overfitting</em>. Diante disso, o treinamento deve ser interrompido quando a curva de validação atinge seu valor mínimo.</p>
<div id="fig-validacao" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-validacao-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/validacao.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-validacao-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;11: Curvas de erro de estimação e validação. O treinamento deve parar na época correspondente ao mínimo da curva de erro de validação. Fonte: Figura adaptada de <span class="citation" data-cites="Haykin2009">(<a href="#ref-Haykin2009" role="doc-biblioref">Haykin 2009</a>)</span>.
</figcaption>
</figure>
</div>
<p>A validação cruzada descrita anteriormente é conhecida como <em>holdout method</em>. Existem outras variantes da validação cruzada na literatura. Uma das mais utilizadas é a conhecida como <em>multifold cross-validation</em>, que é particularmente útil quando os exemplos de treinamento são escassos <span class="citation" data-cites="Leite2020">(<a href="#ref-Leite2020" role="doc-biblioref">Leite 2020</a>)</span>. Nesse método, o conjunto de treinamento disponível de <span class="math inline">\(N_t\)</span> exemplos é dividido em <span class="math inline">\(K\)</span> subconjuntos com <span class="math inline">\(K&gt;1\)</span>, sendo <span class="math inline">\(N_t\)</span> divisível por <span class="math inline">\(K\)</span>. O modelo é treinado com todos os subconjuntos exceto um e o erro de validação é medido testando o modelo no subconjunto que é deixado de fora. Este procedimento é repetido <span class="math inline">\(K\)</span> vezes, cada vez usando um subconjunto diferente para validação, conforme ilustrado na <a href="#fig-kfold" class="quarto-xref">Figura&nbsp;12</a> para <span class="math inline">\(K=5\)</span>. O desempenho do modelo é avaliado pela média do erro quadrado de validação em todas as tentativas do experimento. A desvantagem dessa variante é o custo computacional envolvido, uma vez que o modelo tem que ser treinado <span class="math inline">\(K\)</span> vezes, sendo <span class="math inline">\(1&lt;K\leq N_t\)</span>.</p>
<div id="fig-kfold" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-kfold-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/kfold.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-kfold-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12: <em>Multifold cross-validation</em>: para cada treinamento, o subconjunto de dados destacado em azul é usado para validar o modelo treinado com os dados destacados em magenta. <a href="https://drigols.medium.com/">[Fonte]</a>
</figcaption>
</figure>
</div>
<p>A validação cruzada é útil não só para evitar <em>overfitting</em>, mas também para validar a arquitetura da rede. Dessa forma, uma vez definido o número de camadas de uma rede MLP, por exemplo, o modelo de treinamento e validação da <a href="#fig-kfold" class="quarto-xref">Figura&nbsp;12</a> pode ser utilizado para verificar se o número de camadas é adequado com base no erro de validação. Se o erro de validação cai nos <span class="math inline">\(K\)</span> treinamentos, então o número de camadas parece ser adequado. Isso também pode ser utilizado para comparar redes MLP com diferentes arquiteturas para ajudar na escolha da arquitetura mais adequada.</p>
</section>
<section id="normalização" class="level2">
<h2 class="anchored" data-anchor-id="normalização">Normalização</h2>
<p>Suponha que se deseja prever se um paciente tem ou não uma determina doença com base em determinadas medidas diagnósticas, incluídas no conjunto de dados. Considere que um dos dados é o ácido úrico, cujos valores de referência estão no intervalo <span class="math inline">\([3,4,\; 7,0]~\rm{mg/dL}\)</span> e um outro dado é o número de plaquetas, cujos valores de referência estão no intervalo <span class="math inline">\([151.000,\; 304.000]/{\rm mm}^3\)</span>. Esses diferentes intervalos tornam o treinamento mais desafiador. Por exemplo, considere um regressor com uma única camada e dois pesos, em que os dois dados de entrada possuem faixas de valores muito diferentes. Alterações no valor de um dos pesos produzem mudanças muito maiores na saída e na função de erro do que mudanças semelhantes no outro peso. Nessa situação, pode ser benéfico mudar a escala das variáveis de entrada para que fiquem em intervalos semelhantes. Vamos ver três técnicas a seguir.</p>
<section id="dimensionamento-linear" class="level3">
<h3 class="anchored" data-anchor-id="dimensionamento-linear">Dimensionamento linear</h3>
<p>Nessa técnica, os valores dos dados de entrada são normalizados para que fiquem em um intervalo padrão, geralmente <span class="math inline">\([0,\; 1]\)</span> ou <span class="math inline">\([-1, 1]\)</span>. Como antes, considere que o conjunto de dados tenha <span class="math inline">\(N\)</span> elementos, organizados como uma sequência de <span class="math inline">\(M\)</span> valores de <span class="math inline">\(x\)</span>, ou seja, <span class="math display">\[
\{(x_{11}, x_{21}, \cdots, x_{M1}), (x_{12}, x_{22}, \cdots, x_{M2}),\cdots, (x_{1N}, x_{2N}, \cdots, x_{MN})\}.
\]</span> Para normalização no intervalo <span class="math inline">\([0,\; 1]\)</span>, basta fazer <span class="math display">\[
\widetilde{x}_{kn}=\frac{x_{kn}-x_{k,\text{min}}}{x_{k,\text{max}}-x_{k,\text{min}}},
\]</span> <span class="math inline">\(k=1,2, \cdots, M\)</span>, <span class="math inline">\(n=1,2,\cdots, N\)</span>, <span class="math inline">\(x_{k,\text{min}}=\min\{x_{kn}\}_{n=1}^N\)</span> e <span class="math inline">\(x_{k,\text{max}}=\max\{x_{kn}\}_{n=1}^N\)</span>. Considerando a normalização no intervalo <span class="math inline">\([-1,\; 1]\)</span>, basta fazer <span class="math display">\[
\widetilde{\widetilde{x}}_{kn}=2\widetilde{x}_{kn}-1.
\]</span> Essa normalização é uma boa opção quando os dados seguem uma distribuição aproximadamente uniforme em todo o intervalo.</p>
<p>Dependendo da distribuição dos dados, pode ser útil considerar um dimensionamento logarítmico, em que <span class="math inline">\(\widetilde{x}_{kn}=\ln(x_{kn})\)</span>. Esse tipo de normalização é utilizado quando a distribuição dos recursos é muito assimétrica em pelo menos um dos lados da cauda. Por exemplo, quando os dados apresentam uma distribuição exponencial.</p>
</section>
<section id="média-zero-e-variância-unitária" class="level3">
<h3 class="anchored" data-anchor-id="média-zero-e-variância-unitária">Média zero e variância unitária</h3>
<p>A fim de reescalar os dados de entrada para pertencerem a intervalos semelhantes é comum normalizá-los para que tenham média zero e variância unitária. Para isso, calcula-se primeiramente a média e variância dos dados, ou seja, <span class="math display">\[
\mu_k=\frac{1}{N}\sum_{n=1}^{N}x_{kn}
\]</span> e <span class="math display">\[
\sigma_k^2=\frac{1}{N}\sum_{n=1}^{N}(x_{kn}-\mu_k)^2.
\]</span> Em seguida, considera-se <span class="math display">\[
\widetilde{x}_{kn}=\frac{x_{kn}-\mu_k}{\sigma_k}.
\]</span></p>
<p>Na <span class="citation" data-cites="fighistnorm1">(<a href="#ref-fighistnorm1" role="doc-biblioref"><strong>fighistnorm1?</strong></a>)</span> são mostrados dois histogramas: o histograma da esquerda representa a distribuição dos valores de plaquetas de um conjunto de pacientes e à direita o histograma dos valores dessa característica normalizados.</p>
<div id="fighistnorm1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/histnorm1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Histograma de dados de plaquetas não normalizados (à direita) e normalizados com média zero e variância unitária (à esquerda).</figcaption>
</figure>
</div>
<p>Essa normalização é uma boa opção quando os dados seguem uma distribuição normal ou próxima de normal. No entanto, é comum também considerá-la em casos de distribuição não normal.</p>
</section>
<section id="corte" class="level3">
<h3 class="anchored" data-anchor-id="corte">Corte</h3>
<p>O corte é uma técnica utilizada para minimizar a influência de <em>outliers</em> extremos. Diferente do truncamento, que simplesmente ignora valores de <em>outliers</em>, o corte substitui os valores que aparecem fora do intervalo de maior ocorrência pelo valor máximo desse intervalo. Considere por exemplo o histograma mostrado na <span class="citation" data-cites="fighistnorm2">(<a href="#ref-fighistnorm2" role="doc-biblioref"><strong>fighistnorm2?</strong></a>)</span>, à esquerda. É possível observar que o intervalo de maior ocorrência dos valores dessa característica é <span class="math inline">\([150, 450]\)</span>. No entanto, há valores acima de 450, que podem ser considerados *outliers. A normalização por corte substitui todos os valores acima de 450 por 450 e por isso aparece um pico nesse valor, como mostrado no histograma na <span class="citation" data-cites="fighistnorm2">(<a href="#ref-fighistnorm2" role="doc-biblioref"><strong>fighistnorm2?</strong></a>)</span>, à direita. O corte impede que o modelo utilize dados sem importância.</p>
<div id="fighistnorm2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/histnorm2.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Histograma de dados não normalizados (à direita) e normalizados pelo corte.</figcaption>
</figure>
</div>
</section>
<section id="normalização-em-lote" class="level3">
<h3 class="anchored" data-anchor-id="normalização-em-lote">Normalização em lote</h3>
<p>Além de normalizar os dados de entrada, é importante também normalizar as entradas das funções de ativação ou as saídas das camadas ocultas de uma rede neural. Se houver grande variação na faixa de valores das variáveis de uma determinada camada oculta, então normalizar esses valores para que tenham média zero e variância unitária deve tornar o problema de aprendizado mais fácil para a próxima camada. No entanto, diferentemente da normalização dos valores de entrada, que pode ser feita uma única vez antes do início do treinamento, a normalização dos valores das variáveis das camadas ocultas precisa ser repetida durante o treinamento, toda vez que os valores dos pesos forem atualizados. Isso é chamado de normalização em lote <em>batch normalization</em>, proposta por Ioffe e Szegedy em 2015. Uma motivação adicional para a <em>batch normalization</em> surge dos fenômenos de desvanecimento ou explosão dos gradientes, que costumam ocorrer no treinamento de redes neurais profundas.</p>
<p>Para entender como a <em>batch normalization</em> é definida, considere uma camada oculta <span class="math inline">\(j\)</span> de uma rede MLP com múltiplas camadas. A saída do neurônio <span class="math inline">\(k\)</span> dessa camada é dada por <span class="math inline">\(y_k^{(j)}=\varphi_j(v_k^{(j)})\)</span>. Portanto, temos a opção de normalizar os valores de <span class="math inline">\(v_k^{(j)}\)</span> ou os valores de saída <span class="math inline">\(y_k^{(j)}\)</span>, <span class="math inline">\(k=1, 2, \cdots, N_j\)</span> da camada <span class="math inline">\(j\)</span>. Na prática, qualquer uma das abordagens pode ser utilizada, e aqui ilustramos o procedimento normalizando os valores de <span class="math inline">\(v_k^{(j)}\)</span>.</p>
<p>Como os valores dos pesos são atualizados após cada <em>mini-batch</em>, aplica-se a normalização a cada <em>mini-batch</em>. Especificamente, para um mini-batch de tamanho <span class="math inline">\(N_b\)</span>, definem-se <span class="math display">\[\mu_k^{(j)}=\frac{1}{N_b}\sum_{n=1}^{N_b}v_{k,n}^{(j)}\]</span> e <span class="math display">\[
{\sigma_k^{(j)}}^2=\frac{1}{N_b}\sum_{n=1}^{N_b}\left(v_{k,n}^{(j)}-\mu_k^{(j)}\right)^2.
\]</span> Em seguida, considera-se <span class="math display">\[
\widetilde{v}_{k,n}^{(j)}=\frac{v_{k,n}^{(j)}-\mu_k^{(j)}}{\sqrt{{\sigma_k^{(j)}}^2+\delta}},
\]</span> em que as somas levam em conta variáveis de um dado mini-batch já que <span class="math inline">\(n=1,2,\cdots, N_b\)</span> e <span class="math inline">\(\delta\)</span> é uma constante pequena utilizada para evitar problemas numéricos quando <span class="math inline">\({\sigma_k^{(j)}}^2\)</span> for pequeno.</p>
<p>Ao normalizar os valores de <span class="math inline">\(v_k^{(j)}\)</span> em uma determinada camada da rede, reduzimos o número de graus de liberdade nos parâmetros dessa camada e, consequentemente, diminuímos sua capacidade de representação. Podemos compensar isso reescalando os valores de <span class="math inline">\(\widetilde{v}_{k,n}^{(j)}\)</span> do <em>mini-batch</em> para que tenham média <span class="math inline">\(\beta_k^{(j)}\)</span> e desvio padrão <span class="math inline">\(\gamma_k^{(j)}\)</span>, usando <span class="math display">\[
\overset{\approx}{v}_{k,n}^{(j)}=\gamma_k^{(j)}\widetilde{v}_{k,n}^{(j)}+\beta_k^{(j)},
\]</span> em que onde <span class="math inline">\(\beta_k^{(j)}\)</span> e <span class="math inline">\(\gamma_k^{(j)}\)</span> são parâmetros adaptativos aprendidos com o método do gradiente juntamente com os pesos e vieses da rede. Esses parâmetros ajustáveis representam uma diferença fundamental em relação à normalização dos dados de entrada.</p>
<p>Pode parecer que essa transformação simplesmente desfaz o efeito da normalização, já que a média e a variância agora podem novamente se adaptar a valores arbitrários. No entanto, a diferença crucial está na forma como os parâmetros evoluem durante o treinamento. Na rede original, a média e a variância em um <em>mini-batch</em> são determinadas por uma função complexa de todos os pesos e vieses da camada, enquanto na transformação com os parâmetros <span class="math inline">\(\beta_k^{(j)}\)</span> e <span class="math inline">\(\gamma_k^{(j)}\)</span>, elas são determinadas diretamente por esses parâmetros independentes, que acabam sendo mais fáceis de aprender durante a descida do gradiente.</p>
<p>A <em>batch normalization</em> pode ser vista como uma camada adicional na rede neural, de modo que cada camada oculta padrão pode ser seguida por uma camada de normalização em <em>mini-batch</em>. Uma vez que a rede foi treinada e queremos fazer previsões sobre novos dados, não temos mais disponíveis os <em>mini-batches</em> de treinamento e, portanto, não podemos determinar a média e a variância a partir de apenas um exemplo de dado. Para resolver isso, poderíamos, em princípio, calcular <span class="math inline">\(\mu_k^{(j)}\)</span> e <span class="math inline">\({\sigma_k^{(j)}}^2\)</span> para cada camada em todo o conjunto de treinamento após realizarmos a atualização final dos pesos e vieses. No entanto, isso exigiria processar todo o conjunto de dados apenas para avaliar essas quantidades e, portanto, costuma ser muito custoso. Em vez disso, calculam-se médias móveis de <span class="math inline">\(\mu_k^{(j)}\)</span> e <span class="math inline">\({\sigma_k^{(j)}}^2\)</span> ao longo do treinamento.</p>
<p>Embora a <em>batch normalization</em> seja muito eficaz na prática, há incerteza sobre por que ela funciona tão bem. Essa normalização foi originalmente motivada pela observação de que atualizações nos pesos das camadas anteriores da rede alteram a distribuição dos valores vistos pelas camadas posteriores, um fenômeno chamado de deslocamento interno de covariáveis (<em>internal covariate shift</em>). No entanto, estudos posteriores (Santurkar et al., 2018) sugerem que o deslocamento de covariáveis não é um fator significativo e que a melhoria no treinamento resulta, na verdade, de uma maior suavidade na função de erro.</p>
<div hidden="">
[<span class="citation" data-cites="bihop2024">(<a href="#ref-bihop2024" role="doc-biblioref"><strong>bihop2024?</strong></a>)</span>]<span class="citation" data-cites="google_mlcc_normalization">(<a href="#ref-google_mlcc_normalization" role="doc-biblioref">Google Developers 2023</a>)</span>
</div>
</section>
</section>
</div>





<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">Referências</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-BaydinJMLR2018" class="csl-entry" role="listitem">
Baydin, Atılım G., Barak A. Pearlmutter, Alexey A. Radul, e Jeffrey M. Siskind. 2018. <span>“Automatic Differentiation in Machine Learning: a Survey”</span>. <em>Journal of Machine Learning Research</em> 18: 1–43.
</div>
<div id="ref-Bishop_book2006" class="csl-entry" role="listitem">
Bishop, C. M. 2006. <em>Pattern recognition and machine learning</em>. Springer.
</div>
<div id="ref-JasonInit2021" class="csl-entry" role="listitem">
Brownlee, Jason. 2021. <em>Weight Initialization for Deep Learning Neural Networks</em>. <a href="https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/" class="uri">https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/</a>.
</div>
<div id="ref-Xavier2010" class="csl-entry" role="listitem">
Glorot, Xavier, e Yoshua Bengio. 2010. <span>“Understanding the difficulty of training deep feedforward neural networks”</span>. Em <em>Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</em>, 249–56.
</div>
<div id="ref-Goodfellow2016" class="csl-entry" role="listitem">
Goodfellow, Ian, Yoshua Bengio, e Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press,&nbsp;<a href="http://www.deeplearningbook.org" class="uri">http://www.deeplearningbook.org</a>.
</div>
<div id="ref-google_mlcc_normalization" class="csl-entry" role="listitem">
Google Developers. 2023. <span>“Dados numéricos: normalização | Machine Learning Crash Course”</span>. <a href="https://developers.google.com/machine-learning/crash-course/numerical-data/normalization?hl=pt-br">https://developers.google.com/machine-learning/crash-course/numerical-data/normalization?hl=pt-br</a>.
</div>
<div id="ref-Haykin2009" class="csl-entry" role="listitem">
Haykin, Simon. 2009. <em>Neural networks and learning machines</em>. 3rd ed. Pearson.
</div>
<div id="ref-He2015" class="csl-entry" role="listitem">
He, Kaiming, Xiangyu Zhang, Shaoqing Ren, e Jian Sun. 2015. <span>“Delving deep into rectifiers: surpassing human-level performance on <span>I</span>mage<span>N</span>et classification”</span>. Em <em>Proceedings of the IEEE International Conference on Computer Vision (ICCV)</em>, 1026–34.
</div>
<div id="ref-Jordan2018learning" class="csl-entry" role="listitem">
Jordan, Jeremy. 2018. <em>Setting the learning rate of your neural network</em>. <a href="https://www.jeremyjordan.me/nn-learning-rate/" class="uri">https://www.jeremyjordan.me/nn-learning-rate/</a>.
</div>
<div id="ref-Adam2015" class="csl-entry" role="listitem">
Kingma, Diederik P., e Jimmy Ba. 2015. <em>Adam: A Method for Stochastic Optimization</em>. <a href="https://arxiv.org/abs/1412.6980" class="uri">https://arxiv.org/abs/1412.6980</a>.
</div>
<div id="ref-Leite2020" class="csl-entry" role="listitem">
Leite, Rodrigo. 2020. <em>Introdução a Validação-Cruzada: K-Fold</em>. <a href="https://drigols.medium.com/introdu%C3%A7%C3%A3o-a-valida%C3%A7%C3%A3o-cruzada-k-fold-2a6bced32a90" class="uri">https://drigols.medium.com/introdu%C3%A7%C3%A3o-a-valida%C3%A7%C3%A3o-cruzada-k-fold-2a6bced32a90</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Notas de rodapé</h2>

<ol>
<li id="fn1"><p>Alguns autores utilizem o termo “sigmoidal” para uma classe de funções em que a logística e a tangente hiperbólica são exemplos. Neste texto, vamos utilizar o termo “sigmoidal” apenas para a função logística.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>O termo <em>estocástico</em> é utilizado aqui para se referir ao modo de treinamento em que cada exemplo de treinamento individual é utilizado para fazer uma iteração de adaptação dos coeficientes.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script>
var custom_title = document.querySelectorAll('.custom .theorem-title');

for (let i = 0; i < custom_title.length; i++ ) {
   var mod_name = custom_title[i].innerHTML;
   custom_title[i].innerHTML = mod_name.replace("Exemplo", "Algoritmo");
};
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiada");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiada");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>