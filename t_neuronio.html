<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pt-br" xml:lang="pt-br"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>O modelo do neurônio – PSI5892</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e0b2e4e5c4db31b3b64fdef51415d7d2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nenhum resultado",
    "search-matching-documents-text": "documentos correspondentes",
    "search-copy-link-title": "Copiar link para a busca",
    "search-hide-matches-text": "Esconder correspondências adicionais",
    "search-more-match-text": "mais correspondência neste documento",
    "search-more-matches-text": "mais correspondências neste documento",
    "search-clear-button-title": "Limpar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Procurar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">PSI5892</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Procurar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Alternar de navegação" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teoria" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Teoria</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-teoria">    
        <li>
    <a class="dropdown-item" href="./t_introducao.html">
 <span class="dropdown-text">Introdução</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_regressao_linear.html">
 <span class="dropdown-text">Regressão linear</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_lms.html">
 <span class="dropdown-text">O algoritmo LMS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_neuronio.html">
 <span class="dropdown-text">O modelo do neurônio</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_mlp.html">
 <span class="dropdown-text">A rede perceptron multicamada</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_hiperparametros.html">
 <span class="dropdown-text">Evitando mínimos locais e <em>overfitting</em></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_autodiff.html">
 <span class="dropdown-text">Introdução à diferenciação automática</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_pytorch_topicos.html">
 <span class="dropdown-text">Tópicos sobre o <em>framework</em> PyTorch</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_pytorch_exemplo_mlp.html">
 <span class="dropdown-text">Implementação da rede MLP com PyTorch</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_medidas.html">
 <span class="dropdown-text">Medidas de desempenho</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_pca.html">
 <span class="dropdown-text">Análise de Componentes Principais</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_lda.html">
 <span class="dropdown-text">Análise de Discriminantes Lineares</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-material-de-apoio" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Material de apoio</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-material-de-apoio">    
        <li>
    <a class="dropdown-item" href="./ap_python_topicos.html">
 <span class="dropdown-text">Tópicos de programação com Python</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">O modelo do neurônio</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="justify">
<section id="o-perceptron-de-rosenblatt" class="level2">
<h2 class="anchored" data-anchor-id="o-perceptron-de-rosenblatt">O perceptron de Rosenblatt</h2>
<p>Para introduzir o perceptron de Rosenblatt, vamos voltar ao exemplo das meias-luas, em que o algoritmo LMS foi utilizado para classificar os dados como pertencentes à Região A ou Região B, como mostrado na <a href="#fig-meiasluas" class="quarto-xref">Figura&nbsp;1</a>, repetida aqui por conveniência.</p>
<div id="fig-meiasluas" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-meiasluas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/meiasluas.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-meiasluas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1: O problema de classificação das meias-luas <span class="citation" data-cites="Haykin2009">(<a href="#ref-Haykin2009" role="doc-biblioref">Haykin 2009</a>)</span>.
</figcaption>
</figure>
</div>
<p>Para <span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=1\)</span>, <span class="math inline">\(r_3=6\)</span>, <span class="math inline">\(\mu=10^{-3}\)</span> e <span class="math inline">\(M=2\)</span>, a saída do LMS no modo estocástico (<span class="math inline">\(N_t=5000\)</span>, <span class="math inline">\(N_b=1\)</span> e <span class="math inline">\(N_e=1\)</span>) está mostrada na Figura <a href="#fig-saidalms" class="quarto-xref">Figura&nbsp;2</a>. Nesta aplicação, considerou-se como sinal desejado <span class="math inline">\(d=+1\)</span> para dados pertencentes à Região A e <span class="math inline">\(d=-1\)</span> para os pertencentes à Região B. Com os pesos e <em>bias</em> da última iteração, o LMS consegue classificar os dados com uma taxa de erros de aproximadamente 0,6% por meio de uma separação linear entre as regiões. Apesar disso, a saída do algoritmo fica espalhada no intervalo <span class="math inline">\([-1,\!5\;\; 1,\!5],\)</span> não havendo uma clara separação em torno do zero.</p>
<div id="fig-saidalms" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-saidalms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/SaidaLMS.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-saidalms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2: Saída do algoritmo LMS (<span class="math inline">\(\eta=10^{-3}\)</span> e <span class="math inline">\(M=2\)</span>) durante o treinamento no modo estocástico (<span class="math inline">\(N_t=5000\)</span>, <span class="math inline">\(N_b=1\)</span> e <span class="math inline">\(N_e=1\)</span>) utilizado no problema de classificação das meias-luas (<span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=1\)</span> e <span class="math inline">\(r_3=6\)</span>).
</figcaption>
</figure>
</div>
<p>Diferente do LMS, o perceptron de Rosenblatt força a saída <span class="math inline">\(y(n)\)</span> a assumir valores do conjunto <span class="math inline">\(\{-1,\; +1\}.\)</span> Para isso, ele introduz uma função não linear <span class="math inline">\(\varphi(\cdot)\)</span> à saída do combinador. No caso, a função <span class="math inline">\(\varphi(\cdot)\)</span> é um limitador abrupto (<em>hard limiter</em>), dado por</p>
<p><span class="math display">\[
\varphi(v)=\text{sgn}(v)=\left\{\begin{array}{cc}
                      +1, &amp; v\geq 0 \\
                      -1, &amp; v&lt;0
                    \end{array},
\right.
\]</span></p>
<p>em que <span class="math inline">\(\text{sgn}(\cdot)\)</span> representa a função sinal, como mostrado na <a href="#fig-sinal" class="quarto-xref">Figura&nbsp;3</a>.</p>
<div id="fig-sinal" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sinal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/Sinal.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sinal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3: Função sinal.
</figcaption>
</figure>
</div>
<p>Considerando o <span class="math inline">\(n\)</span>-ésimo vetor dos dados de treinamento</p>
<p><span class="math display">\[
\mathbf{x}(n)=[\,1\;x_{1n}\; x_{2n}\; \cdots\; x_{Mn}\,]^{\rm T}
\]</span></p>
<p>e o vetor de pesos e <em>bias</em> com dimensão <span class="math inline">\(M+1\)</span></p>
<p><span class="math display">\[
\mathbf{w}(n) = [\,b(n)\;w_1(n)\;\cdots\;w_M(n)\,]^{\rm T},
\]</span></p>
<p>a saída do combinador linear pode ser escrita como</p>
<p><span class="math display">\[
v(n) = \mathbf{x}^{\rm T}(n)\mathbf{w}(n-1)
\]</span></p>
<p>e a saída do perceptron de Rosenblatt é dada por</p>
<p><span class="math display">\[
y(n)=\varphi(v(n))=\text{sgn}(v(n)).
\]</span></p>
<p>Observe que devido à função sinal, <span class="math inline">\(y(n)\in \{-1,\;+1\}\)</span>. O diagrama de fluxo de sinal do perceptron de Rosenblatt está mostrado na <a href="#fig-rosenblatt" class="quarto-xref">Figura&nbsp;4</a>.</p>
<div id="fig-rosenblatt" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rosenblatt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/Rosenblatt.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rosenblatt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;4: Fluxo de sinal do perceptron de Rosenblatt.
</figcaption>
</figure>
</div>
<p>Como no algoritmo LMS, os pesos são atualizados para minimizar o erro quadrático <span class="math inline">\(e^2(n)\)</span>, em que</p>
<p><span class="math display">\[
e(n)=d(n)-\varphi(\mathbf{x}^{\rm T}(n)\mathbf{w}(n-1))=d(n)-{\text{sgn}}(v(n))=d(n)-y(n).
\]</span></p>
<p>Observe que <span class="math inline">\(e(n)\)</span> assume agora três valores possíveis: <span class="math inline">\(-2\)</span> ou <span class="math inline">\(+2\)</span> quando <span class="math inline">\(d(n)\neq y(n)\)</span> e <span class="math inline">\(0\)</span> quando <span class="math inline">\(d(n)=y(n)\)</span>. Como a função sinal não é derivável em todos os pontos, não é possível obter o algoritmo de maneira formal, como feito na dedução do algoritmo LMS. Além disso, note que</p>
<p><span class="math display">\[
\frac{\partial e(n)}{\partial \mathbf{w}(n-1)}=-\frac{\partial \text{sgn}(\mathbf{x}^{\rm T}(n)\mathbf{w}(n-1))}{\partial \mathbf{w}(n-1)}=-\mathbf{x}(n)\,{\text{sgn}'}(v(n))=\left\{\begin{array}{cc}
                                         \boldsymbol{0}, &amp; v(n)\neq 0 \\
                                         \nexists, &amp; v(n)=0. \\
                                       \end{array}
\right.
\]</span></p>
<p>Ignorando o fato da derivada não existir para <span class="math inline">\(v(n)=0\)</span>, os pesos não seriam atualizados se utilizássemos esse resultado, uma vez que o vetor gradiente é nulo para <span class="math inline">\(v(n)\neq 0\)</span>. Por isso, utiliza-se a equação de atualização</p>
<p><span class="math display">\[
\mathbf{w}(n)=\mathbf{w}(n-1)+\eta e(n)\mathbf{x}(n).
\]</span></p>
<p>Assim, os pesos são atualizados apenas quando <span class="math inline">\(e(n)\neq 0\)</span>, ou seja, quando <span class="math inline">\(y(n)\neq d(n)\)</span>. Caso contrário, <span class="math inline">\(\mathbf{w}(n)=\mathbf{w}(n-1)\)</span>. O passo de adaptação <span class="math inline">\(\eta\)</span>, também chamado de taxa de aprendizado, é uma constante positiva que deve ser escolhida no intervalo <span class="math inline">\(0&lt;\eta\leq 1\)</span>. Como no caso do LMS, a escolha desse passo deve sempre levar em conta o compromisso entre estimativas mais precisas dos pesos e velocidade de aprendizado. A prova de convergência desse algoritmo para <span class="math inline">\(\eta=1\)</span> pode ser encontrada, por exemplo, em <span class="citation" data-cites="Haykin2009">(<a href="#ref-Haykin2009" role="doc-biblioref">Haykin 2009</a>)</span>. Considerando a formulação matricial e o modo de treinamento <em>mini-batch</em><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, o pseudocódigo do algoritmo de treinamento do perceptron de Rosenblatt é mostrado no <a href="#exm-rosenmbatch" class="quarto-xref">Algoritmo&nbsp;1</a>.</p>
<div class="box">
<div id="exm-rosenmbatch" class="custom theorem example">
<p><span class="theorem-title"><strong>Exemplo 1</strong></span> Sumário do algoritmo de treinamento do perceptron de Rosenblatt no modo <em>mini-batch</em>. <span class="math inline">\(N_e\)</span> é o número de épocas, <span class="math inline">\(N_b\)</span> o tamanho do mini-batch, <span class="math inline">\(N_t\)</span> o número de dados de treinamento e <span class="math inline">\(N_{mb}= \lfloor N_t/N_b \rfloor\)</span> o número de <em>mini-batches</em> por época.</p>
<p>Inicialização: <span class="math inline">\(\mathbf{w}(0)=\boldsymbol{0}\)</span><br>    Para <span class="math inline">\(k=1,2,\ldots, N_e\)</span>, calcule:<br>      Misture os dados de treinamento<br>      Organize os dados na matriz <span class="math inline">\(\mathbf{X}(\ell)\)</span> e no vetor <span class="math inline">\(\mathbf{d}(\ell)\)</span> para <span class="math inline">\(\ell=0, 1,2,\ldots, N_{mb}-1\)</span><br>      Para <span class="math inline">\(\ell=0, 1,2,\ldots, N_{mb} - 1\)</span> calcule:<br>       <span class="math inline">\(m=(k-1)N_{mb}+\ell+1\)</span><br>       <span class="math inline">\(\mathbf{v}_{m-1}(\ell)=\mathbf{X}(\ell)\mathbf{w}(m-1)\)</span><br>       <span class="math inline">\(\mathbf{y}_{m-1}(\ell)=\text{sgn}(\mathbf{v}_{m-1}(\ell))\)</span><br>       <span class="math inline">\(\mathbf{e}_{m-1}(\ell)=\mathbf{d}(\ell)-{\mathbf y}_{m-1}(\ell)\)</span><br>       <span class="math inline">\(\mathbf{w}(m)=\mathbf{w}(m-1)+\displaystyle\frac{\eta}{N_b}\mathbf{X}^{\rm T}(\ell)\mathbf{e}_{m-1}(\ell)\)</span><br>      Fim<br>    Fim</p>
</div>
</div>
<p>Voltando ao exemplo das meias-luas, vamos considerar agora a solução obtida pelo perceptron de Rosenblatt no modo de treinamento <em>batch</em> com <span class="math inline">\(M=2\)</span> e considerando <span class="math inline">\(\eta=10^{-3}\)</span>, <span class="math inline">\(N_t=5000\)</span>, <span class="math inline">\(N_b=N_t\)</span> e <span class="math inline">\(N_e=50\)</span>. Na <a href="#fig-jmsesepd1" class="quarto-xref">Figura&nbsp;5</a> são mostrados a função custo ao longo das épocas, os dados de teste e a separação linear das regiões no caso de <span class="math inline">\(r_2=1\)</span>. Observa-se neste caso que a função custo converge para zero e a separação obtida proporciona uma solução com taxa de erro nula. Para <span class="math inline">\(r_2=-4\)</span>, uma condição que viola a separabilidade linear, os resultados estão mostrados na <a href="#fig-jmsesepdm4" class="quarto-xref">Figura&nbsp;6</a>. Neste caso, observa-se que a função custo não converge mais para zero. Ela varia continuamente, indicando o “colapso” do algoritmo. Isso faz com que parte dos pontos da Região A sejam classificados erroneamente como pertencentes à Região B e vice-versa ao se utilizar os pesos e <em>bias</em> da última iteração, o que leva a uma taxa de erro de aproximadamente <span class="math inline">\(12\%\)</span>.</p>
<div id="fig-jmsesepd1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-jmsesepd1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/JMSESepd1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-jmsesepd1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5: O problema de classificação das meias-luas (<span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=1\)</span> e <span class="math inline">\(r_3=6\)</span>). Função custo ao longo das épocas de treinamento (figura à esquerda); Dados de teste (<span class="math inline">\(N_{\text{teste}}=2000\)</span>) e separação das regiões (figura à direita) obtida com o perceptron de Rosenblatt treinado em <em>batch</em> (<span class="math inline">\(M=2\)</span>, <span class="math inline">\(\eta=10^{-3}\)</span>, <span class="math inline">\(N_t=5000\)</span>, <span class="math inline">\(N_b=N_t\)</span> e <span class="math inline">\(N_e=50\)</span>).
</figcaption>
</figure>
</div>
<div id="fig-jmsesepdm4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-jmsesepdm4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/JMSESepdm4.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-jmsesepdm4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6: O problema de classificação das meias-luas (<span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=-4\)</span> e <span class="math inline">\(r_3=6\)</span>). Função custo ao longo das épocas de treinamento (figura à esquerda); Dados de teste (<span class="math inline">\(N_{\text{teste}}=2000\)</span>) e separação das regiões (figura à direita) obtida com o perceptron de Rosenblatt treinado em <em>batch</em> (<span class="math inline">\(M=2\)</span>, <span class="math inline">\(\eta=10^{-3}\)</span>, <span class="math inline">\(N_t=5000\)</span>, <span class="math inline">\(N_b=N_t\)</span> e <span class="math inline">\(N_e=50\)</span>).
</figcaption>
</figure>
</div>
<p>Comparando o perceptron de Rosenblatt com o algoritmo LMS, percebe-se que ambos podem ser descritos pelo modelo da <a href="#fig-rosenblatt" class="quarto-xref">Figura&nbsp;4</a>. A única diferença é a função utilizada na saída do combinador linear. Como vimos, no perceptron de Rosenblatt utiliza-se <span class="math inline">\(\varphi(v)={\rm sgn}(v)\)</span>, enquanto no LMS considera-se <span class="math inline">\(\varphi(v)=v\)</span>. Em termos de convergência, o sinal de erro utilizado no perceptron de Rosenblatt é limitado, pois <span class="math inline">\(e(n)\in \{-2,\; 0,\; 2\}\)</span>, o que não ocorre no algoritmo LMS. Isso faz com que o perceptron de Rosenblatt não sofra divergência desde que as entradas sejam limitadas. O mesmo não se pode afirmar sobre o algoritmo LMS, pois o sinal de erro não é limitado. Dependendo do valor do passo de adaptação <span class="math inline">\(\eta\)</span>, o LMS pode divergir. Apesar dessa diferença, ambos levam a fronteiras de separação que são retas (ou hiperplanos no caso em que <span class="math inline">\(M\geq 2\)</span>). Essas soluções são boas apenas quando há separabilidade linear, o que no exemplo das meias-luas ocorre para <span class="math inline">\(r_2=1\)</span>, mas não ocorre para <span class="math inline">\(r_2=-4\)</span>. Para gerar uma fronteira não linear, podemos usar uma rede neural, como será visto posteriormente. Antes de vermos que o perceptron de Rosenblatt é um dos primeiros modelos de neurônio, unidade básica de uma rede neural, vamos tratar a seguir da regressão logística.</p>
</section>
<section id="regressão-logística-para-classificação-binária" class="level2">
<h2 class="anchored" data-anchor-id="regressão-logística-para-classificação-binária">Regressão logística para classificação binária</h2>
<p>A adaptação dos pesos do perceptron de Rosenblatt não levam em conta a derivada da função <span class="math inline">\(\varphi(v)\)</span>, uma vez que essa função tem derivada nula para <span class="math inline">\(v\neq 0\)</span> e não é definida para <span class="math inline">\(v=0\)</span>. Em vez de usar a função sinal no perceptron de Rosenblatt, poderíamos considerar uma função <span class="math inline">\(\varphi(v)\)</span> com derivada definida e não nula para todo <span class="math inline">\(v\)</span>. Neste caso, teríamos <span class="math display">\[
e(n)=d(n)-\varphi({\mathbf{x}^{\rm T}}(n)\mathbf{w}(n-1))=d(n)-\varphi(v(n))=d(n)-y(n),
\]</span> cuja derivada em relação a <span class="math inline">\(\mathbf{w}(n-1)\)</span> é <span class="math display">\[
\frac{\partial e(n)}{\partial \mathbf{w}(n-1)}=-\frac{\partial \varphi(\mathbf{x}^{\rm T}(n)\mathbf{w}(n-1))}{\partial \mathbf{w}(n-1)}=-\mathbf{x}(n)\,{\varphi'}(v(n)).
\]</span> Considerando a minimização do erro quadrático instantâneo como no LMS, temos o vetor gradiente dado por <span class="math display">\[
\widehat{\boldsymbol{\nabla}}_{\mathbf{w}}J_{\text{MSE}}=2e(n)\frac{\partial e(n)}{\partial \mathbf{w}(n-1)}=-2e(n)\,{\varphi'}(v(n))\,\mathbf{x}(n).
\]</span> Assim, o vetor de pesos no modo estocástico deve ser adaptado como <span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\mathbf{w}(n)=\mathbf{w}(n-1)+\eta\, e(n)\,{\varphi'}(v(n))\,\mathbf{x}(n).
$}
\end{equation*}\]</span></p>
<p>A minimização do erro quadrático pode levar o algoritmo a ficar parado em mínimos locais. Uma alternativa é usar a entropia cruzada, definida como <span class="math display">\[  
J_{\rm EC} = -  \left[ d(n) \ln\left({y(n)}\right) + [1 - d(n)] \ln{\left(1 -y(n)\right)}\right].
\]</span> Lembrando que <span class="math inline">\(v(n)=\mathbf{x}^{\rm T}(n)\mathbf{w}(n-1)\)</span> e que <span class="math inline">\(y(n)=\varphi(v(n))\)</span>, chega-se ao seguinte gradiente <span class="math display">\[
\begin{align*}
\widehat{\boldsymbol{\nabla}}_{\mathbf{w}}J_{\text{EC}}=&amp;-\frac{d(n)}{y(n)}\frac{\partial y(n)}{\partial \mathbf{w}(n-1)}+\frac{1-d(n)}{1-y(n)}\frac{\partial y(n)}{\partial \mathbf{w}(n-1)}\nonumber\\
=&amp;-\frac{e(n)}{y(n)(1-y(n))}\frac{\partial y(n)}{\partial \mathbf{w}(n-1)}\nonumber\\
=&amp;-\frac{e(n)}{y(n)(1-y(n))}\,\varphi'(v(n))\,\mathbf{x}(n).\nonumber
\end{align*}
\]</span> Assim, o vetor de pesos no modo estocástico deve ser adaptado como <span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\mathbf{w}(n)=\mathbf{w}(n-1)+\eta\, \frac{e(n)\varphi'(v(n))}{y(n)(1-y(n))}\mathbf{x}(n).
$}
\end{equation*}\]</span></p>
<p>Em um problema de classificação binária com rótulos iguais a 0 ou 1, uma possível candidata para a função <span class="math inline">\(\varphi(\cdot)\)</span> que apresenta derivada não nula e definida em todos os pontos é a função sigmoidal, também conhecida como função logística. Essa função é definida como <span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\varphi(v)={\rm sgm}(v)=\displaystyle\frac{1}{1+e^{-v}}
$}
\end{equation*}\]</span> e tem derivada dada por <span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\varphi'(v)=\frac{\rm d}{{\rm d}v}{\rm sgm}(v)=\displaystyle \frac{e^{-v}}{\left[1+e^{-v}\right]^2}=  \varphi(v)[1-\varphi(v)]=y(1-y),
$}
\end{equation*}\]</span> em que se usou o fato da saída do neurônio ser <span class="math inline">\(y=\varphi(v)\)</span>. Na <a href="#fig-sigmoide" class="quarto-xref">Figura&nbsp;7</a> são mostrados gráficos da função sigmoidal e de sua derivada. Pode-se observar que a saída do neurônio com função sigmoidal fica no intervalo <span class="math inline">\([0,\; 1]\)</span>. Caso os rótulos sejam iguais a <span class="math inline">\(-1\)</span> e <span class="math inline">\(1\)</span>, pode-se considerar a função tangente hiperbólica, dada por <span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\varphi(v)={\rm tanh}(v)=\frac{e^{v}-e^{-v}}{e^{v}+e^{-v}},
$}
\end{equation*}\]</span> cuja derivada é <span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\varphi'(v)=\frac{\rm d}{{\rm d}v}{\rm tanh}(v)=\left[1-{\rm tanh}^2(v)\right]=(1-y)(1+y),
$}
\end{equation*}\]</span> em que se usou o fato da saída do neurônio ser igual a <span class="math inline">\(y={\rm tanh}(v)\)</span>. Na <a href="#fig-tanh" class="quarto-xref">Figura&nbsp;8</a> são mostrados gráficos da tangente hiperbólica e de sua derivada.</p>
<div id="fig-sigmoide" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sigmoide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/sgmoide1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sigmoide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7: Função logística e sua derivada.
</figcaption>
</figure>
</div>
<div id="fig-tanh" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tanh-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/tanh1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tanh-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8: Função tangente hiperbólica e sua derivada.
</figcaption>
</figure>
</div>
<p>Vamos agora obter quatro formas de adaptar os pesos levando em conta as funções logística (sgm) e tangente hiperbólica (tanh) e as funções custo do erro quadrático médio (MSE) e da entropia cruzada (EC): <span class="math display">\[
\begin{align*}
&amp;\text{MSE, sgm:}\;\;\; \mathbf{w}(n)=\mathbf{w}(n-1)+\eta e(n)y(n)[1-y(n)]\mathbf{x}(n)\\
&amp;\text{EC, sgm:}\;\;\;\;\;\, \mathbf{w}(n)=\mathbf{w}(n-1)+\eta e(n)\mathbf{x}(n)\\
&amp;\text{MSE, tanh:}\;\; \mathbf{w}(n)=\mathbf{w}(n-1)+\eta e(n)[1+y(n)][1-y(n)]\mathbf{x}(n)\\
&amp;\text{EC, tanh:}\;\;\;\;\, \mathbf{w}(n)=\mathbf{w}(n-1)+\eta e(n)\!\left(1+\frac{1}{y(n)}\right)\mathbf{x}(n).
\end{align*}
\]</span> A equação obtida com EC e sgm é conhecida na literatura como <strong>regressão logística</strong> para o caso binário. As demais podem ser interpretadas como variantes. Cabe observar que na equação obtida com EC e tanh aparece o termo <span class="math inline">\(1/y(n)\)</span>, o que pode levar a divisão por <span class="math inline">\(0\)</span>. Para evitar isso, pode-se somar uma constante pequena em <span class="math inline">\(y(n),\)</span> o que acaba alterando a dinâmica do algoritmo. Por isso, essa equação não é muito utilizada e o que se faz é mapear os rótulos iguais a <span class="math inline">\(-1\)</span> em <span class="math inline">\(0\)</span> para se utilizar as versões do algoritmo obtidas com a função logística.</p>
<p>Para exemplificar, vamos considerar novamente o problema de classificação binária com as meias-luas com <span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=-4\)</span> e <span class="math inline">\(r_3=6\)</span>, mas agora os rótulos da Região B foram mapeados de <span class="math inline">\(-1\)</span> para <span class="math inline">\(0\)</span> a fim de se utilizar as equações obtidas anteriormente com a função logística. Os resultados utilizando o modo de treinamento <em>mini-batch</em> podem ser vistos na <a href="#fig-RLog1" class="quarto-xref">Figura&nbsp;9</a> e na <a href="#fig-RLog2" class="quarto-xref">Figura&nbsp;10</a>, considerando a minimização do MSE e da EC, respectivamente. Os pesos e <em>bias</em> obtidos na minimização de cada função custo são diferentes, mas a separação das regiões são similares e levam a uma taxa de erro de aproximadamente <span class="math inline">\(8\%\)</span>. Apesar dessa taxa ser um pouco menor que a obtida com o neurônio de Rosenblatt, a separação continua linear.</p>
<div id="fig-RLog1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-RLog1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/Rlog1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-RLog1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;9: O problema de classificação das meias-luas (<span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=1\)</span> e <span class="math inline">\(r_3=6\)</span>). Pesos e <em>bias</em> ao longo das épocas de treinamento (figura à esquerda); Dados de teste (<span class="math inline">\(N_{\text{teste}}=2000\)</span>) e separação das regiões (figura à direita) obtida com a regressão logística que minimiza o MSE; modo <em>mini-batch</em> (<span class="math inline">\(M=2\)</span>, <span class="math inline">\(\eta=10^{-2}\)</span>, <span class="math inline">\(N_t=5000\)</span>, <span class="math inline">\(N_b=10\)</span> e <span class="math inline">\(N_e=100\)</span>); Taxa de erro de <span class="math inline">\(8,15\%\)</span>.
</figcaption>
</figure>
</div>
<div id="fig-RLog2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-RLog2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/Rlog2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-RLog2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;10: O problema de classificação das meias-luas (<span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=1\)</span> e <span class="math inline">\(r_3=6\)</span>). Pesos e ao longo das épocas de treinamento (figura à esquerda); Dados de teste (<span class="math inline">\(N_{\text{teste}}=2000\)</span>) e separação das regiões (figura à direita) obtida com a regressão logística que minimiza a EC; modo (<span class="math inline">\(M=2\)</span>, <span class="math inline">\(\eta=10^{-2}\)</span>, <span class="math inline">\(N_t=5000\)</span>, <span class="math inline">\(N_b=10\)</span> e <span class="math inline">\(N_e=100\)</span>); Taxa de erro de <span class="math inline">\(8,25\%\)</span>.
</figcaption>
</figure>
</div>
<p>Na literatura a regressão logística é abordada sob o ponto de vista probabilístico como, por exemplo, em <span class="citation" data-cites="Bishop_book2006">(<a href="#ref-Bishop_book2006" role="doc-biblioref">Bishop 2006</a>)</span>. Nessa referência, também é abordado o caso multiclasse.</p>
</section>
<section id="o-neurônio-biológico-e-um-pouco-de-história" class="level2">
<h2 class="anchored" data-anchor-id="o-neurônio-biológico-e-um-pouco-de-história">O neurônio biológico e um pouco de história</h2>
<p>No início do século passado, o médico e histologista espanhol Ramón y Cajál foi o primeiro a introduzir a ideia dos neurônios como unidades básicas do sistema nervoso. Os neurônios são células altamente especializadas na transmissão de informações na forma de pulsos nervosos. As ligações entre os neurônios são chamadas de sinapses, que tem por função enviar sinais por transmissões sinápticas para ocorrer ações específicas no corpo. A taxa dessas transmissões é considerada baixa quando comparada com portas lógicas de silício. Eventos em um chip de silício acontecem na faixa de nanossegundos, enquanto os eventos neurais acontecem na faixa de milissegundos. No entanto, essa taxa “baixa” é compensada pelo impressionante número de neurônios existentes no sistema nervoso humano, estimado em mais de 86 bilhões. Em termos de sinapses, esse número aumenta para mais de 60 trilhões. O resultado final é que o cérebro é uma estrutura extremamente eficiente.</p>
<p>O neurônio biológico está esquematizado na <a href="#fig-neuron" class="quarto-xref">Figura&nbsp;11</a>. A atividade do neurônio é caracterizada por pulsos elétricos da ordem de milivolts e duração da ordem de milissegundos. Ele recebe esses pulsos de outros neurônios pelos seus dendritos. Se o sinal acumulado exceder um certo valor, um pulso é enviado via axônio aos seus terminais, que por sua vez, se acoplam a outros neurônios. Grosso modo, a computação realizada por um neurônio na sua saída (no seu axônio) pode ser resumida na frequência dos pulsos. Se houver poucos pulsos por unidade de tempo, o neurônio é considerado pouco ativo. Em contrapartida, se ele tiver muitos pulsos por unidade de tempo, haverá mais estímulos sinápticos e o músculo que o neurônio controla, por exemplo, é forçado a uma atividade maior.</p>
<div id="fig-neuron" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-neuron-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/neuron.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-neuron-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;11: Neurônio biológico. Fonte: adaptado de <span class="citation" data-cites="DurrBook2020">(<a href="#ref-DurrBook2020" role="doc-biblioref">Dürr e Sick 2020</a>)</span>.
</figcaption>
</figure>
</div>
<p>Redes neurais surgiram para buscar modelar o cérebro humano. Nos anos de surgimento das redes neurais (1943-1960), vários pesquisadores se destacam por suas contribuições pioneiras <span class="citation" data-cites="Haykin2009">(<a href="#ref-Haykin2009" role="doc-biblioref">Haykin 2009</a>)</span>:</p>
<ol type="1">
<li>McCulloch e Pitts (1943) por introduzirem a ideia de redes neurais como máquinas de computação;</li>
<li>Hebb (1949) por postular a primeira regra de aprendizagem auto-organizada;</li>
<li>Rosenblatt (1958) por propor o perceptron como o primeiro modelo de aprendizagem supervisionada;</li>
<li>Widrow e Hoff (1960) por propor o Adaline (<em>adaptive linear element</em>), que deu origem ao algoritmo LMS.</li>
</ol>
<p>Inspirado no funcionamento do neurônio biológico, Rosenblatt propôs o modelo de neurônio artificial, chamado de perceptron, como ilustrado na <a href="#fig-rosenblatt" class="quarto-xref">Figura&nbsp;4</a>. O neurônio biológico recebe vários estímulos de outros neurônios que chegam por seus dendritos, esses estímulos são então acumulados e se exceder um limiar, o neurônio gera um estímulo no seu axônio que são transmitidos a outros neurônios. No modelo matemático de Rosenblatt, esses estímulos são representados pelo vetor de entrada <span class="math inline">\(\mathbf{x}(n)\)</span> e o acúmulo dos estímulos pela soma ponderada da entrada com os pesos, gerando o sinal <span class="math inline">\(v(n)\)</span>. Se <span class="math inline">\(v(n)&lt;0\)</span>, o neurônio estará em repouso. Caso contrário, estará ativo e um novo estímulo, representado por <span class="math inline">\(y(n)\)</span>, é gerado. Aqui cabe uma observação: para representar o neurônio em repouso, talvez fosse mais adequado considerar a função degrau (função de Heaviside) em vez da função sinal. Assim, <span class="math inline">\(y(n)=0\)</span> para <span class="math inline">\(v(n)&lt;0\)</span>. No entanto, pensando na implementação do modelo com um circuito analógico, pode ser mais adequado considerar uma tensão negativa em vez de uma tensão nula para representar o repouso e para isso, a função sinal se mostrou mais adequada.</p>
<p>Em julho de 1958, o escritório de Pesquisa Naval dos EUA revelou uma invenção notável. Um IBM 704, um computador de 5 toneladas que ocupava uma sala, foi alimentado com uma série de cartões perfurados. Após 50 tentativas, o computador aprendeu a distinguir os cartões marcados à esquerda dos cartões marcados à direita. Foi uma demonstração do perceptron de Rosenblatt, a primeira máquina capaz de ter uma ideia original. Na época, Rosenblatt era psicólogo pesquisador e engenheiro de projetos no Laboratório Aeronáutico da Cornell em Buffalo, Nova York. “As histórias sobre a criação de máquinas com qualidades humanas têm sido fascinantes em ficção científica. No entanto, estamos prestes a testemunhar o nascimento de tal máquina - uma máquina capaz de perceber, reconhecer e identificar seus arredores sem qualquer treinamento ou controle humano”, escreveu Rosenblatt em 1958. Ele estava certo, mas levou aproximadamente meio século para vermos isso acontecer. Na <a href="#fig-rosen" class="quarto-xref">Figura&nbsp;12</a>, são mostradas uma imagem do título da publicação de Rosenblatt de 1958 e uma foto de Rosenblatt em 1960 com seu perceptron chamado de Mark I, uma máquina eletromecânica implementava os pesos adaptativos por meio de potenciômetros que eram ajustados por atuadores.</p>
<div id="fig-rosen" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rosen-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/Rosen.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rosen-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12: Publicação de Rosenblatt de 1958 (à esquerda) e foto de Rosenblatt e seu perceptron chamado de Mark I em 1960 (à direita) <a href="https://paslongtemps.net/blog/2020/05/29/frank-rosenblatt-mark-i-perceptron-1960-dnvdk/">[Fonte]</a>.
</figcaption>
</figure>
</div>
<p>Desde 1960, muita pesquisa foi feita com o objetivo de melhorar o modelo do cérebro humano. Apesar dos inúmeros avanços, ainda estamos longe de termos um sistema que consiga modelar de maneira precisa o cérebro, devido à sua alta complexidade e eficiência. Apesar das redes neurais artificiais serem inspiradas no funcionamento do cérebro, vamos encará-las como sistemas não lineares que podem ser aplicados como soluções eficientes em problemas de regressão e classificação.</p>
<p>Uma sugestão de vídeo sobre o surgimento das redes neurais é o <a href="https://www.youtube.com/watch?v=Suevq-kZdIw"><em>The man who forever changed artificial intelligence</em></a>.</p>
<p>Quem quiser se aprofundar em modelos de neurônios e do cérebro humano já que esse assunto está fora do escopo deste curso, sugerimos o livro <span class="citation" data-cites="GerstnerBook2014">(<a href="#ref-GerstnerBook2014" role="doc-biblioref">Gerstner et al. 2014</a>)</span>.</p>
</section>
</div>





<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">Referências</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Bishop_book2006" class="csl-entry" role="listitem">
Bishop, C. M. 2006. <em>Pattern recognition and machine learning</em>. Springer.
</div>
<div id="ref-DurrBook2020" class="csl-entry" role="listitem">
Dürr, Oliver, e Beate Sick. 2020. <em>Probabilistic Deep Learning</em>. Manning.
</div>
<div id="ref-GerstnerBook2014" class="csl-entry" role="listitem">
Gerstner, Wulfram, Werner M. Kistler, Richard Naud, e Liam Paninski. 2014. <em>Neural Dynamics: from single neurons to networks and models of cognition</em>. Cambridge University Press.
</div>
<div id="ref-Haykin2009" class="csl-entry" role="listitem">
Haykin, Simon. 2009. <em>Neural networks and learning machines</em>. 3rd ed. Pearson.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Notas de rodapé</h2>

<ol>
<li id="fn1"><p>Como no caso do algoritmo LMS no modo <em>mini-batch</em>, inserimos aqui o índice <span class="math inline">\(m-1\)</span> aos vetores que foram calculados com os dados da posição <span class="math inline">\(\ell\)</span> e pesos <span class="math inline">\(\mathbf{w}(m-1)\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script>
var custom_title = document.querySelectorAll('.custom .theorem-title');

for (let i = 0; i < custom_title.length; i++ ) {
   var mod_name = custom_title[i].innerHTML;
   custom_title[i].innerHTML = mod_name.replace("Exemplo", "Algoritmo");
};
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiada");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiada");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>