<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pt-br" xml:lang="pt-br"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Regressão linear – PSI5892</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e0b2e4e5c4db31b3b64fdef51415d7d2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nenhum resultado",
    "search-matching-documents-text": "documentos correspondentes",
    "search-copy-link-title": "Copiar link para a busca",
    "search-hide-matches-text": "Esconder correspondências adicionais",
    "search-more-match-text": "mais correspondência neste documento",
    "search-more-matches-text": "mais correspondências neste documento",
    "search-clear-button-title": "Limpar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Procurar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">PSI5892</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Procurar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Alternar de navegação" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teoria" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Teoria</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-teoria">    
        <li>
    <a class="dropdown-item" href="./t_introducao.html">
 <span class="dropdown-text">Introdução</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_regressao_linear.html">
 <span class="dropdown-text">Regressão linear</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_lms.html">
 <span class="dropdown-text">O algoritmo LMS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_neuronio.html">
 <span class="dropdown-text">O modelo do neurônio</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_mlp.html">
 <span class="dropdown-text">A rede perceptron multicamada</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_hiperparametros.html">
 <span class="dropdown-text">Evitando mínimos locais e <em>overfitting</em></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_autodiff.html">
 <span class="dropdown-text">Introdução à diferenciação automática</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_pytorch_topicos.html">
 <span class="dropdown-text">Tópicos sobre o <em>framework</em> PyTorch</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_pytorch_exemplo_mlp.html">
 <span class="dropdown-text">Implementação da rede MLP com PyTorch</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_medidas.html">
 <span class="dropdown-text">Medidas de desempenho</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_pca.html">
 <span class="dropdown-text">Análise de Componentes Principais</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./t_lda.html">
 <span class="dropdown-text">Análise de Discriminantes Lineares</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-material-de-apoio" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Material de apoio</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-material-de-apoio">    
        <li>
    <a class="dropdown-item" href="./ap_python_topicos.html">
 <span class="dropdown-text">Tópicos de programação com Python</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Regressão linear</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="justify">
<section id="regressão-linear-univariada" class="level2">
<h2 class="anchored" data-anchor-id="regressão-linear-univariada">Regressão linear univariada</h2>
<p>Em engenharia, é muito comum ajustar um modelo a dados experimentais previamente observados. Utilizando o modelo, é possíver prever valores de dados não observados, o que caracteriza um problema de <em>regressão</em>. Um dos modelos mais simples é o ajuste de uma reta a dados conhecidos, o que leva à solução conhecida como <strong>regressão linear univariada</strong>.</p>
<p>Seja</p>
<p><span class="math display">\[
\{(x_1,d_1),(x_2,d_2),\cdots, (x_N,d_N)\},
\]</span></p>
<p>um conjunto de <span class="math inline">\(N\)</span> pontos conhecidos previamente que podem ser fruto de um experimento. Vamos obter a melhor reta que se ajusta a esses pontos. Quando dizemos <em>melhor</em>, precisamos especificar em que sentido. Como, em geral, os pontos são experimentais, raramente se consegue obter uma reta que se ajuste exatamente aos pontos. Por isso, vamos buscar uma aproximação que melhor se ajusta aos dados, considerando o critério dos mínimos quadrados. Assim, deseja-se obter uma relação matemática do tipo</p>
<p><span class="math display">\[
d=b+wx
\]</span></p>
<p>entre as variáveis <span class="math inline">\(x\)</span> e <span class="math inline">\(d\)</span>, em que <span class="math inline">\(w\)</span> e <span class="math inline">\(b\)</span> são constantes que se deseja determinar. É comum chamar <span class="math inline">\(d\)</span> de sinal desejado ou rótulo, <span class="math inline">\(x\)</span> de entrada, <span class="math inline">\(w\)</span> de peso e <span class="math inline">\(b\)</span> de viés (ou <em>bias</em>).</p>
<p>Quando os pontos experimentais são colineares, a reta passa exatamente por todos os <span class="math inline">\(n\)</span> pontos e as constantes desconhecidas <span class="math inline">\(w\)</span> e <span class="math inline">\(b\)</span> satisfazem</p>
<p><span class="math display">\[
\begin{array}{c}
  d_1=b+w\;x_1 \\
  d_2=b+w\;x_2 \\
  \vdots \\
  d_N=b+w\;x_N.
\end{array}
\]</span></p>
<p>Podemos reescrever esse sistema de equações na forma matricial, ou seja,</p>
<p><span class="math display">\[
\underbrace{\left[
  \begin{array}{c}
    d_1 \\
    d_2 \\
    \vdots \\
   d_N \\
  \end{array}
\right]}_{\mathbf{d}}=
\underbrace{\left[
  \begin{array}{cc}
    1&amp;x_1 \\
    1&amp;x_2 \\
    \vdots&amp;\vdots \\
    1&amp;x_N
  \end{array}
\right]}_{\mathbf{X}}
\underbrace{\left[
  \begin{array}{c}
    b \\
    w   \end{array}
\right]}_{\mathbf{w}}.
\]</span></p>
<p>Nesse caso, como os pontos experimentais são colineares, vale <span class="math inline">\(\mathbf{d}-\mathbf{X}\mathbf{w}=\mathbf{0}\)</span>.</p>
<p>Se os pontos não forem colineares, o que acontece na maior parte dos casos, <span class="math inline">\(\mathbf{d}-\mathbf{X}\mathbf{w}\neq\mathbf{0}\)</span>. Dessa forma, para encontrar a reta que melhor se ajusta aos dados, vamos representar a diferença entre os vetores <span class="math inline">\(\mathbf{d}\)</span> e <span class="math inline">\(\mathbf{Xw}\)</span> por meio do vetor de erros, ou seja,</p>
<p><span class="math display">\[
\mathbf{e}=\mathbf{d}-\mathbf{X}\mathbf{w}.
\]</span></p>
<p>Os elementos desse vetor de erros, <span class="math inline">\(e_i=d_i-b-wx_i\)</span> para <span class="math inline">\(i=1,\cdots,N\)</span>, representam as distâncias verticais da reta <span class="math inline">\(wx+b\)</span> aos pontos experimentais <span class="math inline">\((x_i,d_i)\)</span>, como ilustrado na <a href="#fig-MV2" class="quarto-xref">Figura&nbsp;1</a>, considerando <span class="math inline">\(N=3\)</span>.</p>
<div id="fig-MV2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-MV2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="././images/mmq.jpg" class="quarto-figure quarto-figure-center figure-img" height="250">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-MV2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1: Distância de um conjunto de pontos a uma determinada reta, considerando <span class="math inline">\(N=3\)</span>.
</figcaption>
</figure>
</div>
<p>A <em>melhor</em> reta segundo o critério dos mínimos quadrados deve minimizar o quadrado da norma Euclidiana do vetor de erros, ou seja</p>
<p><span class="math display">\[
\|\mathbf{e}\|^2=\sum_{i=1}^N e_i^2=\|\mathbf{d}-\mathbf{X}\mathbf{w}\|^2=\sum_{i=1}^N(d_i-b-wx_i)^2.
\]</span></p>
<p>Para minimizar essa norma quadrática, devemos derivá-la em relação às constantes <span class="math inline">\(w\)</span> e <span class="math inline">\(b\)</span> que se deseja determinar e igualar essas derivadas a zero. Assim, obtemos as seguintes derivadas:</p>
<p><span class="math display">\[
\begin{array}{cccc}
   \displaystyle\frac{\displaystyle\partial\sum_{i=1}^N e_i^2}{\partial w} &amp; = &amp; 2\displaystyle\sum_{i=1}^N e_i\displaystyle\frac{\partial e_i}{\partial w} &amp;
  = -2\displaystyle\sum_{i=1}^N e_i x_i\\
   \displaystyle\frac{\displaystyle\partial\sum_{i=1}^N e_i^2}{\partial b} &amp; = &amp; 2\displaystyle\sum_{i=1}^N e_i\displaystyle\frac{\partial e_i}{\partial b} &amp;
  = - 2\displaystyle\sum_{i=1}^N e_i,
\end{array}
\]</span></p>
<p>que podem ser escritas de forma compacta como</p>
<p><span class="math display">\[
\displaystyle\frac{\displaystyle\partial\sum_{i=1}^N e_i^2}{\partial \mathbf{w}}=
-2\displaystyle\sum_{i=1}^N \left[
                                  \begin{array}{c}
                                    1 \\
                                    x_i \\
                                  \end{array}
                                \right] e_i=-2\mathbf{X}^{{\rm T}}\mathbf{e}=-2\mathbf{X}^{{\rm T}}(\mathbf{d}-\mathbf{X}\mathbf{w}),
\]</span></p>
<p>em que <span class="math inline">\((\cdot)^{{\rm T}}\)</span> representa a operação de transposição da matriz <span class="math inline">\(\mathbf{X}\)</span>. Igualando essa derivada ao vetor nulo, obtemos</p>
<p><span class="math display">\[
-2\mathbf{X}^{{\rm T}}(\mathbf{d}-\mathbf{X}\mathbf{w}^{\rm o})=\mathbf{0},
\]</span></p>
<p>ou ainda</p>
<p><span class="math display">\[
\mathbf{X}^{{\rm T}}\mathbf{X}\mathbf{w}^{\rm o}=\mathbf{X}^{{\rm T}}\mathbf{d}.
\]</span></p>
<p>Portanto, o vetor de coeficientes <span class="math inline">\(\mathbf{w}\)</span> que satisfaz essa equação, denotado como <span class="math inline">\(\mathbf{w}^{\rm o}=[\,b^{\rm o}\;\;w^{\rm o}\,]^{{\rm T}}\)</span>, minimiza a norma quadrática do vetor de erros e</p>
<p><span class="math display">\[
y=w^{\rm o}x+b^{\rm o}\approx d
\]</span></p>
<p>é a melhor reta que se ajusta aos pontos previamente conhecidos, segundo o critério dos mínimos quadrados.</p>
<p>Se <span class="math inline">\(\mathbf{X}^{{\rm T}}\mathbf{X}\)</span> for invertível,</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\mathbf{w}^{\rm o}=(\mathbf{X}^{{\rm T}}\mathbf{X})^{-1}\mathbf{X}^{{\rm T}}\mathbf{d}.
$}
\end{equation*}\]</span></p>
<p>Essa equação expressa a unicidade da solução. Assim, existe uma única reta que se ajusta a esses pontos segundo o critério dos mínimos quadrados.</p>
<p>Observações importantes:</p>
<ul>
<li><p>O modelo <span class="math inline">\(y=w^{\rm o}x+b^{\rm o}\)</span> é de fato linear apenas quando <span class="math inline">\(b^{\rm o}=0\)</span>, pois neste caso <span class="math inline">\(x=0\)</span> leva a <span class="math inline">\(y=0\)</span>. No entanto, o termo <em>linear</em> é frequentemente usado na literatura neste caso para se referir ao modelo dado por uma reta.</p></li>
<li><p>Os dados <span class="math inline">\(\{(x_1,d_1),(x_2,d_2),\cdots, (x_N,d_N)\}\)</span> conhecidos previamente foram totalmente usados aqui para se obter o modelo da reta. Neste caso, eles podem ser chamados de dados de <strong>treinamento</strong> do modelo.</p></li>
<li><p>A matriz <span class="math inline">\((\mathbf{X}^{{\rm T}}\mathbf{X})^{-1}\mathbf{X}^{{\rm T}}\)</span> é conhecida na literatura como a pseudoinversa de <span class="math inline">\(\mathbf{X}\)</span>.</p></li>
</ul>
</section>
<section id="regressão-linear-multivariada" class="level2">
<h2 class="anchored" data-anchor-id="regressão-linear-multivariada">Regressão linear multivariada</h2>
<p>Suponha agora que os dados não sejam mais compostos por duplas do tipo <span class="math inline">\((x_i, d_i)\)</span>, mas por uma sequência de <span class="math inline">\(M\)</span> valores de <span class="math inline">\(x\)</span>, seguida do valor de <span class="math inline">\(d\)</span>, ou seja,</p>
<p><span class="math display">\[
\{(x_{11}, x_{21}, \cdots, x_{M1} ,d_1), (x_{12}, x_{22}, \cdots, x_{M2} ,d_2),\cdots, (x_{1N}, x_{2N}, \cdots, x_{MN} ,d_N)\}.
\]</span></p>
<p>Considerando que esses <span class="math inline">\(N\)</span> conjuntos de dados sejam previamente conhecidos, deseja-se agora obter a melhor função linear segundo o critério dos mínimos quadrados, que se ajusta a esses dados. Trata-se de uma generalização do resultado anterior. Em vez de se obter a melhor reta, vamos encontrar o melhor hiperplano que se ajusta aos dados, levando à solução conhecida como <em>regressão linear multivariada</em>.</p>
<p>Assim, o modelo se torna</p>
<p><span class="math display">\[
y=b+w_1x_1+w_2x_2+\cdots+w_Mx_M\approx d.
\]</span></p>
<p>Considerando os <span class="math inline">\(N\)</span> conjuntos de dados, obtemos o seguinte vetor de erros</p>
<p><span class="math display">\[
\underbrace{\left[
  \begin{array}{c}
    e_1 \\
    e_2 \\
    \vdots \\
    e_N \\
  \end{array}
\right]}_{\mathbf{e}}
=\underbrace{\left[
  \begin{array}{c}
    d_1 \\
    d_2 \\
    \vdots \\
    d_N \\
  \end{array}
\right]}_{\mathbf{d}}
-
\underbrace{\left[
  \begin{array}{ccccc}
    1      &amp; x_{11} &amp; x_{21} &amp; \cdots &amp; x_{M1} \\
    1      &amp; x_{12} &amp; x_{22} &amp; \cdots &amp; x_{M2} \\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    1      &amp; x_{1N} &amp; x_{2N} &amp; \cdots &amp; x_{MN} \\
  \end{array}
\right]}_{\mathbf{X}}
\underbrace{\left[
  \begin{array}{c}
    b \\
    w_1 \\
    \vdots \\
    w_M \\
  \end{array}
\right]}_{\mathbf{w}}
\]</span></p>
<p>Como no caso da reta, o melhor hiperplano que se ajusta aos dados segundo o critério dos mínimos quadrados é o que minimiza o quadrado da norma Euclidiana do vetor de erros, dada por</p>
<p><span class="math display">\[
\|\mathbf{e}\|^2=\|\mathbf{d}-\mathbf{X}\mathbf{w}\|^2.
\]</span></p>
<p>Generalizando os passos para obtenção da reta que se ajusta aos dados, chega-se a</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\mathbf{w}^{\rm o}=(\mathbf{X}^{\rm T}\mathbf{X})^{-1}\mathbf{X}^{\rm T}\mathbf{d}
$}
\end{equation*}\]</span></p>
<p>em que <span class="math inline">\(\mathbf{w}^{\rm o}=[\,b^{\rm o}\;\;w_1^{\rm o}\;\;w_2^{\rm o}\;\;\cdots\;\;w_M^{\rm o}\,]^{\rm T}\)</span> é o vetor que contém o <em>bias</em> e pesos ótimos que minimizam <span class="math inline">\(\|\mathbf{e}\|^2\)</span>.</p>
<p>Observações importantes:</p>
<ol type="1">
<li><p>Calcular a inversa da matriz <span class="math inline">\(\mathbf{X}^{\rm T}\mathbf{X}\)</span> diretamente pode levar a problemas numéricos, dependendo do valor de <span class="math inline">\(M\)</span>. Isso ocorre, por exemplo, quando se utiliza a função <a href="https://www.mathworks.com/help/matlab/ref/inv.html"><code>inv.m</code></a> no Matlab. Algo semelhante também ocorre em Python e é pior ao se considerar precisão de 32 bits em ponto flutuante. Procure evitar isso, resolvendo o sistema linear</p>
<p><span class="math display">\[
\mathbf{X}^{\rm T}\mathbf{X}\mathbf{w}^{\rm o}=\mathbf{X}^{\rm T}\mathbf{d}
\]</span></p>
<p>para encontrar <span class="math inline">\(\mathbf{w}^{\rm o}\)</span>. No Matlab, basta fazer <span class="math inline">\((\mathbf{X}^{\rm T}\mathbf{X})\backslash(\mathbf{X}^{\rm T}\mathbf{d})\)</span>. Em Python, pode-se, por exemplo, usar a função <a href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html"><code>np.linalg.solve</code></a> do NumPy.</p></li>
<li><p>A matriz <span class="math inline">\(\mathbf{X}^{\rm T}\mathbf{X}\)</span> é uma estimativa da matriz de autocorrelação dos dados de entrada <span class="math inline">\(x\)</span>.</p></li>
<li><p>O vetor <span class="math inline">\(\mathbf{X}^{\rm T}\mathbf{d}\)</span> é uma estimativa da correlação cruzada entre os dados de entrada <span class="math inline">\(x\)</span> e o sinal desejado <span class="math inline">\(d\)</span>.</p></li>
<li><p>Quando se deseja ajustar um polinômio de grau <span class="math inline">\(M\)</span> aos dados</p>
<p><span class="math display">\[
\{(x_1,d_1),(x_2,d_2),\cdots, (x_N,d_N)\},
\]</span></p>
<p>basta usar o resultado do caso multivariado, considerando</p>
<p><span class="math display">\[
\{(x_{1}, x_{1}^2, \cdots, x_{1}^M ,d_1), (x_{2}, x_{2}^2, \cdots, x_{2}^M ,d_2),\cdots, (x_{N}, x_{N}^2, \cdots, x_{N}^M ,d_N)\}.
\]</span></p>
<p>Isso leva à seguinte aproximação</p>
<p><span class="math display">\[
y=b+w_1x+w_2x^2+\cdots+w_Mx^M\approx d.
\]</span></p>
<p>Neste caso a matrix <span class="math inline">\(\mathbf{X}\)</span> se torna</p>
<p><span class="math display">\[\mathbf{X}=\left[
   \begin{array}{ccccc}
     1      &amp; x_{1} &amp; x_{1}^2 &amp; \cdots &amp; x_{1}^M \\
     1      &amp; x_{2} &amp; x_{2}^2 &amp; \cdots &amp; x_{2}^M \\
     \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
     1      &amp; x_{N} &amp; x_{N}^2 &amp; \cdots &amp; x_{N}^M \\
   \end{array}
\right].
\]</span></p></li>
<li><p>O resultado do item anterior pode ser usado para aproximar os dados não só por polinômios, mas também por outras funções. Por exemplo, poderíamos calcular as seguintes aproximações para os dados</p>
<p><span class="math display">\[
y=b+w_1\ln(x+5)+w_2\exp(x-2)\approx d
\]</span></p>
<p>ou</p>
<p><span class="math display">\[
y=b+w_1\cos(2\pi f_0 x)+w_2{\rm sen}(2\pi f_0 x)\approx d
\]</span></p>
<p>em que <span class="math inline">\(f_0\)</span> é uma frequência pré-determinada. Um outro exemplo útil em Engenharia Elétrica é aproximar uma função <span class="math inline">\(f(t)\)</span> periódica com período <span class="math inline">\(T_0=1/f_0\)</span> por uma soma de senos e cossenos, ou seja,</p>
<p><span class="math display">\[
\begin{align}
{f}(t)\approx \;b&amp;+w_{11}\cos(2\pi f_0 t)+ w_{12}{\rm sen}\,(2\pi f_0 t)\nonumber\\
&amp;+w_{21}\cos(2\pi 2 f_0 t)+ w_{22}{\rm sen}\,(2\pi 2 f_0 t)\nonumber\\
&amp;+\cdots\nonumber\\
&amp;+w_{M1}\cos(2\pi f_0 M t)+ w_{M2}{\rm sen}\,(2\pi f_0 M t).\nonumber
\end{align}
\]</span> Os coeficientes <span class="math inline">\(b, w_{11}, w_{12}, w_{21}, w_{22}, \cdots, w_{M1}, w_{M2}\)</span> são conhecidos como coeficientes da série de Fourier e os dados usados para obter essa aproximação são obtidos a partir da amostragem da função <span class="math inline">\(f(t)\)</span>.</p></li>
</ol>
</section>
<section id="overfitting" class="level2">
<h2 class="anchored" data-anchor-id="overfitting"><em>Overfitting</em></h2>
<p>Um conceito que aparece de forma recorrente em redes neurais é o chamado <em>overfitting</em>. Apesar de nem termos falado em redes neurais ainda, é possível já introduzir esse conceito considerando regressão linear. Antes de falar de <em>overfitting</em>, precisamos fazer algumas considerações importantes.</p>
<p>Suponha que se deseja criar um modelo de regressão para prever o valor de venda de um automóvel usado. Dispomos de um banco de dados que contém várias informações sobre diferentes automóveis usados como ano de fabricação, modelo, estado de conservação, valor da tabela Fipe, valor médio de venda no mercado, etc. Utilizando esse banco de dados, podemos obter um modelo de regressão linear, que neste caso será multivariada, pois dispomos de muitas variáveis. Poderíamos usar todos os dados disponíveis para gerar o modelo. Se fizéssemos isso, como conseguiríamos avaliar se o modelo obtido é bom? Como saber se o modelo é capaz de prever adequadamente o valor de venda de um determinado carro que não aparece no banco de dados? Por isso, é importante reservar uma parte dos dados para avaliar a qualidade do modelo. Assim, é uma prática comum separar os dados de forma aleatória em dois conjuntos disjuntos: (1) conjunto de <strong>treinamento</strong> (ou aprendizado) e (2) conjunto de <strong>teste</strong><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Os dados do conjunto de treinamento são efetivamente usados para gerar o modelo. Os dados do conjunto de teste são então usados para avaliar a qualidade do modelo gerado. Os dados usados para avaliação não devem aparecer no treinamento e vice-versa. Se o modelo se sair bem no teste, costuma-se dizer que ele tem uma boa capacidade de <strong>generalização</strong>.</p>
<p>Em qualquer problema de regressão, deseja-se que o modelo tenha uma boa capacidade de generalização. No exemplo do automóvel usado, é importante que o modelo consiga prever com o menor erro possível o valor de venda de um carro que não constava no banco de dados. No entanto, um modelo com muitos parâmetros pode ter um ótimo desempenho no treinamento, mas uma baixa capacidade de generalização, o que leva a um erro elevado na fase de teste. Isso é chamado de <strong><em>overfitting</em></strong>. Modelos com baixa capacidade de generalização não são desejáveis, uma vez que na prática serão apresentados a dados que não foram usados no treinamento e deveriam ser capazes de realizar uma predição ou classificação de maneira adequada. Diante isso, existem várias técnicas em aprendizado de máquina que foram propostas para evitar o <em>overfitting</em>. Por ora, vamos apenas entender melhor esse conceito com um exemplo.</p>
<p>Considere que dispomos de apenas dez valores igualmente espaçados de <span class="math inline">\(x\)</span> no intervalo <span class="math inline">\([0,\!1;\;1,\!5]\)</span>. Os valores de <span class="math inline">\(d\)</span> são gerados utilizando a função</p>
<p><span class="math display">\[
d=0,\!5+0,\!25\cos(2\pi x)+v,
\]</span></p>
<p>em que <span class="math inline">\(v\)</span> é um ruído branco gaussiano com média zero e desvio padrão <span class="math inline">\(0,\!06\)</span>. Assim, por exemplo, poderíamos ter o seguinte conjunto de treinamento</p>
<p><span class="math display">\[
\{(0,\!1000,\;0,\!7055),\;\;(0,\!2556,\;0,\!4357),\;\;(0,\!4111,\;0,\!3264),\;\;\cdots,\;\;(1,\!5000,\;0,\!2514)\}.
\]</span></p>
<p>Como o valor de <span class="math inline">\(d\)</span> depende do ruído, se não fixarmos uma semente, cada vez que gerarmos os dados teremos valores distintos. O objetivo é encontrar uma função (um modelo) polinomial de grau <span class="math inline">\(M\)</span> que melhor se aproxima dos pontos do conjunto de treinamento, levando em conta a forma da cossenóide sem ruído. Na <a href="#fig-rlfit" class="quarto-xref">Figura&nbsp;2</a>, são mostrados os pontos disponíveis no treinamento (em vermelho), as curvas pretas representam o sinal senoidal sem ruído e as azuis os polinômios obtidos com a regressão. Foram considerados polinômios com graus <span class="math inline">\(M=1\)</span> (reta), <span class="math inline">\(M=2\)</span> (parábola) até <span class="math inline">\(M=9\)</span>. É possível ver que para <span class="math inline">\(M=1\)</span> e <span class="math inline">\(M=2\)</span> ocorre o <em>underfitting</em>, ou seja, as distâncias dos pontos de treinamento aos pontos gerados pelos polinômios dos modelos são elevadas, o que indica que eles não são adequados. À medida em que o valor do grau do polinômio aumenta, observa-se um melhor ajuste entre os pontos vermelhos e as curvas azuis, até o caso extremo de <span class="math inline">\(M=9\)</span>. Neste caso, o polinômio obtido passa exatamente em todos os pontos do treinamento, mas claramente a curva azul fica distante da cossenóide sem ruído em alguns trechos como pode ser visto pelas flutuações indesejadas. Isso indica que pode ter ocorrido <em>overfitting</em> devido ao número excessivo de parâmetros do modelo.</p>
<div id="cell-fig-rlfit" class="cell quarto-layout-panel" data-layout-ncol="1" data-execution_count="1">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-rlfit" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rlfit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="t_regressao_linear_files/figure-html/fig-rlfit-output-1.png" width="943" height="949" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rlfit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2: Regressão linear polinomial; <span class="math inline">\(M\)</span> representa o grau do polinômio, os pontos do conjunto de treinamento estão representados em vermelho; as curvas pretas representam o sinal senoidal sem ruído e as azuis os polinômios obtidos com a regressão.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Para analisar o <em>overfitting</em>, geramos um conjunto de teste com 1401 valores de <span class="math inline">\(x\)</span> igualmente espaçados no intervalo <span class="math inline">\([0,\!1;\;1,\!5]\)</span> e calculamos o valor de <span class="math inline">\(d\)</span>. Como há ruído na geração de <span class="math inline">\(d\)</span>, os pontos gerados no teste são diferentes dos de treinamento. Para cada valor de <span class="math inline">\(M\)</span>, medimos o valor absoluto médio do erro de predição, levando em conta o conjunto de treinamento e de teste. Na <a href="#fig-rl-error" class="quarto-xref">Figura&nbsp;3</a>, são mostrados os valores desses erros em função do grau do polinômio. Como esperado, o erro de aprendizagem (com os dados do treinamento) diminuem monotonicamente, chegando a zero para <span class="math inline">\(M=9\)</span>. Esse comportamento é típico sempre que o modelo ajustado varia do mais simples para o mais complexo. Em contrapartida, o erro do teste diminui até <span class="math inline">\(M=5\)</span> e depois aumenta, indicando que modelos com muitos parâmetros têm baixas capacidades de generalização.</p>
<div id="cell-fig-rl-error" class="cell quarto-layout-panel" data-layout-ncol="1" data-execution_count="2">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-rl-error" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rl-error-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="t_regressao_linear_files/figure-html/fig-rl-error-output-1.png" width="607" height="432" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rl-error-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3: Regressão linear polinomial; valor médio do módulo do erro de predição levando em conta o conjunto de treinamento e o conjunto de teste.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div hidden="">
[<span class="citation" data-cites="mmqpsi3260">Miranda et al. (<a href="#ref-mmqpsi3260" role="doc-biblioref">2015</a>)</span>]<span class="citation" data-cites="Goodfellow2016">(<a href="#ref-Goodfellow2016" role="doc-biblioref">Goodfellow, Bengio, e Courville 2016</a>)</span>[<span class="citation" data-cites="Bishop_book2006">Bishop (<a href="#ref-Bishop_book2006" role="doc-biblioref">2006</a>)</span>]<span class="citation" data-cites="AlanBook2008">(<a href="#ref-AlanBook2008" role="doc-biblioref">Izenman 2008</a>)</span><span class="citation" data-cites="Haykin2009">(<a href="#ref-Haykin2009" role="doc-biblioref">Haykin 2009</a>)</span>
</div>
</section>
</div>





<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">Referências</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Bishop_book2006" class="csl-entry" role="listitem">
Bishop, C. M. 2006. <em>Pattern recognition and machine learning</em>. Springer.
</div>
<div id="ref-Goodfellow2016" class="csl-entry" role="listitem">
Goodfellow, Ian, Yoshua Bengio, e Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press,&nbsp;<a href="http://www.deeplearningbook.org" class="uri">http://www.deeplearningbook.org</a>.
</div>
<div id="ref-Haykin2009" class="csl-entry" role="listitem">
Haykin, Simon. 2009. <em>Neural networks and learning machines</em>. 3rd ed. Pearson.
</div>
<div id="ref-AlanBook2008" class="csl-entry" role="listitem">
Izenman, Alan Julian. 2008. <em>Modern Multivariate Statistical Techniques</em>. Springer.
</div>
<div id="ref-mmqpsi3260" class="csl-entry" role="listitem">
Miranda, Maria D., Magno T. M. Silva, Marcio Eisencraft, e Vı́tor H. Nascimento. 2015. <em>Método dos Mínimos Quadrados – apostila da disciplina PSI3260 Aplicações de Álgebra Linear</em>. Escola Politécnica da USP.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Notas de rodapé</h2>

<ol>
<li id="fn1"><p>Na realidade, é comum reservar também uma parte dos dados em um conjunto chamado de <strong>validação</strong>, mas isso será abordado posteriormente. No momento, considere apenas os conjuntos de treinamento e teste.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script>
var custom_title = document.querySelectorAll('.custom .theorem-title');

for (let i = 0; i < custom_title.length; i++ ) {
   var mod_name = custom_title[i].innerHTML;
   custom_title[i].innerHTML = mod_name.replace("Exemplo", "Algoritmo");
};
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiada");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiada");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>