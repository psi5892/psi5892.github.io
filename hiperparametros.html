<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pt-br" xml:lang="pt-br"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Evitando mínimos locais e overfitting – PSI5892</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nenhum resultado",
    "search-matching-documents-text": "documentos correspondentes",
    "search-copy-link-title": "Copiar link para a busca",
    "search-hide-matches-text": "Esconder correspondências adicionais",
    "search-more-match-text": "mais correspondência neste documento",
    "search-more-matches-text": "mais correspondências neste documento",
    "search-clear-button-title": "Limpar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Procurar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">PSI5892</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Procurar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Alternar de navegação" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teoria" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Teoria</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-teoria">    
        <li>
    <a class="dropdown-item" href="./introducao.html">
 <span class="dropdown-text">Introdução</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./regressao_linear.html">
 <span class="dropdown-text">Regressão linear</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./lms.html">
 <span class="dropdown-text">O algoritmo LMS</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-exercícios-para-aula" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Exercícios para aula</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-exercícios-para-aula">    
        <li>
    <a class="dropdown-item" href="./ex_aula_1.html">
 <span class="dropdown-text">Exercício 1 - Regressão Linear</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ex_aula_2.html">
 <span class="dropdown-text">Exercício 2 - O algoritmo LMS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ex_aula_3.html">
 <span class="dropdown-text">Exercício 3 - Filtro Adaptativo LMS</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-material-de-apoio" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Material de apoio</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-material-de-apoio">    
        <li>
    <a class="dropdown-item" href="./python_videos.html">
 <span class="dropdown-text">Tópicos de programação com Python</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://edisciplinas.usp.br/course/view.php?id=125106"> 
<span class="menu-text">Moodle</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Evitando mínimos locais e <em>overfitting</em></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="justify">
<p>Há diferentes maneiras de evitar que o algoritmo <em>backpropagation</em> fique parado em um mínimo local da função custo, evitando assim que a rede atinja soluções subótimas no treinamento. Outro problema que pode acontecer no treinamento das redes neurais é o chamado <em>overfitting</em>, em que a solução da rede fica especializada nos dados de treinamento e tem um desempenho ruim com os dados de teste. Vimos um exemplo de <em>overfitting</em> com a regressão linear. A seguir, vamos abordar as técnicas mais usadas para evitar esses problemas. Boa parte delas envolve o ajuste de hiperparâmetros, que por sua vez, são todos os parâmetros da rede que permanecem inalterados durante o treinamento. Por exemplo, o passo de adaptação <span class="math inline">\(\eta\)</span> é um hiperparâmetro enquanto os pesos não o são.</p>
<section id="função-de-ativação" class="level2">
<h2 class="anchored" data-anchor-id="função-de-ativação">Função de ativação</h2>
<p>O cálculo do gradiente para atualização do vetor de pesos de um determinado neurônio requer o conhecimento da derivada da função de ativação <span class="math inline">\(\varphi(\cdot)\)</span> associada a ele. Para essa derivada existir, a função <span class="math inline">\(\varphi(\cdot)\)</span> deve ser contínua. Basicamente, ser diferenciável é a única propriedade que a função de ativação deve satisfazer. A seguir vamos descrever as funções de ativação mais usadas na MLP.</p>
<section id="sigmoidal" class="level3">
<h3 class="anchored" data-anchor-id="sigmoidal">Sigmoidal</h3>
<p>A função sigmoidal também é conhecida como função logística. Embora alguns autores utilizem o termo “sigmoidal” para uma classe de funções em que a logística e a tangente hiperbólica são exemplos, o termo “sigmoidal” é frequentemente utilizado para a função definida como</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \varphi(v_k^{(j)})={\rm sgm}(a\,v_k^{(j)})=\displaystyle\frac{1}{1+e^{-a\, v_k^{(j)}}},\;\;\;\; a&gt;0,
$}
\end{equation*}\]</span></p>
<p>em que <span class="math inline">\(v_k^{(j)}\)</span> é o resultado da combinação linear entre as entradas e os pesos do Neurônio <span class="math inline">\(k\)</span> da Camada <span class="math inline">\(j\)</span> e <span class="math inline">\(a\)</span> é um parâmetro positivo ajustável. A derivada dessa função é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \varphi'(v_k^{(j)})=\frac{\rm d}{{\rm d}v_k^{(j)}}{\rm sgm}(a\,v_k^{(j)})=\displaystyle \frac{a\,e^{-a\, v_k^{(j)}}}{\left[1+e^{-a\, v_k^{(j)}}\right]^2}= a \varphi(v_k^{(j)})[1-\varphi(v_k^{(j)})].
$}
\end{equation*}\]</span></p>
<p>Como <span class="math inline">\(\varphi(v_k^{(j)})=y_k^{(j)}\)</span> é a saída do Neurônio <span class="math inline">\(k\)</span> da Camada <span class="math inline">\(j\)</span>, ainda podemos escrever</p>
<p><span class="math display">\[
\varphi'(v_k^{(j)})= a\, y_k^{(j)}(1-y_k^{(j)}).
\]</span></p>
<p>Na <a href="#fig-sigmoide" class="quarto-xref">Figura&nbsp;1</a> são mostrados gráficos da função sigmoidal e de sua derivada para dois valores de <span class="math inline">\(a\)</span>. Pode-se observar que a saída do neurônio com função sigmoidal fica no intervalo <span class="math inline">\([0,\; 1]\)</span>. Quanto maior o valor do parâmetro <span class="math inline">\(a\)</span> mais abrupta é a mudança do patamar <span class="math inline">\(0\)</span> para o patamar <span class="math inline">\(1\)</span> e consequentemente maior a derivada em <span class="math inline">\(v_k^{(j)}=0\)</span>.</p>
<div id="fig-sigmoide" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sigmoide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/sgmoide.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sigmoide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1: Função sigmoidal e sua derivada para dois valores do parâmetro <span class="math inline">\(a\)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="tangente-hiperbólica" class="level3">
<h3 class="anchored" data-anchor-id="tangente-hiperbólica">Tangente hiperbólica</h3>
<p>Outra função de ativação muito utilizada na MLP é a tangente hiperbólica, que também é uma função do tipo sigmoidal. Essa é a função de ativação que usamos nos experimentos com a rede MLP até agora (com <span class="math inline">\(a=1\)</span>). A tangente hiperbólica é definida como</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \varphi(v_k^{(j)})={\rm tanh}(a\,v_k^{(j)})=\frac{e^{a\,v_k^{(j)}}-e^{-a\,v_k^{(j)}}}{e^{a\,v_k^{(j)}}+e^{-a\,v_k^{(j)}}},\;\;\;a&gt;0,
  $}
\end{equation*}\]</span></p>
<p>sendo <span class="math inline">\(a\)</span> uma constante positiva. Sua derivada é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\varphi'(v_k^{(j)})=\frac{\rm d}{{\rm d}v_k^{(j)}}{\rm tanh}(a\,v_k^{(j)})=a\,\left[1-{\rm tanh}^2(v_k^{(j)})\right].
$}
\end{equation*}\]</span></p>
<p>Lembrando que a saída do Neurônio <span class="math inline">\(k\)</span> com função de ativação tangente hiperbólica é dada por <span class="math inline">\(y_k^{(j)}={\rm tanh}(v_k^{(j)})\)</span>, também podemos escrever</p>
<p><span class="math display">\[
\varphi'(v_k^{(j)})=\frac{1}{a}(a-y_k^{(j)})(a+y_k^{(j)}).
\]</span></p>
<p>Na <a href="#fig-tanh" class="quarto-xref">Figura&nbsp;2</a> são mostrados gráficos da função tangente hiperbólica e de sua derivada para dois valores de <span class="math inline">\(a\)</span>. Pode-se observar que a saída do neurônio com essa função fica no intervalo <span class="math inline">\([-1,\; 1]\)</span>. Quanto maior o valor do parâmetro <span class="math inline">\(a\)</span> mais abrupta é a mudança do patamar <span class="math inline">\(-1\)</span> para o patamar <span class="math inline">\(1\)</span> e consequentemente maior a derivada em <span class="math inline">\(v_k^{(j)}=0\)</span>.</p>
<div id="fig-tanh" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tanh-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/tanh.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tanh-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2: Função tangente hiperbólica e sua derivada para dois valores do parâmetro <span class="math inline">\(a\)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="relu" class="level3">
<h3 class="anchored" data-anchor-id="relu">ReLU</h3>
<p>A unidade linear retificada (<em>Rectified Linear Unit</em> - ReLU) é uma função de ativação dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \varphi(v_k^{(j)})={\rm ReLU}(v_k^{(j)})=\max(0, v_k^{(j)})=\left\{\begin{array}{cc}
                                     0, &amp; v_k^{(j)}\leq 0 \\
                                     v_k^{(j)}, &amp; v_k^{(j)}&gt;0
                                   \end{array}
                                 \right.

$}
\end{equation*}\]</span></p>
<p>Essa função também é conhecida como função rampa e é análoga ao retificador de meia-onda, o que justifica seu nome. Sua derivada é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \varphi'(v_k^{(j)})={\rm ReLU}'(v_k^{(j)})=\left\{\begin{array}{cc}
                                     0, &amp; v_k^{(j)}&lt; 0 \\
                                     1, &amp; v_k^{(j)}&gt;0\\
                                     \nexists, &amp; v_k^{(j)}=0.
                                   \end{array}
                                 \right.

$}
\end{equation*}\]</span></p>
<p>Na <a href="#fig-relu" class="quarto-xref">Figura&nbsp;3</a> são mostradas a função ReLU e a sua derivada. Observe que a função ReLU não é diferenciável em <span class="math inline">\(v_k^{(j)}=0\)</span>. Como ela é diferenciável em todos os outros valores de <span class="math inline">\(v_k^{(j)}\)</span>, o valor de sua derivada em zero pode ser arbitrariamente escolhido como 0 ou 1. Em geral, o treinamento de redes MLP profundas que usam essa função é mais rápido quando comparado ao treinamento das redes MLP que usam a tangente hiperbólica. Essa função foi baseada no princípio de que os modelos são mais facilmente otimizados quando o seu comportamento é próximo do linear.</p>
<div id="fig-relu" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-relu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/ReLU.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-relu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3: Função ReLU e sua derivada (a derivada em <span class="math inline">\(v_k^{(j)}=0\)</span> foi arbitrariamente escolhida como 0)
</figcaption>
</figure>
</div>
<p>Na literatura, há diferentes variantes da ReLU, como:</p>
<ul>
<li><em>Softplus</em>;</li>
<li><em>Gaussian Error Linear Unit</em> (GELU);</li>
<li><em>Leaky rectified linear unit</em> (<em>Leaky</em> ReLU);</li>
<li><em>Parametric rectified linear unit</em> (PReLU);</li>
<li><em>Exponential linear unit</em> (ELU);</li>
<li><em>Sigmoid linear unit</em> (SiLU).</li>
</ul>
<p>Algumas dessas funções são diferenciáveis em todos os pontos, o que evita ter que escolher arbitrariamente o valor da derivada em <span class="math inline">\(v_k^{(j)}=0\)</span>. A ReLU ainda é a mais utilizada em redes profundas. Ela apresenta algumas vantagens como:</p>
<ol type="1">
<li>ativação esparsa: em uma rede inicializada aleatoriamente, apenas 50% dos neurônios ocultos são ativados (saída não nula);</li>
<li>melhor propagação do gradiente: consegue escapar de mínimos locais em comparação com funções do tipo sigmoidal;</li>
<li>computação eficiente;</li>
<li>invariante à escala: <span class="math inline">\(\max(0,\,ax)= a\,\max(0,\,x),\;\;a&gt;0\)</span>.</li>
</ol>
<p>Apesar dessas vantagens, a ReLU é ilimitada, o que pode levar o algoritmo de treinamento à divergência. Além disso, neurônios com ReLU podem se tornar inativos para essencialmente todas as entradas. Nesse estado, nenhum gradiente é retropropagado e o neurônio “morre”. Em alguns casos, muitos neurônios podem ficar inativos, diminuindo efetivamente a capacidade do modelo. Esse problema geralmente surge quando a taxa de aprendizado (passo de adaptação) é muito alta e pode ser evitado usando a função <em>leaky</em> ReLU, que atribui uma pequena inclinação positiva para entradas negativas.</p>
</section>
<section id="softmax" class="level3">
<h3 class="anchored" data-anchor-id="softmax"><em>Softmax</em></h3>
<p>Em problemas de classificação multiclasse, é comum considerar uma rede com <span class="math inline">\(N_L\)</span> neurônios de saída, sendo <span class="math inline">\(N_L\)</span> o número de classes. Nesse caso, a saída esperada da rede é a ativação de apenas um dos <span class="math inline">\(N_L\)</span> neurônios e a inativação dos <span class="math inline">\(N_L-1\)</span> restantes. Para isso, costuma-se usar a função de ativação <em>softmax</em> nos neurônios de saída. Como a função sigmoidal, a função <em>softmax</em> limita a saída do neurônio entre 0 e 1. Porém, ela também leva em conta as saídas dos demais neurônios da camada. Dessa forma, considera-se uma normalização fazendo com que a soma de todas as saídas dos neurônios seja unitária, o que faz com que o vetor saída da rede seja um vetor de probabilidades. A função <em>softmax</em> para o <span class="math inline">\(k\)</span>-ésimo neurônio da camada de saída é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\varphi(v_k^{(L)})={\rm Softmax}(v_k^{(L)})=\frac{e^{v_k^{(L)}}}{\displaystyle \sum_{\ell=1}^{N_L}e^{v_\ell^{(L)}}},
$}
\end{equation*}\]</span></p>
<p>em que <span class="math inline">\(0\leq\varphi(v_k^{(L)})\leq 1\)</span> e <span class="math inline">\(\sum_{\ell=1}^{N_L}\varphi(v_\ell^{(L)})=1\)</span>. A derivada dessa função é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\varphi'(v_k^{(L)})={\rm Softmax}'(v_k^{(L)})=\frac{e^{v_k^{(L)}}\left[\displaystyle \sum_{\ell=1}^{N_L}e^{v_\ell^{(L)}}-e^{v_k^{(L)}}\right]}{\displaystyle \left[\sum_{\ell=1}^{N_L}e^{v_\ell^{(L)}}\right]^2}.
$}
\end{equation*}\]</span></p>
</section>
</section>
<section id="função-custo" class="level2">
<h2 class="anchored" data-anchor-id="função-custo">Função custo</h2>
<p>A escolha da função custo depende da finalidade da rede neural. Quando empregada em problemas de regressão, é comum usar o erro quadrático médio (<em>Mean Squared Error</em> - MSE) definido por</p>
<p><span class="math display">\[\begin{equation}\label{mse}
J_{\rm MSE} = \frac{1}{N_L} \sum_{\ell=1}^{N_L} e_{\ell}^2(n),
\end{equation}\]</span> em que <span class="math display">\[\begin{equation}\label{e_n}
e_{\ell}(n) = d_{\ell}(n) - y_{\ell}^{(L)}(n)
\end{equation}\]</span></p>
<p>são os erros dos neurônios da camada de saída da rede. Apesar de não ser a função custo mais adequada para problemas de classificação, o MSE foi utilizado nos problemas das meias-luas apresentados até o momento.</p>
<p>Quando a rede é empregada em problemas de classificação, é comum usar a entropia cruzada, uma vez que ela é mais adequada para erros de categorização. No caso de classificação binária em que as categorias são <span class="math inline">\(d = 0\)</span> ou <span class="math inline">\(d=1\)</span> e existe apenas um neurônio de saída, a entropia cruzada é dada por</p>
<p><span class="math display">\[
J_{\rm EC} = -  \left[ d_1(n) \ln\left({y_{1}^{(L)}(n)}\right) + [1 - d_1(n)] \ln{\left(1 -y_{1}^{(L)}(n)\right)}\right].
\]</span></p>
<p>Para entender essa função, considere novamente o problema das meias-luas, mantendo <span class="math inline">\(d=1\)</span> para a Região A, mas considerando que <span class="math inline">\(d=0\)</span> para a Região B. Quando <span class="math inline">\(y_1^{(L)}(n)\geq 0,5\)</span> a rede classifica o dado como pertencente à Região A e para <span class="math inline">\(y_1^{(L)}(n)&lt;0,5\)</span> o dado é classificado como pertencente à Região B. Dessa forma, a saída da rede pode ser interpretada como a probabilidade do dado de entrada pertencer à Região A. Quando <span class="math inline">\(d_1(n)=y_1^{(L)}(n) \in \{0, 1\}\)</span>, <span class="math inline">\(J_{\rm EC}=0\)</span>, que é o valor mínimo que essa função custo pode assumir. Para <span class="math inline">\(d_1(n)=1\)</span> e <span class="math inline">\(y_1^{(L)}(n)=0,\!1\)</span>, a rede erra, pois classifica o dado como pertencente à Região B enquanto ele de fato pertence à Região A e <span class="math inline">\(J_{\rm EC}=-1\times \ln(0,1)=2,\!3026.\)</span> A função custo tem o mesmo valor para <span class="math inline">\(d_1(n)=0\)</span> e <span class="math inline">\(y_1^{(L)}(n)=0,\!9\)</span>, caso em que também há erro de classificação. No caso de classificação entre <span class="math inline">\(N_L\)</span> classes, essa função é chamada de entropia cruzada categórica e é dada por</p>
<p><span class="math display">\[
J_{\rm ECC} = -  \frac{1}{N_L}\sum_{\ell=1}^{N_L} d_\ell(n)  \ln\left(y_{\ell}^{(L)}(n)\right).
\]</span></p>
<p>Uma das maneiras de se reduzir <em>overfitting</em> é usar regularização na função custo. Isso controla o ajuste dos pesos, possibilitando que a rede tenha uma boa capacidade de generalização. A regularização <span class="math inline">\(\ell_2\)</span> é a mais comum e consiste em somar à função custo o termo <span class="math display">\[\frac{\lambda}{2N_L}\sum_{\ell=1}^{N_L}\|\mathbf{w}_\ell^{(L)}(n-1)\|^2,\]</span> em que <span class="math inline">\(\lambda\)</span> é um hiperparâmetro. Assim, ao minimizar a função custo somada a esse termo, o algoritmo também procura minimizar a norma dos vetores de peso da camada de saída, evitando dessa forma que ocorra divergência <span class="citation" data-cites="Bishop_book2006">(<a href="#ref-Bishop_book2006" role="doc-biblioref">Bishop 2006</a>)</span>.</p>
<p>Existem também outras funções custo cujas derivadas não são determinadas analiticamente, mas podem ser obtidas por diferenciação automática (<em>autodiff</em>), que é um conjunto de técnicas usadas para avaliar derivadas de funções numéricas expressas como programas de computador. Mais detalhes sobre <em>autodiff</em> podem ser obtidos em <span class="citation" data-cites="BaydinJMLR2018">(<a href="#ref-BaydinJMLR2018" role="doc-biblioref">Baydin et al. 2018</a>)</span>.</p>
</section>
<section id="inicialização" class="level2">
<h2 class="anchored" data-anchor-id="inicialização">Inicialização</h2>
<p>Sabemos que a inicialização é fundamental para que a rede MLP evite mínimos locais. Nos experimentos com as meias-luas que apresentamos até agora, os pesos e <em>biases</em> foram inicializados com números aleatórios gerados a partir de uma distribuição uniforme no intervalo <span class="math inline">\([-10^{-2},\;10^{-2}]\)</span>. Como não se tem ideia dos valores dos parâmetros ótimos, de fato os pesos precisam ser inicializados de forma aleatória. O problema da forma que inicializamos é definir o intervalo da distribuição uniforme. O intervalo “ideal” depende do conjunto de dados, da arquitetura da rede etc. e sua escolha se torna mais difícil ainda em redes profundas. Além disso, uma pergunta que poderíamos fazer é: a inicialização dos parâmetros da rede considerando uma distribuição uniforme é a mais adequada?</p>
<p>No algoritmo <em>backpropagation</em>, o cálculo do gradiente local de uma determinada camada <span class="math inline">\(j\)</span> da rede depende dos gradientes locais das camadas posteriores, ou seja, o gradiente local <span class="math inline">\(\delta^{(j)}_k\)</span> carrega consigo a multiplicação de todos os gradientes locais das camadas mais profundas da rede. Para redes neurais profundas, se os gradientes locais forem menores do que um, as atualizações dos pesos e <em>biases</em> das camadas mais rasas acabam assumindo valores muito pequenos, tornando o processo de aprendizado lento e ineficiente. Analogamente, para gradientes locais sempre maiores que um, as atualizações dos pesos das camadas menos profundas acabam assumindo valores muito elevados, levando o algoritmo de treinamento à divergência. Esse problema é conhecido como desvanecimento ou explosão dos gradientes. O objetivo das técnicas de inicialização de parâmetros é evitar esse problema. Dessa forma, os pesos e <em>biases</em> precisam ser inicializados dentro de um intervalo específico.</p>
<p>A seguir, vamos abordar duas técnicas de inicialização frequentemente usadas na literatura <span class="citation" data-cites="JasonInit2021">(<a href="#ref-JasonInit2021" role="doc-biblioref">Brownlee 2021</a>)</span>.</p>
<section id="inicialização-de-xavier" class="level3">
<h3 class="anchored" data-anchor-id="inicialização-de-xavier">Inicialização de Xavier</h3>
<p>A inicialização de Xavier foi proposta originalmente no artigo <span class="citation" data-cites="Xavier2010">(<a href="#ref-Xavier2010" role="doc-biblioref">Glorot e Bengio 2010</a>)</span>. Para entender a ideia dessa inicialização, vamos primeiramente considerar que os neurônios da rede MLP têm função de ativação do tipo sigmoidal e pesos grandes. Como a função do tipo sigmoidal é plana para valores grandes da entrada, as ativações ficarão saturadas e os gradientes começarão a se aproximar de zero.</p>
<p>Para evitar esse problema, a inicialização de Xavier busca garantir que a variância de <span class="math inline">\(y^{(j)}_k\)</span> seja mantida igual ao longo das camadas, o que pode evitar o problema de desvanecimento ou explosão dos gradientes. Considerando função de ativação linear, temos</p>
<p><span class="math display">\[
y_k^{(j)}=b_k^{(j)}+w_{k1}^{(j)}y_1^{(j-1)}+w_{k2}^{(j)}y_2^{(j-1)}+\cdots+w_{kN_{j-1}}^{(j)}y_{N_{j-1}}^{(j-1)}.
\]</span></p>
<p>Calculando a variância de <span class="math inline">\(y_k^{(j)}\)</span>, obtém-se</p>
<p><span class="math display">\[
{\rm var}(y_k^{(j)})={\rm var}\left(b_k^{(j)}+w_{k1}^{(j)}y_1^{(j-1)}+w_{k2}^{(j)}y_2^{(j-1)}+\cdots+w_{kN_{j-1}}^{(j)}y_{N_{j-1}}^{(j-1)}\right).
\]</span></p>
<p>Assumindo que os <em>biases</em> foram inicializados com zero, sua variância também é nula. Portanto, precisamos calcular apenas a variância dos termos do lado direito da equação que contém os pesos. Assumindo independência entre os pesos e as entradas da camada <span class="math inline">\(j\)</span>, temos</p>
<p><span class="math display">\[
{\rm var}(w_{k\ell}^{(j)}y_\ell^{(j-1)})=[{\rm E}\{y_\ell^{(j-1)}\}]^2{\rm var}(w_{k\ell}^{(j)})+[{\rm E}\{w_{k\ell}^{(j)}\}]^2{\rm var}(y_\ell^{(j-1)})+{\rm var}(w_{k\ell}^{(j)}){\rm var}(y_\ell^{(j-1)}),
\]</span></p>
<p><span class="math inline">\(\ell=1,2,\cdots,N_{j-1}.\)</span> Considerando ainda que as entradas e os pesos têm médias nulas, a expressão anterior se reduz a</p>
<p><span class="math display">\[
{\rm var}(w_{k\ell}^{(j)}y_\ell^{(j-1)})={\rm var}(w_{k\ell}^{(j)}){\rm var}(y_\ell^{(j-1)}).
\]</span></p>
<p>Usando esse resultado no cálculo da variância de <span class="math inline">\(y_k^{(j)}\)</span>, chega-se a</p>
<p><span class="math display">\[
{\rm var}(y_k^{(j)})=N_{j-1}{\rm var}(w_{k\ell}^{(j)}){\rm var}(y_\ell^{(j-1)}).
\]</span></p>
<p>Como se deseja que <span class="math inline">\({\rm var}(y_k^{(j)})={\rm var}(y_\ell^{(j-1)})\)</span>, obtemos</p>
<p><span class="math display">\[
{\rm var}(w_{k\ell}^{(j)})=\frac{1}{N_{j-1}}.
\]</span></p>
<p>Diante desse resultado, a inicialização de Xavier propõe inicializar os pesos utilizando uma distribuição normal com média nula e desvio padrão <span class="math inline">\(1/\sqrt{N_{j-1}}\)</span>, ou seja</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm N}\left(0,\,\frac{1}{N_{j-1}}\right).
$}
\end{equation*}\]</span></p>
<p>Uma variante dessa inicialização, conhecida na literatura como inicialização de Glorot, leva em conta também o número de número de neurônios da camada <span class="math inline">\(j\)</span>, ou seja</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm N}\left(0,\,\frac{2}{N_{j-1}+N_j}\right).
$}
\end{equation*}\]</span></p>
<p>A ideia dessa inicialização é preservar também a variância do sinal retropropagado e para isso, considera que a variância do peso é aproximada por</p>
<p><span class="math display">\[
{\rm var}(w_{k\ell}^{(j)})\approx\frac{1}{(N_{j-1}+N_j)/2}.
\]</span></p>
<p>Há ainda variantes dessas inicializações que utilizam a distribuição uniforme. Assim, a inicialização de Xavier com distribuição uniforme é</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm U}\left[-\sqrt{\frac{3}{N_{j-1}}},\;+\sqrt{\frac{3}{N_{j-1}}}\,\right]

$}
\end{equation*}\]</span></p>
<p>e a inicialização de Glorot com distribuição uniforme é</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm U}\left[-\sqrt{\frac{6}{N_{j-1}+N_j}},\;+\sqrt{\frac{6}{N_{j-1}+N_j}}\,\right].
$}
\end{equation*}\]</span></p>
</section>
<section id="inicialização-de-he" class="level3">
<h3 class="anchored" data-anchor-id="inicialização-de-he">Inicialização de He</h3>
<p>O problema de desvanecimento ou explosão dos gradientes visto com funções de ativação do tipo sigmoidal geralmente não ocorre quando se usa ReLU. Diante disso, foi proposta uma inicialização alternativa à de Xavier para neurônios que consideram ReLU, conhecida como inicialização de He, no artigo <span class="citation" data-cites="He2015">(<a href="#ref-He2015" role="doc-biblioref">He et al. 2015</a>)</span>. Basicamente, a inicialização de He propõe que os pesos tenham o dobro da variância calculada anteriormente, ou seja,</p>
<p><span class="math display">\[
{\rm var}(w_{k\ell}^{(j)})=\frac{2}{N_{j-1}},
\]</span></p>
<p>o que leva à seguinte inicialização considerando a distribuição normal</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm N}\left(0,\,\frac{2}{N_{j-1}}\right)
$}
\end{equation*}\]</span></p>
<p>e à seguinte variante para distribuição uniforme</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  w_{k\ell}^{(j)}\sim {\rm U}\left[-\sqrt{\frac{6}{N_{j-1}}},\;+\sqrt{\frac{6}{N_{j-1}}}\,\right].
$}
\end{equation*}\]</span></p>
</section>
</section>
<section id="passo-de-adaptação" class="level2">
<h2 class="anchored" data-anchor-id="passo-de-adaptação">Passo de Adaptação</h2>
<p>Um dos principais hiperparâmetros que precisam ser ajustados no treinamento de uma rede neural é o passo de adaptação ou taxa de aprendizagem. Se o passo for muito baixo, a convergência do algoritmo de treinamento será muito lenta como mostrado na <a href="#fig-passos" class="quarto-xref">Figura&nbsp;4</a> (a). Em contrapartida, um passo muito elevado pode levar o algoritmo à divergência, caso ilustrado na <a href="#fig-passos" class="quarto-xref">Figura&nbsp;4</a> (c). Na <a href="#fig-passos" class="quarto-xref">Figura&nbsp;4</a> (b), considera-se um passo ideal que proporciona uma rápida convergência. O passo de adaptação ideal depende da superfície de desempenho, que, por sua vez, depende da arquitetura da rede e do conjunto de dados. O treinamento da rede pode ser acelerado quando se utiliza uma taxa de aprendizagem ideal <span class="citation" data-cites="Jordan2018learning">(<a href="#ref-Jordan2018learning" role="doc-biblioref">Jordan 2018</a>)</span>.</p>
<div id="fig-passos" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-passos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/passos.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-passos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;4: Três passos de adaptação diferentes: (a) passo muito baixo que requer muitas iterações até que o algoritmo atinja o mínimo da função custo; (b) passo ótimo que faz com que o algoritmo atinja o mínimo rapidamente e (c) passo muito elevado que pode levar o algoritmo à divergência. <a href="https://www.jeremyjordan.me/nn-learning-rate">[Fonte]</a>.
</figcaption>
</figure>
</div>
<p>Uma das técnicas mais utilizadas para ajustar o passo de adaptação é a <em>learning rate annealing</em>. Nessa técnica, o valor do passo deve ser relativamente alto no início e diminuir gradualmente ao longo do treinamento. Com um passo elevado no início do treinamento, os pesos e <em>biases</em> são ajustados rapidamente para valores “bons”, ou seja, uma taxa alta pode fazer com que o algoritmo “pule” mínimos locais. Em seguida, uma taxa de aprendizagem pequena faz um ajuste fino, possibilitando o algoritmo explorar as partes “mais profundas” da função custo. A forma mais comum de fazer isso é considerar o decaimento do passo em escada ou exponencial, como ilustrado na <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a>.</p>
<p>No decaimento em escada com degraus uniformes da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (a), o passo da <span class="math inline">\(k\)</span>-ésima época é calculado como</p>
<p><span class="math display">\[
\eta(k)=\eta_0-\Delta \eta \lfloor k/\Delta k\rfloor,
\]</span></p>
<p>em que <span class="math inline">\(\eta_0\)</span> é o valor inicial do passo, <span class="math inline">\(\Delta \eta\)</span> o valor do decaimento e <span class="math inline">\(\Delta k\)</span> o número de épocas em que o passo é mantido fixo. No caso da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (a), foram usados <span class="math inline">\(\eta_0=0,\!1\)</span>, <span class="math inline">\(\Delta \eta=0,\!0101\)</span> e <span class="math inline">\(\Delta k=20\)</span>.</p>
<p>No decaimento em escada com degraus não uniformes da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (b), o passo da <span class="math inline">\(k\)</span>-ésima época é calculado como</p>
<p><span class="math display">\[
\eta(k)=\eta_0\Delta \eta^{\lfloor k/\Delta k\rfloor}.
\]</span></p>
<p>No caso da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (b), foram usados <span class="math inline">\(\eta_0=0,\!1\)</span>, <span class="math inline">\(\Delta \eta=0,\!5\)</span> e <span class="math inline">\(\Delta k=20\)</span>.</p>
<p>Por fim, no decaimento exponencial da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (c), o passo da <span class="math inline">\(k\)</span>-ésima época é calculado como</p>
<p><span class="math display">\[
\eta(k)=\eta_0 e^{-a k},\;\;a&gt;0.
\]</span></p>
<p>No caso da <a href="#fig-decaimento" class="quarto-xref">Figura&nbsp;5</a> (c), foram usados <span class="math inline">\(\eta_0=0,\!1\)</span> e <span class="math inline">\(a=0,\!01\)</span>.</p>
<div id="fig-decaimento" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-decaimento-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/decaimento.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-decaimento-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5: <em>Learning rate annealing</em>: (a) decaimento em escada uniforme, (b) decaimento em escada não uniforme e (c) decaimento exponencial.
</figcaption>
</figure>
</div>
<p>O desafio de usar esquemas de ajuste dos passos de adaptação é que seus hiperparâmetros precisam ser definidos com antecedência e dependem da arquitetura da rede e do problema. Além disso, pode ser conveniente adaptar pesos de neurônios de camadas diferentes com passos distintos. Algoritmos de otimização como Adam e RMSprop resolvem esses problemas, pois ajustam os passos de adaptação de forma automática com o uso de regularização, como veremos posteriormente.</p>
</section>
<section id="mini-batch" class="level2">
<h2 class="anchored" data-anchor-id="mini-batch"><em>Mini-batch</em></h2>
<p>Abordamos anteriormente o treinamento do algoritmo LMS nos modos <em>batch</em>, <em>mini-batch</em> e estocástico<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Como o algoritmo LMS foi proposto para aplicações de tempo real, o modo estocástico é o mais utilizado. A cada dado de entrada se deseja ter o dado de saída correspondente com o menor atraso possível, ou seja, o treinamento ocorre junto com a inferência. A saída e o erro calculados no treinamento são utilizados para atualizar os pesos e ao mesmo tempo para se obter a estimativa ou classificação desejada.</p>
<p>No caso das redes neurais, o modo <em>mini-batch</em> é o mais utilizado. Geralmente, a inferência não é realizada durante o treinamento. A saída e o erro são utilizados no treinamento apenas para atualizar os pesos do algoritmo. Depois do treinamento, fixam-se os pesos para então se fazer a inferência e testar o classificador ou regressor. Apesar de termos abordado os três modos de treinamento apenas no algoritmo LMS, a extensão para redes neurais é direta.</p>
<p>O uso de <em>mini-batch</em> no processo de aprendizado consiste em dividir aleatoriamente o conjunto de treinamento da rede em blocos de tamanho previamente definido, embaralhando-se as amostras do conjunto. A atualização dos pesos e <em>biases</em> ocorre apenas depois que são calculados os gradientes de todos os elementos de um <em>mini-batch</em>. Dessa forma, a atualização dos parâmetros da rede está associada à média dos gradientes de um <em>mini-batch</em>. Considera-se passada uma época quando todos os <em>mini-batches</em> são percorridos. Após cada época do algoritmo de otimização, a divisão do conjunto de treinamento entre <em>mini-batches</em> é refeita de maneira aleatória, embaralhando-se novamente o conjunto de treinamento. <strong>O tamanho de cada <em>mini-batch</em> é um hiperparâmetro e não muda no decorrer das épocas.</strong></p>
<p>Quando se considera que cada <em>mini-batch</em> é formado apenas por uma amostra do conjunto de treinamento, diz-se que o método de atualização de parâmetros é estocástico. O uso do método estocástico para atualização de parâmetros de uma rede neural é pouco eficiente, pois a atualização ocorre em direções distintas do mínimo da função custo, o que faz com que o algoritmo leve mais épocas para convergir. O método estocástico também anula as vantagens computacionais de uma implementação matricial do algoritmo, uma vez que as atualizações são realizadas sobre cada amostra de treinamento.</p>
<p>Quando um <em>mini-batch</em> possui todos os elementos do conjunto de treinamento, nomeia-se o método de atualização de parâmetros apenas como <em>batch</em>. Com o método <em>batch</em>, os parâmetros são sempre atualizados na direção do mínimo da função custo. Diante disso, o <em>batch</em> seria o modo de treinamento ideal se não houvesse limitações computacionais. Como é necessário esperar que todo o conjunto de treinamento seja percorrido para se realizar a atualização dos parâmetros, o modo de treinamento <em>batch</em> é muito demorado e computacionalmente ineficiente quando comparado com o <em>mini-batch</em>.</p>
</section>
<section id="dropout" class="level2">
<h2 class="anchored" data-anchor-id="dropout"><em>Dropout</em></h2>
<p>Outro problema que pode aparecer no treinamento das redes neurais é o <em>overfitting</em>, que ocorre quando há uma diferença significativa entre o desempenho da rede sobre seu conjunto de treinamento e sobre um outro conjunto distinto de dados, o conjunto de teste. Neste caso, a rede se especializa tanto no conjunto de treinamento, que não apresenta capacidade de generalização satisfatória para outros dados. Uma das técnicas mais utilizadas para evitar esse problema é o <em>dropout</em>. Essa técnica basicamente inativa aleatoriamente, em cada iteração do algoritmo <em>backpropagation</em>, diferentes neurônios de cada camada oculta da rede. Cada neurônio é inativado com probabilidade <span class="math inline">\(p\)</span>, sendo <span class="math inline">\(p\)</span> o hiperparâmetro associado a essa esquema. Na <a href="#fig-dropout" class="quarto-xref">Figura&nbsp;6</a>, exemplifica-se a aplicação do <em>dropout</em> com <span class="math inline">\(p = 0,\!5\)</span>. Observe que metade dos neurônios de cada camada oculta (neurônios destacadas em vermelho) foram inativados em uma determinada iteração. Quando um neurônio é inativado, seu gradiente é nulo de modo que seus pesos não são atualizados. Heuristicamente, a eliminação temporária de diferentes conjuntos de neurônios leva ao treinamento de redes neurais distintas. Dessa forma, o procedimento de eliminação é equivalente ao cálculo da média dos efeitos de um grande número de redes distintas. Como elas vão se adaptar de diferentes maneiras, isso possibilita a redução do <em>overfitting</em>, pois será mais difícil para a rede se especializar nos dados de treinamento <span class="citation" data-cites="Goodfellow2016">(<a href="#ref-Goodfellow2016" role="doc-biblioref">Goodfellow, Bengio, e Courville 2016</a>)</span>.</p>
<div id="fig-dropout" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dropout-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/dropout.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dropout-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6: Exemplo de aplicação do <em>dropout</em> em uma rede MLP com <span class="math inline">\(p = 0,5\)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="momentum" class="level2">
<h2 class="anchored" data-anchor-id="momentum"><em>Momentum</em></h2>
<p>Como vimos anteriormente, o algoritmo LMS é uma aproximação estocástica do algoritmo do gradiente exato (<em>steepest descent</em>). Vimos também que existe um compromisso entre a velocidade de convergência e a precisão da solução. Quanto menor o passo de adaptação, mais lento é o algoritmo e os pesos variam menos em torno da solução de Wiener. Quanto maior o passo, maior a sua velocidade de convergência e maior também a variação dos pesos torno da solução ótima. O algoritmo também pode divergir dependendo do valor do passo e neste caso, os pesos vão para infinito. O mesmo acontece com o algoritmo <em>backpropagation</em>: quanto menor for o passo de adaptação, menores serão as mudanças nos pesos da rede de uma iteração para outra, mais suave será a trajetória no espaço dos pesos e mais lenta a taxa de aprendizagem. Se aumentarmos muito o passo de adaptação para acelerar a taxa de aprendizagem, as mudanças dos pesos de uma iteração para outra também aumentam e o algoritmo pode divergir.</p>
<p>Um método simples de aumentar a taxa de aprendizagem sem causar divergência é modificar a adaptação do <em>backpropagation</em> incluindo um termo chamado <em>momentum</em>. Antes de introduzir esse termo, vamos lembrar da atualização da matriz de pesos da Camada <span class="math inline">\(j\)</span> da MLP com o algoritmo <em>backpropagation</em>:</p>
<p><span class="math display">\[
\mathbf{W}^{(j)}(n)=\mathbf{W}^{(j)}(n-1)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(n),
\]</span></p>
<p>em que</p>
<p><span class="math display">\[
\boldsymbol{\Delta}_{\delta}^{(j)}(n)=\boldsymbol{\delta}^{(j)}(n)[\mathbf{x}^{(j)}(n)]^{\rm T}.
\]</span></p>
<p>Definindo agora a matriz <span class="math display">\[
\boldsymbol{\Delta}\mathbf{W}^{(j)}(n-1)\triangleq\mathbf{W}^{(j)}(n-1)-\mathbf{W}^{(j)}(n-2),
\]</span></p>
<p>que representa a diferença entre a matriz de pesos da iteração <span class="math inline">\(n-1\)</span> e da iteração <span class="math inline">\(n-2\)</span>, a atualização do <em>backpropagation</em> com <em>momentum</em> fica</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \mathbf{W}^{(j)}(n)=\mathbf{W}^{(j)}(n-1)+\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(n-1)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(n),
$}
\end{equation*}\]</span></p>
<p>em que <span class="math inline">\(0\leq \alpha&lt;1\)</span> é a constante de <em>momentum</em>. Observe que <span class="math inline">\(\alpha=0\)</span> leva essa atualização à forma padrão do <em>backpropagation</em> sem <em>momentum</em>. Usando a definição <span class="math inline">\(\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)\)</span>, podemos reescrever essa equação de atualização como</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
  \boldsymbol{\Delta}\mathbf{W}^{(j)}(n)=\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(n-1)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(n).
$}
\end{equation*}\]</span></p>
<p>Para entender o efeito do termo de <em>momentum</em>, note que</p>
<p><span class="math display">\[\begin{align*}
\boldsymbol{\Delta}\mathbf{W}^{(j)}(1)&amp;=\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(1)\nonumber\\
\boldsymbol{\Delta}\mathbf{W}^{(j)}(2)&amp;=\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(1)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(2)\nonumber\\
&amp;=\alpha\left[\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(1)\right]+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(2)\nonumber\\
&amp;=\alpha^2\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)+\eta\left[\alpha\boldsymbol{\Delta}_{\delta}^{(j)}(1)+\boldsymbol{\Delta}_{\delta}^{(j)}(2)\right]\nonumber\\
\boldsymbol{\Delta}\mathbf{W}^{(j)}(3)&amp;=\alpha\boldsymbol{\Delta}\mathbf{W}^{(j)}(2)+\eta\boldsymbol{\Delta}_{\delta}^{(j)}(3)\nonumber\\
&amp;=\alpha^3\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)+\eta\left[\alpha^2\boldsymbol{\Delta}_{\delta}^{(j)}(1)+\alpha\boldsymbol{\Delta}_{\delta}^{(j)}(2)+\boldsymbol{\Delta}_{\delta}^{(j)}(3)\right]\nonumber\\
&amp;\vdots\nonumber\\
\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)&amp;=\alpha^n\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)+\eta\sum_{k=1}^n \alpha^{n-k}\boldsymbol{\Delta}_{\delta}^{(j)}(k).\nonumber
\end{align*}\]</span></p>
<p>O termo <span class="math inline">\(\alpha^n\boldsymbol{\Delta}\mathbf{W}^{(j)}(0)\)</span> tende a zero a medida que o número de iterações aumenta, uma vez que <span class="math inline">\(0\leq\alpha&lt;1\)</span> e os pesos são inicializados com valores finitos. Assim, podemos escrever</p>
<p><span class="math display">\[
\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)=\eta\sum_{k=1}^n \alpha^{n-k}\boldsymbol{\Delta}_{\delta}^{(j)}(k).
\]</span></p>
<p>Essa equação nos possibilita entender os efeitos benéficos do <em>momentum</em>, enumerados a seguir <span class="citation" data-cites="Haykin2009">(<a href="#ref-Haykin2009" role="doc-biblioref">Haykin 2009</a>)</span>:</p>
<ul>
<li>o ajuste <span class="math inline">\(\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)\)</span> representa a soma de uma série temporal ponderada exponencialmente. Como <span class="math inline">\(0\leq \alpha&lt;1\)</span>, consideram-se pesos maiores para ajustes recentes e pesos menores para os mais antigos. Dessa forma, <span class="math inline">\(\alpha\)</span> também é chamado na literatura de fator de esquecimento;</li>
<li>quando o termo <span class="math inline">\(\boldsymbol{\Delta}_{\delta}^{(j)}(n)\)</span> tem o mesmo sinal algébrico em sucessivas iterações, a matriz <span class="math inline">\(\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)\)</span> cresce em magnitude e a matriz de pesos <span class="math inline">\(\mathbf{W}^{(j)}(n)\)</span> é ajustada com uma grande quantidade. Diante disso, o <em>momentum</em> tende a acelerar a convergência do <em>backpropagation</em> em direções de descida mais íngreme;</li>
<li>quando o sinal algébrico do termo <span class="math inline">\(\boldsymbol{\Delta}_{\delta}^{(j)}(n)\)</span> muda em sucessivas iterações, a matriz <span class="math inline">\(\boldsymbol{\Delta}\mathbf{W}^{(j)}(n)\)</span> diminui em magnitude e a matriz de pesos <span class="math inline">\(\mathbf{W}^{(j)}(n)\)</span> é ajustada com uma pequena quantidade. Diante disso, o <em>momentum</em> tem o efeito de estabilizador em direções que oscilam em sinal.</li>
</ul>
<p>Em suma, a incorporação do <em>momentum</em> no algoritmo <em>backpropagation</em> pode trazer alguns efeitos benéficos no aprendizado, incluindo a possibilidade de evitar que o algoritmo fique estagnado em um mínimo local.</p>
<p>A seguir vamos comparar o <em>backpropagation</em> com e sem <em>momentum</em>.</p>
<section id="exemplo-das-meias-luas" class="level3">
<h3 class="anchored" data-anchor-id="exemplo-das-meias-luas">Exemplo das meias-luas</h3>
<p>No exemplo das meias-luas com <span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=-4\)</span> e <span class="math inline">\(r_3=6\)</span>, vimos que uma MLP com configuração 3-2-1 treinada com o <em>backpropagation</em> sem <em>momentum</em> é capaz de classificar corretamente os dados dependendo da inicialização. Para verificar o efeito benéfico de se utilizar <em>momentum</em>, vamos considerar uma MLP com configuração 3-10-1. Essa mudança de configuração se deve ao fato de que o <em>backpropagation</em> com <em>momentum</em> na configuração anterior se comporta de maneira análoga ao caso sem <em>momentum</em>. Considerou-se ainda o modo de treinamento <em>mini-batch</em> (<span class="math inline">\(N_0=2\)</span>, <span class="math inline">\(N_t=1000\)</span>, <span class="math inline">\(N_b=50\)</span> e <span class="math inline">\(N_e=2000\)</span>). Os pesos e <em>biases</em> foram inicializados com números aleatórios gerados a partir de uma distribuição uniforme no intervalo <span class="math inline">\([-10^{-2}, 10^{-2}]\)</span>, o passo de adaptação foi considerado fixo e igual a <span class="math inline">\(\eta=0,\!1\)</span> e a constante de momentum igual a <span class="math inline">\(\alpha=0,\!9\)</span>. Além disso, a tangente hiperbólica foi utilizada como função de ativação de todos os neurônios e a função custo foi a do erro quadrático médio (MSE).</p>
<p>Na <a href="#fig-momentum" class="quarto-xref">Figura&nbsp;7</a>, são mostradas a função custo ao longo das épocas de treinamento, a classificação dos dados de teste e a curva de separação das regiões para uma determinada inicialização. Verifica-se que o algoritmo <em>backpropagation</em> sem <em>momentum</em> não consegue escapar do mínimo local, obtendo <span class="math inline">\(6,\!65\%\)</span> de taxa de erro de classificação. Ao se utilizar <em>momentum</em>, percebe-se que o algoritmo apresenta um MSE próximo do caso sem <em>momentum</em> durante as <span class="math inline">\(250\)</span> épocas iniciais do treinamento. Depois disso, eles seguem caminhos diferentes: o algoritmo sem <em>momentum</em> fica parado no mínimo local correspondente a um MSE aproximadamente <span class="math inline">\(-7\)</span> dB, enquanto o algoritmo com <em>momentum</em> consegue atingir um MSE de aproximadamente <span class="math inline">\(-45\)</span> dB na época <span class="math inline">\(2000\)</span>. Isso é suficiente para não gerar erros de classificação.</p>
<div id="fig-momentum" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-momentum-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/momentum.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-momentum-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7: O problema de classificação das meias-luas (<span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=-4\)</span> e <span class="math inline">\(r_3=6\)</span>). Função custo ao longo das épocas de treinamento, classificação dos dados de teste (<span class="math inline">\(N_{\text{teste}}=2\times 10^3\)</span>) e curva de separação das regiões obtidas com uma rede MLP (3-10-1) treinada em <em>mini-batch</em> (<span class="math inline">\(N_0=2\)</span>, <span class="math inline">\(N_t=10^3\)</span>, <span class="math inline">\(N_b=50\)</span>) com o algoritmo <em>backpropagation</em> sem <em>momentum</em> (<span class="math inline">\(\eta=0,\!1\)</span>) e com <em>momentum</em> (<span class="math inline">\(\eta=0,1\)</span>, <span class="math inline">\(\alpha=0,\!9\)</span>); função de ativação tangente hiperbólica e pesos e <em>biases</em> inicializados com números aleatórios gerados a partir de uma distribuição uniforme no intervalo <span class="math inline">\([-10^{-2}, 10^{-2}]\)</span>.
</figcaption>
</figure>
</div>
<p>O comportamento observado na <a href="#fig-momentum" class="quarto-xref">Figura&nbsp;7</a> nem sempre se repete, pois depende da inicialização. Em muitos casos, os algoritmos com e sem <em>momentum</em> apresentam comportamentos semelhantes. Ainda podem ocorrer situações em que o algoritmo com <em>momentum</em> não consegue evitar mínimos locais, enquanto o algoritmo sem <em>momentum</em> consegue. Apesar disso, o uso de <em>momentum</em> é considerado benéfico na maior parte das vezes. Isso de deve ao fato de que quando implementado junto com outras técnicas pode fazer com que a rede atinja valores de MSE mais baixos no treinamento, o que é indício de que mínimos locais foram evitados.</p>
</section>
</section>
<section id="otimizador-adam" class="level2">
<h2 class="anchored" data-anchor-id="otimizador-adam">Otimizador Adam</h2>
<p>A escolha do algoritmo de otimização é essencial em Aprendizado de Máquina. O algoritmo de otimização Adam (<em>adaptive moment estimation</em>) <span class="citation" data-cites="Adam2015">(<a href="#ref-Adam2015" role="doc-biblioref">Kingma e Ba 2015</a>)</span> é uma extensão do algoritmo do gradiente estocástico e tem sido muito utilizado recentemente. Ao introduzir o algoritmo, os autores listam os benefícios de se usar Adam em problemas de otimização não convexa:</p>
<ol type="1">
<li>simples de implementar, computacionalmente eficiente e requer poucos requisitos de memória;</li>
<li>adequado quando se usa muitos dados e/ou parâmetros;</li>
<li>apropriado para problemas não estacionários e problemas com gradientes muito ruidosos e/ou esparsos; e</li>
<li>os hiperparâmetros têm interpretação intuitiva e são simples de ajustar.</li>
</ol>
<p>O otimizador Adam atualiza os pesos e <em>biases</em> de uma rede neural a partir dos gradientes calculados na iteração atual e em iterações passadas, de forma a tornar mais estável o processo de aprendizado da rede, evitando-se assim variações excessivas em direções que não são a do mínimo da função custo. Ele combina o gradiente estocástico com <em>momentum</em> com o otimizador RMSprop (<em>root mean squared propagation</em>). Para introduzir esse otimizador, vamos antes introduzir o otimizador RMSprop.</p>
<p>À medida que os dados se propagam na rede, os gradientes calculados para atualização dos parâmetros podem ficar muito pequenos ou muito grandes. Gradientes muito pequenos podem levar à estagnação do <em>backpropagation</em>. Em contrapartida, gradientes muito grandes podem levar à divergência do algoritmo. O otimizador RMSprop foi proposto por G. Hinton, um dos “pais” do <em>backpropagation</em>, para lidar com esse problema usando uma média móvel dos gradientes ao quadrado. Isso gera uma normalização no algoritmo, que passa a ser encarado como um algoritmo de passo variável. Assim, quando os gradientes são grandes, o método diminui o passo para evitar a divergência e quando os gradientes são pequenos, ele aumenta o passo para evitar a estagnação. A título de curiosidade, o algoritmo RMSprop foi proposto por Hinton na sexta aula do curso <em>Neural Networks for Machine Learning</em> e diferente do Adam, não foi publicado.</p>
<p>Quando deduzimos o algoritmo <em>backpropagation</em>, definimos a matriz</p>
<p><span class="math display">\[
\boldsymbol{\Delta}_{\delta}^{(j)}(n)=\boldsymbol{\delta}^{(j)}(n)[\mathbf{x}^{(j)}(n)]^{\rm T},
\]</span></p>
<p>que contém o negativo dos vetores gradiente de todos os neurônios da Camada <span class="math inline">\(j\)</span>. Vamos agora definir a matriz <span class="math inline">\(\mathbf{S}^{(j)}(n)\)</span>, calculada recursivamente como</p>
<p><span class="math display">\[
\mathbf{S}^{(j)}(n) = \beta_2\mathbf{S}^{(j)}(n-1) + (1-\beta_2)\left[\boldsymbol{\Delta}_{\delta}^{(j)}(n)\right]^{\odot 2},
\]</span></p>
<p>em que <span class="math inline">\(\mathbf{S}^{(j)}(0)=\boldsymbol{0}\)</span>, <span class="math inline">\(0\ll \beta_2&lt; 1\)</span> é um hiperparâmetro que faz o papel de um fator de esquecimento e a operação <span class="math inline">\([\boldsymbol{\Delta}_{\delta}^{(j)}(n)]^{\odot 2}\)</span> indica que cada elemento da matriz <span class="math inline">\(\boldsymbol{\Delta}_{\delta}^{(j)}(n)\)</span> é elevado ao quadrado. Levando em conta a inicialização com valores nulos, a equação recursiva para a matriz <span class="math inline">\(\mathbf{S}^{(j)}(n)\)</span> pode ser reescrita como</p>
<p><span class="math display">\[
\mathbf{S}^{(j)}(n)=(1-\beta_2)\displaystyle \sum_{k=1}^{n}\beta_2^{n-k}\left[\boldsymbol{\Delta}_{\delta}^{(j)}(k)\right]^{\odot 2}.
\]</span></p>
<p>A menos da constante <span class="math inline">\((1-\beta_2)\)</span>, observa-se que essa estimativa considera pesos maiores para os gradientes ao quadrado mais recentes e pesos menores para os mais antigos, o que caracteriza uma janela exponencial. Utilizando a matriz <span class="math inline">\(\mathbf{S}^{(j)}(n)\)</span>, a atualização dos pesos e <em>biases</em> da Camada <span class="math inline">\(j\)</span> da rede segundo o otimizador RMSprop é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\mathbf{W}^{(j)}(n) = \mathbf{W}^{(j)}(n-1) + \eta\;{\boldsymbol{\Delta}_{\delta}^{(j)}(n)} \oslash \left[{\left[{\mathbf{S}}^{(j)}(n)\right]^{\odot \frac{1}{2}} + \varepsilon}\mathbf{1}\right],
$}
\end{equation*}\]</span></p>
<p>em que <span class="math inline">\(\oslash\)</span> se refere a divisão de Hadamard, que resulta em uma matriz em que cada elemento é igual à divisão do respectivo elemento da matriz à esquerda pelo respectivo elemento da matriz à direita, <span class="math inline">\(\varepsilon\)</span> é uma constante positiva pequena (e.g., <span class="math inline">\(\varepsilon=10^{-8}\)</span>) usada para evitar divisões por zero e <span class="math inline">\(\mathbf{1}\)</span> é uma matriz com todos os elementos iguais a 1 e dimensões adequadas para que a soma seja possível de ser calculada. Para entender melhor essas operações, suponha que na iteração <span class="math inline">\(n\)</span> dispomos das matrizes</p>
<p><span class="math display">\[
\boldsymbol{\Delta}_{\delta}^{(j)}(n)=\left[\begin{array}{cc}
                a &amp; b \\
                c &amp; d
              \end{array}
\right]\;\;\;\text{e}\;\;\; {\mathbf{S}}^{(j)}(n)=\left[\begin{array}{cc}
                 e &amp; f \\
                 g &amp; h
               \end{array}
\right].
\]</span></p>
<p>Assim,</p>
<p><span class="math display">\[
{\boldsymbol{\Delta}_{\delta}^{(j)}(n)} \oslash \left({\left[{\mathbf{S}}^{(j)}(n)\right]^{\odot \frac{1}{2}} + \varepsilon\mathbf{1}}\right)=\left[\begin{array}{ccc}
                 \displaystyle\frac{a}{\sqrt{e}+\varepsilon} &amp;&amp; \displaystyle\frac{b}{\sqrt{f}+\varepsilon} \\
                 &amp;&amp;\\
                 \displaystyle\frac{c}{\sqrt{g}+\varepsilon} &amp;&amp; \displaystyle\frac{d}{\sqrt{h}+\varepsilon}
               \end{array}
\right].
\]</span></p>
<p>Em vez de usar o negativo dos gradientes de <span class="math inline">\(\boldsymbol{\Delta}_{\delta}^{(j)}(n)\)</span>, o otimizador Adam também considera uma janela exponencial para estimar esses gradientes. Para isso, define-se a matriz</p>
<p><span class="math display">\[
\mathbf{V}^{(j)}(n) = \beta_1\mathbf{V}^{(j)}(n-1) + (1-\beta_1)\boldsymbol{\Delta}_{\delta}^{(j)}(n)
\]</span></p>
<p>em que <span class="math inline">\(\mathbf{V}^{(j)}(0)=\boldsymbol{0}\)</span> e <span class="math inline">\(0\ll \beta_1&lt; 1\)</span> é um hiperparâmetro que também faz o papel de um fator de esquecimento. Novamente, levando em conta a inicialização com valores nulos, a equação recursiva para <span class="math inline">\(\mathbf{V}^{(j)}(n)\)</span> pode ser reescrita como</p>
<p><span class="math display">\[
\mathbf{V}^{(j)}(n)=(1-\beta_1)\displaystyle \sum_{k=1}^{n}\beta_1^{n-k}\boldsymbol{\Delta}_{\delta}^{(j)}(k).
\]</span></p>
<p>As inicializações das matrizes <span class="math inline">\(\mathbf{S}^{(j)}\)</span> e <span class="math inline">\(\mathbf{V}^{(j)}\)</span> com elementos nulos podem gerar distorções no início do treinamento do algoritmo. Observe que na atualização do RMSprop, o valor da matriz <span class="math inline">\(\mathbf{S}^{(j)}(n)\)</span> para <span class="math inline">\(n=1\)</span> é <span class="math inline">\(\mathbf{S}^{(j)}(1)=(1-\beta_2)[\boldsymbol{\Delta}_{\delta}^{(j)}(1)]^{\odot 2}\)</span>, o que tende a ser muito pequeno já que <span class="math inline">\(0\ll \beta_2 &lt;1\)</span>. Para amenizar isso, são definidas as as matrizes de correção</p>
<p><span class="math display">\[\begin{align*}
\overline{\mathbf{V}}^{(j)}(n) &amp;= \frac{1}{1 - \beta_1^n}\,{\mathbf{V}^{(j)}(n)}\;\; \textnormal{e} \nonumber\\
\overline{\mathbf{S}}^{(j)}(n) &amp;= \frac{1}{1 - \beta_2^n}\,{\mathbf{S}^{(j)}(n)}. \nonumber
\end{align*}\]</span></p>
<p>Como <span class="math inline">\(0\ll \beta_1, \beta_2&lt;1\)</span>, as matrizes corrigidas <span class="math inline">\(\overline{\mathbf{V}}^{(j)}(n)\)</span> e <span class="math inline">\(\overline{\mathbf{S}}^{(j)}(n)\)</span> tendem às matrizes <span class="math inline">\({\mathbf{V}}^{(j)}(n)\)</span> e <span class="math inline">\({\mathbf{S}}^{(j)}(n)\)</span>, respectivamente, a medida que <span class="math inline">\(n\)</span> aumenta. Ou seja, o efeito da correção ocorre apenas no início do treinamento, como esperado. Utilizando essas matrizes corrigidas, a atualização dos pesos e <em>bias</em> da Camada <span class="math inline">\(j\)</span> da rede segundo o otimizador Adam é dada por</p>
<p><span class="math display">\[\begin{equation*}
\fbox{$\displaystyle
\mathbf{W}^{(j)}(n) = \mathbf{W}^{(j)}(n-1) + \eta\;{\overline{\mathbf{V}}^{(j)}(n)} \oslash \left[{\left[{\overline{\mathbf{S}}^{(j)}(n)}\right]^{\odot \frac{1}{2}} + \varepsilon\mathbf{1}}\right].
$}
\end{equation*}\]</span></p>
<p>A seguir vamos comparar o <em>backpropagation</em> com o RMSprop e Adam.</p>
<section id="exemplo-das-meias-luas-1" class="level3">
<h3 class="anchored" data-anchor-id="exemplo-das-meias-luas-1">Exemplo das meias-luas</h3>
<p>No exemplo das meias-luas com <span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=-4\)</span> e <span class="math inline">\(r_3=6\)</span>, vimos que uma MLP com configuração 3-2-1 treinada com o <em>backpropagation</em> sem <em>momentum</em> é capaz de classificar corretamente os dados dependendo da inicialização. No entanto, quando consideramos uma rede mais profunda, a probabilidade do <em>backpropagation</em> de ficar parado em mínimos locais é alta. Como exemplo, vamos considerar uma MLP com cinco camadas e configuração 3-4-4-2-1 no modo de treinamento <em>mini-batch</em> (<span class="math inline">\(N_0=2\)</span>, <span class="math inline">\(N_t=10^3\)</span>, <span class="math inline">\(N_b=50\)</span> e <span class="math inline">\(N_e=5000\)</span>). Os pesos e <em>biases</em> foram inicializados com números aleatórios gerados a partir de uma distribuição uniforme no intervalo <span class="math inline">\([-10^{-2}, 10^{-2}]\)</span> e o passo de adaptação foi considerado fixo e igual a <span class="math inline">\(\eta=0,\!5\)</span> para todos os algoritmos. Além disso, a tangente hiperbólica foi utilizada como função de ativação de todos os neurônios e a função custo foi a do erro quadrático médio (MSE). Por fim, os hiperparâmetros do algoritmo RMSprop foram selecionados como <span class="math inline">\(\beta_2=0,\!99\)</span> e <span class="math inline">\(\varepsilon=10^{-4}\)</span> e do Adam como <span class="math inline">\(\beta_1=\beta_2=0,\!99\)</span> e <span class="math inline">\(\varepsilon=10^{-4}\)</span>.</p>
<p>Na <a href="#fig-adam1" class="quarto-xref">Figura&nbsp;8</a>, na <a href="#fig-adam2" class="quarto-xref">Figura&nbsp;9</a> e na <a href="#fig-adam4" class="quarto-xref">Figura&nbsp;10</a>, são mostradas a função custo ao longo das épocas, a classificação dos dados de teste e a curva de separação das regiões para três inicializações diferentes, respectivamente. Nas três casos, verifica-se que o algoritmo <em>backpropagation</em> sem <em>momentum</em> não consegue escapar do mínimo local, obtendo <span class="math inline">\(50\%\)</span> de taxa de erro de classificação. No caso da <a href="#fig-adam1" class="quarto-xref">Figura&nbsp;8</a>, os comportamentos do RMSprop e dos Adam durante o treinamento são muito parecidos: ambos atingiram o patamar de aproximadamente <span class="math inline">\(-100\)</span> dB e taxas de erro de classificação de <span class="math inline">\(0,\!1\%\)</span> e <span class="math inline">\(0\%\)</span>, respectivamente. Mudando a inicialização, observamos na <a href="#fig-adam2" class="quarto-xref">Figura&nbsp;9</a> um comportamento diferente para o Adam, que apesar de escapar de um mínimo local logo depois da época <span class="math inline">\(200\)</span>, apresenta um MSE que oscila entre <span class="math inline">\(-10\)</span> dB e <span class="math inline">\(-20\)</span> dB, atingindo valores menores em determinadas épocas. No entanto, a partir da época <span class="math inline">\(3700\)</span>, ele parece ter ficado parado em um mínimo local, o que levou a um MSE de aproximadamente <span class="math inline">\(-8,\!5\)</span> dB e a um erro de classificação de <span class="math inline">\(2\%\)</span>. Mudando novamente a inicialização, observamos na <a href="#fig-adam4" class="quarto-xref">Figura&nbsp;10</a> que o Adam atingiu novamente o patamar de <span class="math inline">\(-100\)</span> dB no treinamento e <span class="math inline">\(0\%\)</span> de taxa de erro de classificação. Já o RMSprop ficou parado em um mínimo local que levou a um MSE de aproximadamente <span class="math inline">\(-7\)</span> dB e a uma taxa de erro de classificação de <span class="math inline">\(6,\!8\%\)</span>.</p>
<p>A partir desse experimento, verifica-se que mudar o algoritmo de otimização é benéfico para evitar mínimos locais, principalmente quando comparamos o RMSprop e o Adam com o <em>backpropagation</em> sem <em>momentum</em> em redes profundas. No entanto, a adoção de um desses algoritmos de otimização apenas não é suficiente para evitar mínimos locais, como vimos na <a href="#fig-adam2" class="quarto-xref">Figura&nbsp;9</a> e na <a href="#fig-adam4" class="quarto-xref">Figura&nbsp;10</a>. Considerando o Adam e o RMSprop, observa-se na literatura que o Adam tem sido preferido na maior parte das aplicações. No entanto, o Adam tem algumas desvantagens:</p>
<ol type="1">
<li>não converge em alguns exemplos simples, como pudemos comprovar no exemplo da <a href="#fig-adam2" class="quarto-xref">Figura&nbsp;9</a>;</li>
<li>o erro de generalização pode ser grande em muitos problemas de visão computacional;</li>
<li>requer mais memória que o método do gradiente; e</li>
<li>tem dois hiperparâmetros e portanto, alguns ajustes podem ser necessários.</li>
</ol>
<div id="fig-adam1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-adam1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/adam1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-adam1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8: O problema de classificação das meias-luas (<span class="math inline">\(r_1=10\)</span>, <span class="math inline">\(r_2=-4\)</span> e <span class="math inline">\(r_3=6\)</span>). Função custo ao longo das épocas de treinamento, classificação dos dados de teste (<span class="math inline">\(N_{\text{teste}}=2\times 10^3\)</span>) e curva de separação das regiões obtidas com uma rede MLP (3-4-4-2-1) treinada em <em>mini-batch</em> (<span class="math inline">\(N_0=2\)</span>, <span class="math inline">\(N_t=10^3\)</span>, <span class="math inline">\(N_b=50\)</span>) com o algoritmo <em>backpropagation</em> (<span class="math inline">\(\eta=0,5\)</span>), RMSprop (<span class="math inline">\(\eta=0,5\)</span>, <span class="math inline">\(\beta_2=0,99\)</span>, <span class="math inline">\(\varepsilon=10^{-4}\)</span>) e Adam (<span class="math inline">\(\eta=0,5\)</span>, <span class="math inline">\(\beta_1=\beta_2=0,99\)</span>, <span class="math inline">\(\varepsilon=10^{-4}\)</span>); função de ativação tangente hiperbólica e pesos e <em>biases</em> inicializados com números aleatórios gerados a partir de uma distribuição uniforme no intervalo <span class="math inline">\([-10^{-2}, 10^{-2}]\)</span>.
</figcaption>
</figure>
</div>
<div id="fig-adam2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-adam2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/adam2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-adam2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;9: Veja legenda da <a href="#fig-adam1" class="quarto-xref">Figura&nbsp;8</a>.
</figcaption>
</figure>
</div>
<div id="fig-adam4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-adam4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/adam4.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-adam4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;10: Veja legenda da <a href="#fig-adam1" class="quarto-xref">Figura&nbsp;8</a>.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="validação-cruzada" class="level2">
<h2 class="anchored" data-anchor-id="validação-cruzada">Validação cruzada</h2>
<p>A essência do aprendizado de uma rede MLP com o algoritmo <em>backpropagation</em> é aproximar um mapeamento entrada-saída por meio dos pesos e <em>biases</em>, utilizado um conjunto de exemplos rotulados. Espera-se que a rede aprenda o suficiente com os dados do passado e que seja capaz de generalizar para dados futuros. No processo de aprendizagem, é importante selecionar a “melhor” rede (número de camadas, número de neurônios, funções de ativação, passo de adaptação, etc.) dentro de um conjunto de redes candidatas, considerando um determinado critério. Além disso, o MSE tende a diminuir monotonicamente ao longo das épocas de treinamento. Em geral, quanto maior o número de épocas, mais baixo é o MSE. No entanto, um MSE baixo no treinamento não corresponde necessariamente a um desempenho satisfatório da rede com o conjunto de teste, ou seja, pode haver <em>overfitting</em>. A pergunta que cabe fazer aqui é: quando devemos parar de treinar já que um treinamento longo pode gerar <em>overfitting</em>?</p>
<p>Para responder essa pergunta e selecionar a melhor rede, é comum utilizar um conjunto de dados de validação. Neste caso, o conjunto de dados disponível deve ser primeiramente particionado de maneira aleatória entre treinamento e teste. O conjunto de treinamento, por sua vez, deve ser particionado em dois subconjuntos disjuntos:</p>
<ol type="1">
<li>subconjunto de estimação, usado para treinar o modelo;</li>
<li>subconjunto de validação, usado para testar o modelo durante o treinamento.</li>
</ol>
<p>A ideia de usar um conjunto de validação distinto do conjunto de treinamento e de teste é validar o modelo durante o treinamento com um conjunto de dados diferente do utilizado para estimar os parâmetros. A avaliação final do modelo para observar sua capacidade de generalização deve ser sempre feita com os dados do conjunto de teste, que não foram usados durante o treinamento, considerando fixos os pesos e <em>biases</em> da rede.</p>
<p>Normalmente, uma rede MLP treinada com o algoritmo <em>backpropagation</em> aprende em etapas, passando da realização de funções de mapeamento simples para funções de mapeamento mais complexas à medida que o treinamento avança. Esse processo pode ser verificado pela diminuição do MSE ao longo das épocas de treinamento: ele começa com um valor alto, diminui rapidamente e depois continua a diminuir lentamente quando a rede atinge um mínimo local da superfície de erro. Como o principal objetivo é obter uma rede com uma boa capacidade de generalização, é muito difícil descobrir quando parar de treinar, baseando-se apenas na curva de aprendizado do treinamento. Em particular, é possível que ocorra <em>overfitting</em> se o treinamento não for interrompido no ponto certo.</p>
<p>Podemos identificar o começo do <em>overfitting</em> por meio da validação cruzada (<em>cross-validation</em>). O subconjunto de exemplos de estimação é usado para treinar a rede da maneira usual, exceto por uma pequena modificação: o treinamento é interrompido periodicamente depois de um determinado número de épocas e e a rede é testada com o subconjunto de validação. Mais especificamente, o “processo de estimação seguido de validação” periódico ocorre da seguinte forma <span class="citation" data-cites="Haykin2009">(<a href="#ref-Haykin2009" role="doc-biblioref">Haykin 2009</a>)</span>:</p>
<ol type="1">
<li>após um intervalo de treinamento - a cada cinco épocas, por exemplo - os pesos e <em>biases</em> da MLP são mantidos fixos e apenas o cálculo progressivo é realizado. O erro de validação é então medido para cada exemplo do subconjunto de validação;</li>
<li>quando a fase de validação é concluída, o treinamento é retomado em um novo intervalo e o processo é repetido.</li>
</ol>
<p>Na <a href="#fig-validacao" class="quarto-xref">Figura&nbsp;11</a> são mostradas duas curvas de aprendizado: uma obtida com o subconjunto de estimação (treinamento) e outra obtida com os dados do subconjunto de validação. Normalmente, o modelo não se sai tão bem no subconjunto de validação quanto no subconjunto de estimação. A curva de aprendizado de estimação diminui monotonicamente ao longo das épocas. Em contrapartida, a curva de validação diminui monotonicamente até um ponto de mínimo e a partir deste ponto começa a aumentar à medida que o o treinamento continua. Observando a curva de aprendizado de estimação, pode parecer que seria melhor continuar o treinamento além do ponto de mínimo da curva de validação. No entanto, o que a rede está aprendendo além desse ponto é essencialmente o ruído contido nos dados de treinamento, o que leva ao <em>overfitting</em>. Diante disso, o treinamento deve ser interrompido quando a curva de validação atinge seu valor mínimo.</p>
<div id="fig-validacao" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-validacao-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/validacao.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-validacao-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;11: Curvas de erro de estimação e validação. O treinamento deve parar na época correspondente ao mínimo da curva de erro de validação. Fonte: Figura adaptada de <span class="citation" data-cites="Haykin2009">(<a href="#ref-Haykin2009" role="doc-biblioref">Haykin 2009</a>)</span>.
</figcaption>
</figure>
</div>
<p>A validação cruzada descrita anteriormente é conhecida como <em>holdout method</em>. Existem outras variantes da validação cruzada na literatura. Uma das mais utilizadas é a conhecida como <em>multifold cross-validation</em>, que é particularmente útil quando os exemplos de treinamento são escassos <span class="citation" data-cites="Leite2020">(<a href="#ref-Leite2020" role="doc-biblioref">Leite 2020</a>)</span>. Nesse método, o conjunto de treinamento disponível de <span class="math inline">\(N_t\)</span> exemplos é dividido em <span class="math inline">\(K\)</span> subconjuntos com <span class="math inline">\(K&gt;1\)</span>, sendo <span class="math inline">\(N_t\)</span> divisível por <span class="math inline">\(K\)</span>. O modelo é treinado com todos os subconjuntos exceto um e o erro de validação é medido testando o modelo no subconjunto que é deixado de fora. Este procedimento é repetido <span class="math inline">\(K\)</span> vezes, cada vez usando um subconjunto diferente para validação, conforme ilustrado na <a href="#fig-kfold" class="quarto-xref">Figura&nbsp;12</a> para <span class="math inline">\(K=5\)</span>. O desempenho do modelo é avaliado pela média do erro quadrado de validação em todas as tentativas do experimento. A desvantagem dessa variante é o custo computacional envolvido, uma vez que o modelo tem que ser treinado <span class="math inline">\(K\)</span> vezes, sendo <span class="math inline">\(1&lt;K\leq N_t\)</span>.</p>
<div id="fig-kfold" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-kfold-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/kfold.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-kfold-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12: <em>Multifold cross-validation</em>: para cada treinamento, o subconjunto de dados destacado em azul é usado para validar o modelo treinado com os dados destacados em magenta. <a href="https://drigols.medium.com/">[Fonte]</a>
</figcaption>
</figure>
</div>
<p>A validação cruzada é útil não só para evitar <em>overfitting</em>, mas também para validar a arquitetura da rede. Dessa forma, uma vez definido o número de camadas de uma rede MLP, por exemplo, o modelo de treinamento e validação da <a href="#fig-kfold" class="quarto-xref">Figura&nbsp;12</a> pode ser utilizado para verificar se o número de camadas é adequado com base no erro de validação. Se o erro de validação cai nos <span class="math inline">\(K\)</span> treinamentos, então o número de camadas parece ser adequado. Isso também pode ser utilizado para comparar redes MLP com diferentes arquiteturas para ajudar na escolha da arquitetura mais adequada.</p>
</section>
</div>





<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">Referências</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-BaydinJMLR2018" class="csl-entry" role="listitem">
Baydin, Atılım G., Barak A. Pearlmutter, Alexey A. Radul, e Jeffrey M. Siskind. 2018. <span>“Automatic Differentiation in Machine Learning: a Survey”</span>. <em>Journal of Machine Learning Research</em> 18: 1–43.
</div>
<div id="ref-Bishop_book2006" class="csl-entry" role="listitem">
Bishop, C. M. 2006. <em>Pattern recognition and machine learning</em>. Springer.
</div>
<div id="ref-JasonInit2021" class="csl-entry" role="listitem">
Brownlee, Jason. 2021. <em>Weight Initialization for Deep Learning Neural Networks</em>. <a href="https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/" class="uri">https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/</a>.
</div>
<div id="ref-Xavier2010" class="csl-entry" role="listitem">
Glorot, Xavier, e Yoshua Bengio. 2010. <span>“Understanding the difficulty of training deep feedforward neural networks”</span>. Em <em>Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</em>, 249–56.
</div>
<div id="ref-Goodfellow2016" class="csl-entry" role="listitem">
Goodfellow, Ian, Yoshua Bengio, e Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press,&nbsp;<a href="http://www.deeplearningbook.org" class="uri">http://www.deeplearningbook.org</a>.
</div>
<div id="ref-Haykin2009" class="csl-entry" role="listitem">
Haykin, Simon. 2009. <em>Neural networks and learning machines</em>. 3rd ed. Pearson.
</div>
<div id="ref-He2015" class="csl-entry" role="listitem">
He, Kaiming, Xiangyu Zhang, Shaoqing Ren, e Jian Sun. 2015. <span>“Delving deep into rectifiers: surpassing human-level performance on <span>I</span>mage<span>N</span>et classification”</span>. Em <em>Proceedings of the IEEE International Conference on Computer Vision (ICCV)</em>, 1026–34.
</div>
<div id="ref-Jordan2018learning" class="csl-entry" role="listitem">
Jordan, Jeremy. 2018. <em>Setting the learning rate of your neural network</em>. <a href="https://www.jeremyjordan.me/nn-learning-rate/" class="uri">https://www.jeremyjordan.me/nn-learning-rate/</a>.
</div>
<div id="ref-Adam2015" class="csl-entry" role="listitem">
Kingma, Diederik P., e Jimmy Ba. 2015. <em>Adam: A Method for Stochastic Optimization</em>. <a href="https://arxiv.org/abs/1412.6980" class="uri">https://arxiv.org/abs/1412.6980</a>.
</div>
<div id="ref-Leite2020" class="csl-entry" role="listitem">
Leite, Rodrigo. 2020. <em>Introdução a Validação-Cruzada: K-Fold</em>. <a href="https://drigols.medium.com/introdu%C3%A7%C3%A3o-a-valida%C3%A7%C3%A3o-cruzada-k-fold-2a6bced32a90" class="uri">https://drigols.medium.com/introdu%C3%A7%C3%A3o-a-valida%C3%A7%C3%A3o-cruzada-k-fold-2a6bced32a90</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Notas de rodapé</h2>

<ol>
<li id="fn1"><p>O termo <em>estocástico</em> é utilizado aqui para se referir ao modo de treinamento em que cada exemplo de treinamento individual é utilizado para fazer uma iteração de adaptação dos coeficientes.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script>
var custom_title = document.querySelectorAll('.custom .theorem-title');

for (let i = 0; i < custom_title.length; i++ ) {
   var mod_name = custom_title[i].innerHTML;
   custom_title[i].innerHTML = mod_name.replace("Exemplo", "Algoritmo");
};
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiada");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiada");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>